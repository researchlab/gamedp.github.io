
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>redis-22-configuration | 一线攻城狮</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Lee Hong">
    

    
    <meta name="description" content="为深入学习了解redis, 本文将对redis5.0.0源码包目录下的redis.conf配置文件进行完整翻译学习, 翻译顺序与配置文件保持一致;">
<meta property="og:type" content="article">
<meta property="og:title" content="redis-22-configuration">
<meta property="og:url" content="http://researchlab.github.io/2018/10/26/redis-22-configuration/index.html">
<meta property="og:site_name" content="一线攻城狮">
<meta property="og:description" content="为深入学习了解redis, 本文将对redis5.0.0源码包目录下的redis.conf配置文件进行完整翻译学习, 翻译顺序与配置文件保持一致;">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2020-11-08T02:57:49.974Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="redis-22-configuration">
<meta name="twitter:description" content="为深入学习了解redis, 本文将对redis5.0.0源码包目录下的redis.conf配置文件进行完整翻译学习, 翻译顺序与配置文件保持一致;">

    
    <link rel="alternative" href="/atom.xml" title="一线攻城狮" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="一线攻城狮">一线攻城狮</a></h1>
				<h2 class="blog-motto">十年磨一剑，一步一步脚踏实地的耕种</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页</a></li>
					
						<li><a href="/archives">归档</a></li>
					
						<li><a href="/reading">书单</a></li>
					
						<li><a href="/opensource">开源</a></li>
					
						<li><a href="/about">关于</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:researchlab.github.io">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/10/26/redis-22-configuration/" title="redis-22-configuration" itemprop="url">redis-22-configuration</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Lee Hong" target="_blank" itemprop="author">Lee Hong</a>
		
 <p class="article-time">
    <time datetime="2018-10-26T06:06:46.000Z" itemprop="datePublished"> 发表于 2018-10-26</time>
   &nbsp&nbsp热度&nbsp<span id="busuanzi_value_page_pv"></span>° 
  </p>
</header>

	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-5"><a class="toc-link" href="#INCLUDES"><span class="toc-number">1.</span> <span class="toc-text">INCLUDES</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#MODULES"><span class="toc-number">2.</span> <span class="toc-text">MODULES</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#NETWORK"><span class="toc-number">3.</span> <span class="toc-text">NETWORK</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#GENERAL"><span class="toc-number">4.</span> <span class="toc-text">GENERAL</span></a></li></ol>
		
		</div>
		
		<p>为深入学习了解<code>redis</code>, 本文将对<code>redis5.0.0</code>源码包目录下的<code>redis.conf</code>配置文件进行完整翻译学习, 翻译顺序与配置文件保持一致;<br><a id="more"></a></p>
<p><code>Redis</code>配置文件示例</p>
<p>为程序能正确读取配置文件, 配置文件路径必须作为程序启动的第一个参数输入,  </p>
<blockquote>
<p>./redis-server /path/to/redis.conf </p>
</blockquote>
<p>默认的配置文件中, 首先约定了存储单位:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1k  =&gt; 1000 bytes</span><br><span class="line">1kb =&gt; 1024 bytes</span><br><span class="line">1m  =&gt; 1000000 bytes</span><br><span class="line">1mb =&gt; 1024*1024 bytes</span><br><span class="line">1g  =&gt; 1000000000 bytes</span><br><span class="line">1gb =&gt; 1024*1024*1024 bytes</span><br></pre></td></tr></table></figure></p>
<p>Redis配置中对单位的大小写不敏感, 1GB、1Gb和1gB都是相同的。由此也说明, Redis只支持bytes, 不支持bit单位。</p>
<h5 id="INCLUDES"><a href="#INCLUDES" class="headerlink" title="INCLUDES"></a>INCLUDES</h5><p>################################## INCLUDES ###################################</p>
<p>Redis支持以<code>include</code>的方式引入一个或多个其他配置文件, 比如:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">include /path/to/local.conf</span><br><span class="line">include /path/to/other.conf</span><br></pre></td></tr></table></figure></p>
<p>当存在一个标准配置模板可以应用到所有的<code>redis server</code>服务实例中, 但又需要自定义配置其中某些服务实例的配置项, 则很适合用<code>include</code>引入这些自定义配置文件, 这些自定义配置文件中也可以通过<code>include</code>引入其他配置文件;<br>需要注意的是,<code>include</code>引入的配置项并不会被<code>admin</code>通过<code>CONFIG REWRITE</code>命令或<code>Redis Sentinel</code>重写; 但如一个配置项在不同配置文件中都有定义, 则以最后一行读入的为准, 就是说后面的配置项会覆盖前面的配置项。<br>在标准配置模板开始位置引入<code>include</code>配置文件, 则引入的这些配置文件不会覆盖标准配置模板中的配置项;<br>在标准配置模板最后位置引入<code>include</code>配置文件, 则引入的这些配置文件会覆盖标准配置模板中的配置项;</p>
<h5 id="MODULES"><a href="#MODULES" class="headerlink" title="MODULES"></a>MODULES</h5><p>################################## MODULES #####################################</p>
<p>从<code>redis4.0</code>版本开始支持载入模块功能, 大大扩展了<code>redis</code>功能,  <code>redis4.0</code>以上版本可以通过<code>loadmodule</code>配置在服务启动时载入相关模块功能,若当前<code>redis</code>服务器版本不支持加载模块, 则不会响应<code>loadmodule</code>指令; 可以使用多个<code>loadmodule</code>指令;</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loadmodule /path/to/my_module.so</span><br><span class="line">loadmodule /path/to/other_module.so</span><br></pre></td></tr></table></figure>
<h5 id="NETWORK"><a href="#NETWORK" class="headerlink" title="NETWORK"></a>NETWORK</h5><p>################################## NETWORK #####################################<br>默认情况下, 如果没有具体指定<code>bind</code>配置指令, Redis会响应本机所有可用网卡的连接请求。Redis允许通过<code>bind</code>配置项来指定要绑定的一个或多个IP,<br>示例,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bind 192.168.1.100 10.0.0.1</span><br><span class="line">bind 127.0.0.1 ::1</span><br></pre></td></tr></table></figure></p>
<p>注意, 将设置<code>bind</code>为响应所有网卡请求<code>redis</code>实例的机器直接暴露在公网上是很危险的行为, 这样做会将数据库实例暴露给公网上的每个用户; 所以默认配置为<code>bind 127.0.0.1</code>，这将强制<code>redis</code>服务实例只能响应与<code>redis</code>服务运行在同一台机器上的客户端请求; 如果你确认安全的情况下, 可以<code>bind</code>为响应所有网卡请求;<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bind 127.0.0.1</span><br></pre></td></tr></table></figure></p>
<p>保护模式是为避免<code>Redis</code>实例运行在公网上和使用的一层保护行为;</p>
<p>当开启保护模式后, 存在如下情况,</p>
<ol>
<li>服务器没有通过<code>bind</code>指令明确绑定到一组网络地址上;</li>
<li>没有配置访问密码;</li>
</ol>
<p>则<code>redis</code>服务器只接受来自IPv4和IPv6环回地址127.0.0.1和:: 1上客户端的连接请求以及Unix sockets请求;</p>
<p>默认情况下, 保护模式是开启的, 在你确认在上述两种情况下需要响应来自其它机器上<code>redis</code>连接请求时, 可以自行保护模式;<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">protected-mode yes</span><br></pre></td></tr></table></figure></p>
<p><code>redis</code>默认监听6379服务端口(IANA #815344), 当端口被设置为0时, <code>redis</code>服务器则不再监听TCP套接字连接了;</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">port 6379</span><br></pre></td></tr></table></figure>
<blockquote>
<p>可是, 如果Redis不监听端口, 还怎么与外界通信呢？其实Redis还支持通过unix socket方式来接收请求。可以通过unix socket配置项来指定unix socket文件的路径, 并通过unix socket perm来指定文件的权限。</p>
</blockquote>
<p>TCP listen() backlog值<br>在高QPS场景下需要提高backlog值来避免TCP的慢连接问题; 若backlog值大于系统<code>/proc/sys/net/core/somaxconn</code>最大值, Linux kernel默认会将backlog值截断保存到somaxconn中, 即backlog值受到somaxconn的最大值影响, 所以为了达到理想效果请注意同时将<code>somaxconn</code>和<code>tcp_max_syn_backlog</code>设置为一个比较大的合理值; <code>redis.conf</code>默认设置tcp-backlog为511,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcp-backlog 511</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><code>tcp_max_syn_backlog</code> 为tcp三次握手中未完成连接队列的最大值限制, 默认值为128;<br><code>somaxconn</code> 定义了系统中每一个端口最大的监听队列的长度,这是个全局的参数, 默认值为128;<br>更多说明可参考 <a href="http://researchlab.github.io/2018/09/23/tcp-net-programing/">TCP网络编程过程完整分析</a></p>
</blockquote>
<p>Unix socket<br>没有设置默认Unix socket 套接字路径, 所以Redis默认不会监听来自Unix socket的请求, 只有具体配置指定了Unix socket套接字路径, 才监听这个套接字上的请求;<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> unixsocket /tmp/redis.sock  指定 unix socket 的路径</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> unixsocketperm 700 指定 unix socket file 的权限</span></span><br></pre></td></tr></table></figure></p>
<p>当客户端闲置多少秒后关闭连接，如果设置为0表示关闭该功能, 默认为0;<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timeout 0</span><br></pre></td></tr></table></figure></p>
<p> TCP keepalive.<br>TCP连接保活策略, 可以通过tcp-keepalive配置项来进行设置, 单位为秒, 假如设置为60秒, 则server端会每60秒向连接空闲的客户端发起一次ACK请求, 以检查客户端是否已经挂掉, 对于无响应的客户端则会关闭其连接。所以关闭一个连接最长需要120秒的时间。如果设置为0, 则不会进行保活检测。<br>官方建议值为300s, 并从redis3.2.1开始默认设置tcp-keepalive值;<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcp-keepalive 300</span><br></pre></td></tr></table></figure></p>
<h5 id="GENERAL"><a href="#GENERAL" class="headerlink" title="GENERAL"></a>GENERAL</h5><p>################################# GENERAL #####################################<br>默认情况, redis实例不会以守护进程运行, 如果需要运行为守护进程， 则应配置其值为<code>yes</code>, 当以守护进程运行时，redis会将其pid默认写入到<code>/var/run/redis.pid</code>文件中<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">daemonize no</span><br></pre></td></tr></table></figure></p>
<p>可以通过upstart和systemd管理Redis守护进程, 具体响应如下,<br><code>supervised no</code>      - 不使用 supervision 管理<br><code>supervised upstart</code> - <code>upstart</code>信号以<code>SIGSTOP</code>模式启动<code>redis</code><br><code>supervised systemd</code> - <code>systemd</code> 将READY=1 写入 $NOTIFY_SOCKET<br><code>supervised auto</code>    - 通过检测<code>UPSTART_JOB</code>或者<code>NOTIFY_SOCKET</code>环境参数来决定使用<code>upstart</code>或者<code>systemd</code>方法启动;<br>注意上述只能管理守护进程存在,并不会检测redis连接是否依然有效;<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">supervised no</span><br></pre></td></tr></table></figure></p>
<p>当redis以守护模式启动时, 如果没有配置pidfile, pidfile默认值是/var/run/redis.pid, redis会在启动时将pid值记录到指定的pidfile中, 并且在服务关闭时删除这个pid记录;<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pidfile /var/run/redis_6379.pid</span><br></pre></td></tr></table></figure></p>
<p>Redis支持通过loglevel配置项设置日志等级, 共分四级, 即debug、verbose、notice、warning, 记录的日志信息依次递减,重要程度依次递增, 默认为notice<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loglevel notice</span><br></pre></td></tr></table></figure></p>
<p>Redis也支持通过logfile配置项来设置日志文件的生成位置。如果设置为空字符串, 则Redis会将日志输出到标准输出。假如在daemon情况下将日志设置为输出到标准输出, 则日志会被写到/dev/null中。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logfile ""</span><br></pre></td></tr></table></figure>
<!--
# To enable logging to the system logger, just set 'syslog-enabled' to yes,
# and optionally update the other syslog parameters to suit your needs.
# syslog-enabled no

# Specify the syslog identity.
# syslog-ident redis

# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.
# syslog-facility local0

# Set the number of databases. The default database is DB 0, you can select
# a different one on a per-connection basis using SELECT <dbid> where
# dbid is a number between 0 and 'databases'-1
databases 16

# By default Redis shows an ASCII art logo only when started to log to the
# standard output and if the standard output is a TTY. Basically this means
# that normally a logo is displayed only in interactive sessions.
#
# However it is possible to force the pre-4.0 behavior and always show a
# ASCII art logo in startup logs by setting the following option to yes.
always-show-logo yes

################################ SNAPSHOTTING  ################################
#
# Save the DB on disk:
#
#   save <seconds> <changes>
#
#   Will save the DB if both the given number of seconds and the given
#   number of write operations against the DB occurred.
#
#   In the example below the behaviour will be to save:
#   after 900 sec (15 min) if at least 1 key changed
#   after 300 sec (5 min) if at least 10 keys changed
#   after 60 sec if at least 10000 keys changed
#
#   Note: you can disable saving completely by commenting out all "save" lines.
#
#   It is also possible to remove all the previously configured save
#   points by adding a save directive with a single empty string argument
#   like in the following example:
#
#   save ""

save 900 1
save 300 10
save 60 10000

# By default Redis will stop accepting writes if RDB snapshots are enabled
# (at least one save point) and the latest background save failed.
# This will make the user aware (in a hard way) that data is not persisting
# on disk properly, otherwise chances are that no one will notice and some
# disaster will happen.
#
# If the background saving process will start working again Redis will
# automatically allow writes again.
#
# However if you have setup your proper monitoring of the Redis server
# and persistence, you may want to disable this feature so that Redis will
# continue to work as usual even if there are problems with disk,
# permissions, and so forth.
stop-writes-on-bgsave-error yes

# Compress string objects using LZF when dump .rdb databases?
# For default that's set to 'yes' as it's almost always a win.
# If you want to save some CPU in the saving child set it to 'no' but
# the dataset will likely be bigger if you have compressible values or keys.
rdbcompression yes

# Since version 5 of RDB a CRC64 checksum is placed at the end of the file.
# This makes the format more resistant to corruption but there is a performance
# hit to pay (around 10%) when saving and loading RDB files, so you can disable it
# for maximum performances.
#
# RDB files created with checksum disabled have a checksum of zero that will
# tell the loading code to skip the check.
rdbchecksum yes

# The filename where to dump the DB
dbfilename dump.rdb

# The working directory.
#
# The DB will be written inside this directory, with the filename specified
# above using the 'dbfilename' configuration directive.
#
# The Append Only File will also be created inside this directory.
#
# Note that you must specify a directory here, not a file name.
dir ./

################################# REPLICATION #################################

# Master-Replica replication. Use replicaof to make a Redis instance a copy of
# another Redis server. A few things to understand ASAP about Redis replication.
#
#   +------------------+      +---------------+
#   |      Master      | ---> |    Replica    |<br>#   | (receive writes) |      |  (exact copy) |<br>#   +——————+      +—————+<br>#<br># 1) Redis replication is asynchronous, but you can configure a master to<br>#    stop accepting writes if it appears to be not connected with at least<br>#    a given number of replicas.<br># 2) Redis replicas are able to perform a partial resynchronization with the<br>#    master if the replication link is lost for a relatively small amount of<br>#    time. You may want to configure the replication backlog size (see the next<br>#    sections of this file) with a sensible value depending on your needs.<br># 3) Replication is automatic and does not need user intervention. After a<br>#    network partition replicas automatically try to reconnect to masters<br>#    and resynchronize with them.<br>#<br># replicaof <masterip> <masterport><br><br># If the master is password protected (using the “requirepass” configuration<br># directive below) it is possible to tell the replica to authenticate before<br># starting the replication synchronization process, otherwise the master will<br># refuse the replica request.<br>#<br># masterauth <master-password><br><br># When a replica loses its connection with the master, or when the replication<br># is still in progress, the replica can act in two different ways:<br>#<br># 1) if replica-serve-stale-data is set to ‘yes’ (the default) the replica will<br>#    still reply to client requests, possibly with out of date data, or the<br>#    data set may just be empty if this is the first synchronization.<br>#<br># 2) if replica-serve-stale-data is set to ‘no’ the replica will reply with<br>#    an error “SYNC with master in progress” to all the kind of commands<br>#    but to INFO, replicaOF, AUTH, PING, SHUTDOWN, REPLCONF, ROLE, CONFIG,<br>#    SUBSCRIBE, UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB,<br>#    COMMAND, POST, HOST: and LATENCY.<br>#<br>replica-serve-stale-data yes<br><br># You can configure a replica instance to accept writes or not. Writing against<br># a replica instance may be useful to store some ephemeral data (because data<br># written on a replica will be easily deleted after resync with the master) but<br># may also cause problems if clients are writing to it because of a<br># misconfiguration.<br>#<br># Since Redis 2.6 by default replicas are read-only.<br>#<br># Note: read only replicas are not designed to be exposed to untrusted clients<br># on the internet. It’s just a protection layer against misuse of the instance.<br># Still a read only replica exports by default all the administrative commands<br># such as CONFIG, DEBUG, and so forth. To a limited extent you can improve<br># security of read only replicas using ‘rename-command’ to shadow all the<br># administrative / dangerous commands.<br>replica-read-only yes<br><br># Replication SYNC strategy: disk or socket.<br>#<br># ——————————————————-<br># WARNING: DISKLESS REPLICATION IS EXPERIMENTAL CURRENTLY<br># ——————————————————-<br>#<br># New replicas and reconnecting replicas that are not able to continue the replication<br># process just receiving differences, need to do what is called a “full<br># synchronization”. An RDB file is transmitted from the master to the replicas.<br># The transmission can happen in two different ways:<br>#<br># 1) Disk-backed: The Redis master creates a new process that writes the RDB<br>#                 file on disk. Later the file is transferred by the parent<br>#                 process to the replicas incrementally.<br># 2) Diskless: The Redis master creates a new process that directly writes the<br>#              RDB file to replica sockets, without touching the disk at all.<br>#<br># With disk-backed replication, while the RDB file is generated, more replicas<br># can be queued and served with the RDB file as soon as the current child producing<br># the RDB file finishes its work. With diskless replication instead once<br># the transfer starts, new replicas arriving will be queued and a new transfer<br># will start when the current one terminates.<br>#<br># When diskless replication is used, the master waits a configurable amount of<br># time (in seconds) before starting the transfer in the hope that multiple replicas<br># will arrive and the transfer can be parallelized.<br>#<br># With slow disks and fast (large bandwidth) networks, diskless replication<br># works better.<br>repl-diskless-sync no<br><br># When diskless replication is enabled, it is possible to configure the delay<br># the server waits in order to spawn the child that transfers the RDB via socket<br># to the replicas.<br>#<br># This is important since once the transfer starts, it is not possible to serve<br># new replicas arriving, that will be queued for the next RDB transfer, so the server<br># waits a delay in order to let more replicas arrive.<br>#<br># The delay is specified in seconds, and by default is 5 seconds. To disable<br># it entirely just set it to 0 seconds and the transfer will start ASAP.<br>repl-diskless-sync-delay 5<br><br># Replicas send PINGs to server in a predefined interval. It’s possible to change<br># this interval with the repl_ping_replica_period option. The default value is 10<br># seconds.<br>#<br># repl-ping-replica-period 10<br><br># The following option sets the replication timeout for:<br>#<br># 1) Bulk transfer I/O during SYNC, from the point of view of replica.<br># 2) Master timeout from the point of view of replicas (data, pings).<br># 3) Replica timeout from the point of view of masters (REPLCONF ACK pings).<br>#<br># It is important to make sure that this value is greater than the value<br># specified for repl-ping-replica-period otherwise a timeout will be detected<br># every time there is low traffic between the master and the replica.<br>#<br># repl-timeout 60<br><br># Disable TCP_NODELAY on the replica socket after SYNC?<br>#<br># If you select “yes” Redis will use a smaller number of TCP packets and<br># less bandwidth to send data to replicas. But this can add a delay for<br># the data to appear on the replica side, up to 40 milliseconds with<br># Linux kernels using a default configuration.<br>#<br># If you select “no” the delay for data to appear on the replica side will<br># be reduced but more bandwidth will be used for replication.<br>#<br># By default we optimize for low latency, but in very high traffic conditions<br># or when the master and replicas are many hops away, turning this to “yes” may<br># be a good idea.<br>repl-disable-tcp-nodelay no<br><br># Set the replication backlog size. The backlog is a buffer that accumulates<br># replica data when replicas are disconnected for some time, so that when a replica<br># wants to reconnect again, often a full resync is not needed, but a partial<br># resync is enough, just passing the portion of data the replica missed while<br># disconnected.<br>#<br># The bigger the replication backlog, the longer the time the replica can be<br># disconnected and later be able to perform a partial resynchronization.<br>#<br># The backlog is only allocated once there is at least a replica connected.<br>#<br># repl-backlog-size 1mb<br><br># After a master has no longer connected replicas for some time, the backlog<br># will be freed. The following option configures the amount of seconds that<br># need to elapse, starting from the time the last replica disconnected, for<br># the backlog buffer to be freed.<br>#<br># Note that replicas never free the backlog for timeout, since they may be<br># promoted to masters later, and should be able to correctly “partially<br># resynchronize” with the replicas: hence they should always accumulate backlog.<br>#<br># A value of 0 means to never release the backlog.<br>#<br># repl-backlog-ttl 3600<br><br># The replica priority is an integer number published by Redis in the INFO output.<br># It is used by Redis Sentinel in order to select a replica to promote into a<br># master if the master is no longer working correctly.<br>#<br># A replica with a low priority number is considered better for promotion, so<br># for instance if there are three replicas with priority 10, 100, 25 Sentinel will<br># pick the one with priority 10, that is the lowest.<br>#<br># However a special priority of 0 marks the replica as not able to perform the<br># role of master, so a replica with priority of 0 will never be selected by<br># Redis Sentinel for promotion.<br>#<br># By default the priority is 100.<br>replica-priority 100<br><br># It is possible for a master to stop accepting writes if there are less than<br># N replicas connected, having a lag less or equal than M seconds.<br>#<br># The N replicas need to be in “online” state.<br>#<br># The lag in seconds, that must be &lt;= the specified value, is calculated from<br># the last ping received from the replica, that is usually sent every second.<br>#<br># This option does not GUARANTEE that N replicas will accept the write, but<br># will limit the window of exposure for lost writes in case not enough replicas<br># are available, to the specified number of seconds.<br>#<br># For example to require at least 3 replicas with a lag &lt;= 10 seconds use:<br>#<br># min-replicas-to-write 3<br># min-replicas-max-lag 10<br>#<br># Setting one or the other to 0 disables the feature.<br>#<br># By default min-replicas-to-write is set to 0 (feature disabled) and<br># min-replicas-max-lag is set to 10.<br><br># A Redis master is able to list the address and port of the attached<br># replicas in different ways. For example the “INFO replication” section<br># offers this information, which is used, among other tools, by<br># Redis Sentinel in order to discover replica instances.<br># Another place where this info is available is in the output of the<br># “ROLE” command of a master.<br>#<br># The listed IP and address normally reported by a replica is obtained<br># in the following way:<br>#<br>#   IP: The address is auto detected by checking the peer address<br>#   of the socket used by the replica to connect with the master.<br>#<br>#   Port: The port is communicated by the replica during the replication<br>#   handshake, and is normally the port that the replica is using to<br>#   listen for connections.<br>#<br># However when port forwarding or Network Address Translation (NAT) is<br># used, the replica may be actually reachable via different IP and port<br># pairs. The following two options can be used by a replica in order to<br># report to its master a specific set of IP and port, so that both INFO<br># and ROLE will report those values.<br>#<br># There is no need to use both the options if you need to override just<br># the port or the IP address.<br>#<br># replica-announce-ip 5.5.5.5<br># replica-announce-port 1234<br><br>################################## SECURITY ###################################<br><br># Require clients to issue AUTH <password> before processing any other<br># commands.  This might be useful in environments in which you do not trust<br># others with access to the host running redis-server.<br>#<br># This should stay commented out for backward compatibility and because most<br># people do not need auth (e.g. they run their own servers).<br>#<br># Warning: since Redis is pretty fast an outside user can try up to<br># 150k passwords per second against a good box. This means that you should<br># use a very strong password otherwise it will be very easy to break.<br>#<br># requirepass foobared<br><br># Command renaming.<br>#<br># It is possible to change the name of dangerous commands in a shared<br># environment. For instance the CONFIG command may be renamed into something<br># hard to guess so that it will still be available for internal-use tools<br># but not available for general clients.<br>#<br># Example:<br>#<br># rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52<br>#<br># It is also possible to completely kill a command by renaming it into<br># an empty string:<br>#<br># rename-command CONFIG “”<br>#<br># Please note that changing the name of commands that are logged into the<br># AOF file or transmitted to replicas may cause problems.<br><br>################################### CLIENTS ####################################<br><br># Set the max number of connected clients at the same time. By default<br># this limit is set to 10000 clients, however if the Redis server is not<br># able to configure the process file limit to allow for the specified limit<br># the max number of allowed clients is set to the current file limit<br># minus 32 (as Redis reserves a few file descriptors for internal uses).<br>#<br># Once the limit is reached Redis will close all the new connections sending<br># an error ‘max number of clients reached’.<br>#<br># maxclients 10000<br><br>############################## MEMORY MANAGEMENT ################################<br><br># Set a memory usage limit to the specified amount of bytes.<br># When the memory limit is reached Redis will try to remove keys<br># according to the eviction policy selected (see maxmemory-policy).<br>#<br># If Redis can’t remove keys according to the policy, or if the policy is<br># set to ‘noeviction’, Redis will start to reply with errors to commands<br># that would use more memory, like SET, LPUSH, and so on, and will continue<br># to reply to read-only commands like GET.<br>#<br># This option is usually useful when using Redis as an LRU or LFU cache, or to<br># set a hard memory limit for an instance (using the ‘noeviction’ policy).<br>#<br># WARNING: If you have replicas attached to an instance with maxmemory on,<br># the size of the output buffers needed to feed the replicas are subtracted<br># from the used memory count, so that network problems / resyncs will<br># not trigger a loop where keys are evicted, and in turn the output<br># buffer of replicas is full with DELs of keys evicted triggering the deletion<br># of more keys, and so forth until the database is completely emptied.<br>#<br># In short… if you have replicas attached it is suggested that you set a lower<br># limit for maxmemory so that there is some free RAM on the system for replica<br># output buffers (but this is not needed if the policy is ‘noeviction’).<br>#<br># maxmemory <bytes><br><br># MAXMEMORY POLICY: how Redis will select what to remove when maxmemory<br># is reached. You can select among five behaviors:<br>#<br># volatile-lru -&gt; Evict using approximated LRU among the keys with an expire set.<br># allkeys-lru -&gt; Evict any key using approximated LRU.<br># volatile-lfu -&gt; Evict using approximated LFU among the keys with an expire set.<br># allkeys-lfu -&gt; Evict any key using approximated LFU.<br># volatile-random -&gt; Remove a random key among the ones with an expire set.<br># allkeys-random -&gt; Remove a random key, any key.<br># volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)<br># noeviction -&gt; Don’t evict anything, just return an error on write operations.<br>#<br># LRU means Least Recently Used<br># LFU means Least Frequently Used<br>#<br># Both LRU, LFU and volatile-ttl are implemented using approximated<br># randomized algorithms.<br>#<br># Note: with any of the above policies, Redis will return an error on write<br>#       operations, when there are no suitable keys for eviction.<br>#<br>#       At the date of writing these commands are: set setnx setex append<br>#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd<br>#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby<br>#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby<br>#       getset mset msetnx exec sort<br>#<br># The default is:<br>#<br># maxmemory-policy noeviction<br><br># LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated<br># algorithms (in order to save memory), so you can tune it for speed or<br># accuracy. For default Redis will check five keys and pick the one that was<br># used less recently, you can change the sample size using the following<br># configuration directive.<br>#<br># The default of 5 produces good enough results. 10 Approximates very closely<br># true LRU but costs more CPU. 3 is faster but not very accurate.<br>#<br># maxmemory-samples 5<br><br># Starting from Redis 5, by default a replica will ignore its maxmemory setting<br># (unless it is promoted to master after a failover or manually). It means<br># that the eviction of keys will be just handled by the master, sending the<br># DEL commands to the replica as keys evict in the master side.<br>#<br># This behavior ensures that masters and replicas stay consistent, and is usually<br># what you want, however if your replica is writable, or you want the replica to have<br># a different memory setting, and you are sure all the writes performed to the<br># replica are idempotent, then you may change this default (but be sure to understand<br># what you are doing).<br>#<br># Note that since the replica by default does not evict, it may end using more<br># memory than the one set via maxmemory (there are certain buffers that may<br># be larger on the replica, or data structures may sometimes take more memory and so<br># forth). So make sure you monitor your replicas and make sure they have enough<br># memory to never hit a real out-of-memory condition before the master hits<br># the configured maxmemory setting.<br>#<br># replica-ignore-maxmemory yes<br><br>############################# LAZY FREEING ####################################<br><br># Redis has two primitives to delete keys. One is called DEL and is a blocking<br># deletion of the object. It means that the server stops processing new commands<br># in order to reclaim all the memory associated with an object in a synchronous<br># way. If the key deleted is associated with a small object, the time needed<br># in order to execute the DEL command is very small and comparable to most other<br># O(1) or O(log_N) commands in Redis. However if the key is associated with an<br># aggregated value containing millions of elements, the server can block for<br># a long time (even seconds) in order to complete the operation.<br>#<br># For the above reasons Redis also offers non blocking deletion primitives<br># such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and<br># FLUSHDB commands, in order to reclaim memory in background. Those commands<br># are executed in constant time. Another thread will incrementally free the<br># object in the background as fast as possible.<br>#<br># DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled.<br># It’s up to the design of the application to understand when it is a good<br># idea to use one or the other. However the Redis server sometimes has to<br># delete keys or flush the whole database as a side effect of other operations.<br># Specifically Redis deletes objects independently of a user call in the<br># following scenarios:<br>#<br># 1) On eviction, because of the maxmemory and maxmemory policy configurations,<br>#    in order to make room for new data, without going over the specified<br>#    memory limit.<br># 2) Because of expire: when a key with an associated time to live (see the<br>#    EXPIRE command) must be deleted from memory.<br># 3) Because of a side effect of a command that stores data on a key that may<br>#    already exist. For example the RENAME command may delete the old key<br>#    content when it is replaced with another one. Similarly SUNIONSTORE<br>#    or SORT with STORE option may delete existing keys. The SET command<br>#    itself removes any old content of the specified key in order to replace<br>#    it with the specified string.<br># 4) During replication, when a replica performs a full resynchronization with<br>#    its master, the content of the whole database is removed in order to<br>#    load the RDB file just transferred.<br>#<br># In all the above cases the default is to delete objects in a blocking way,<br># like if DEL was called. However you can configure each case specifically<br># in order to instead release memory in a non-blocking way like if UNLINK<br># was called, using the following configuration directives:<br><br>lazyfree-lazy-eviction no<br>lazyfree-lazy-expire no<br>lazyfree-lazy-server-del no<br>replica-lazy-flush no<br><br>############################## APPEND ONLY MODE ###############################<br><br># By default Redis asynchronously dumps the dataset on disk. This mode is<br># good enough in many applications, but an issue with the Redis process or<br># a power outage may result into a few minutes of writes lost (depending on<br># the configured save points).<br>#<br># The Append Only File is an alternative persistence mode that provides<br># much better durability. For instance using the default data fsync policy<br># (see later in the config file) Redis can lose just one second of writes in a<br># dramatic event like a server power outage, or a single write if something<br># wrong with the Redis process itself happens, but the operating system is<br># still running correctly.<br>#<br># AOF and RDB persistence can be enabled at the same time without problems.<br># If the AOF is enabled on startup Redis will load the AOF, that is the file<br># with the better durability guarantees.<br>#<br># Please check <a href="http://redis.io/topics/persistence" target="_blank" rel="noopener">http://redis.io/topics/persistence</a> for more information.<br><br>appendonly no<br><br># The name of the append only file (default: “appendonly.aof”)<br><br>appendfilename “appendonly.aof”<br><br># The fsync() call tells the Operating System to actually write data on disk<br># instead of waiting for more data in the output buffer. Some OS will really flush<br># data on disk, some other OS will just try to do it ASAP.<br>#<br># Redis supports three different modes:<br>#<br># no: don’t fsync, just let the OS flush the data when it wants. Faster.<br># always: fsync after every write to the append only log. Slow, Safest.<br># everysec: fsync only one time every second. Compromise.<br>#<br># The default is “everysec”, as that’s usually the right compromise between<br># speed and data safety. It’s up to you to understand if you can relax this to<br># “no” that will let the operating system flush the output buffer when<br># it wants, for better performances (but if you can live with the idea of<br># some data loss consider the default persistence mode that’s snapshotting),<br># or on the contrary, use “always” that’s very slow but a bit safer than<br># everysec.<br>#<br># More details please check the following article:<br># <a href="http://antirez.com/post/redis-persistence-demystified.html" target="_blank" rel="noopener">http://antirez.com/post/redis-persistence-demystified.html</a><br>#<br># If unsure, use “everysec”.<br><br># appendfsync always<br>appendfsync everysec<br># appendfsync no<br><br># When the AOF fsync policy is set to always or everysec, and a background<br># saving process (a background save or AOF log background rewriting) is<br># performing a lot of I/O against the disk, in some Linux configurations<br># Redis may block too long on the fsync() call. Note that there is no fix for<br># this currently, as even performing fsync in a different thread will block<br># our synchronous write(2) call.<br>#<br># In order to mitigate this problem it’s possible to use the following option<br># that will prevent fsync() from being called in the main process while a<br># BGSAVE or BGREWRITEAOF is in progress.<br>#<br># This means that while another child is saving, the durability of Redis is<br># the same as “appendfsync none”. In practical terms, this means that it is<br># possible to lose up to 30 seconds of log in the worst scenario (with the<br># default Linux settings).<br>#<br># If you have latency problems turn this to “yes”. Otherwise leave it as<br># “no” that is the safest pick from the point of view of durability.<br><br>no-appendfsync-on-rewrite no<br><br># Automatic rewrite of the append only file.<br># Redis is able to automatically rewrite the log file implicitly calling<br># BGREWRITEAOF when the AOF log size grows by the specified percentage.<br>#<br># This is how it works: Redis remembers the size of the AOF file after the<br># latest rewrite (if no rewrite has happened since the restart, the size of<br># the AOF at startup is used).<br>#<br># This base size is compared to the current size. If the current size is<br># bigger than the specified percentage, the rewrite is triggered. Also<br># you need to specify a minimal size for the AOF file to be rewritten, this<br># is useful to avoid rewriting the AOF file even if the percentage increase<br># is reached but it is still pretty small.<br>#<br># Specify a percentage of zero in order to disable the automatic AOF<br># rewrite feature.<br><br>auto-aof-rewrite-percentage 100<br>auto-aof-rewrite-min-size 64mb<br><br># An AOF file may be found to be truncated at the end during the Redis<br># startup process, when the AOF data gets loaded back into memory.<br># This may happen when the system where Redis is running<br># crashes, especially when an ext4 filesystem is mounted without the<br># data=ordered option (however this can’t happen when Redis itself<br># crashes or aborts but the operating system still works correctly).<br>#<br># Redis can either exit with an error when this happens, or load as much<br># data as possible (the default now) and start if the AOF file is found<br># to be truncated at the end. The following option controls this behavior.<br>#<br># If aof-load-truncated is set to yes, a truncated AOF file is loaded and<br># the Redis server starts emitting a log to inform the user of the event.<br># Otherwise if the option is set to no, the server aborts with an error<br># and refuses to start. When the option is set to no, the user requires<br># to fix the AOF file using the “redis-check-aof” utility before to restart<br># the server.<br>#<br># Note that if the AOF file will be found to be corrupted in the middle<br># the server will still exit with an error. This option only applies when<br># Redis will try to read more data from the AOF file but not enough bytes<br># will be found.<br>aof-load-truncated yes<br><br># When rewriting the AOF file, Redis is able to use an RDB preamble in the<br># AOF file for faster rewrites and recoveries. When this option is turned<br># on the rewritten AOF file is composed of two different stanzas:<br>#<br>#   [RDB file][AOF tail]<br>#<br># When loading Redis recognizes that the AOF file starts with the “REDIS”<br># string and loads the prefixed RDB file, and continues loading the AOF<br># tail.<br>aof-use-rdb-preamble yes<br><br>################################ LUA SCRIPTING  ###############################<br><br># Max execution time of a Lua script in milliseconds.<br>#<br># If the maximum execution time is reached Redis will log that a script is<br># still in execution after the maximum allowed time and will start to<br># reply to queries with an error.<br>#<br># When a long running script exceeds the maximum execution time only the<br># SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be<br># used to stop a script that did not yet called write commands. The second<br># is the only way to shut down the server in the case a write command was<br># already issued by the script but the user doesn’t want to wait for the natural<br># termination of the script.<br>#<br># Set it to 0 or a negative value for unlimited execution without warnings.<br>lua-time-limit 5000<br><br>################################ REDIS CLUSTER  ###############################<br>#<br># ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++<br># WARNING EXPERIMENTAL: Redis Cluster is considered to be stable code, however<br># in order to mark it as “mature” we need to wait for a non trivial percentage<br># of users to deploy it in production.<br># ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++<br>#<br># Normal Redis instances can’t be part of a Redis Cluster; only nodes that are<br># started as cluster nodes can. In order to start a Redis instance as a<br># cluster node enable the cluster support uncommenting the following:<br>#<br># cluster-enabled yes<br><br># Every cluster node has a cluster configuration file. This file is not<br># intended to be edited by hand. It is created and updated by Redis nodes.<br># Every Redis Cluster node requires a different cluster configuration file.<br># Make sure that instances running in the same system do not have<br># overlapping cluster configuration file names.<br>#<br># cluster-config-file nodes-6379.conf<br><br># Cluster node timeout is the amount of milliseconds a node must be unreachable<br># for it to be considered in failure state.<br># Most other internal time limits are multiple of the node timeout.<br>#<br># cluster-node-timeout 15000<br><br># A replica of a failing master will avoid to start a failover if its data<br># looks too old.<br>#<br># There is no simple way for a replica to actually have an exact measure of<br># its “data age”, so the following two checks are performed:<br>#<br># 1) If there are multiple replicas able to failover, they exchange messages<br>#    in order to try to give an advantage to the replica with the best<br>#    replication offset (more data from the master processed).<br>#    Replicas will try to get their rank by offset, and apply to the start<br>#    of the failover a delay proportional to their rank.<br>#<br># 2) Every single replica computes the time of the last interaction with<br>#    its master. This can be the last ping or command received (if the master<br>#    is still in the “connected” state), or the time that elapsed since the<br>#    disconnection with the master (if the replication link is currently down).<br>#    If the last interaction is too old, the replica will not try to failover<br>#    at all.<br>#<br># The point “2” can be tuned by user. Specifically a replica will not perform<br># the failover if, since the last interaction with the master, the time<br># elapsed is greater than:<br>#<br>#   (node-timeout <em> replica-validity-factor) + repl-ping-replica-period<br>#<br># So for example if node-timeout is 30 seconds, and the replica-validity-factor<br># is 10, and assuming a default repl-ping-replica-period of 10 seconds, the<br># replica will not try to failover if it was not able to talk with the master<br># for longer than 310 seconds.<br>#<br># A large replica-validity-factor may allow replicas with too old data to failover<br># a master, while a too small value may prevent the cluster from being able to<br># elect a replica at all.<br>#<br># For maximum availability, it is possible to set the replica-validity-factor<br># to a value of 0, which means, that replicas will always try to failover the<br># master regardless of the last time they interacted with the master.<br># (However they’ll always try to apply a delay proportional to their<br># offset rank).<br>#<br># Zero is the only value able to guarantee that when all the partitions heal<br># the cluster will always be able to continue.<br>#<br># cluster-replica-validity-factor 10<br><br># Cluster replicas are able to migrate to orphaned masters, that are masters<br># that are left without working replicas. This improves the cluster ability<br># to resist to failures as otherwise an orphaned master can’t be failed over<br># in case of failure if it has no working replicas.<br>#<br># Replicas migrate to orphaned masters only if there are still at least a<br># given number of other working replicas for their old master. This number<br># is the “migration barrier”. A migration barrier of 1 means that a replica<br># will migrate only if there is at least 1 other working replica for its master<br># and so forth. It usually reflects the number of replicas you want for every<br># master in your cluster.<br>#<br># Default is 1 (replicas migrate only if their masters remain with at least<br># one replica). To disable migration just set it to a very large value.<br># A value of 0 can be set but is useful only for debugging and dangerous<br># in production.<br>#<br># cluster-migration-barrier 1<br><br># By default Redis Cluster nodes stop accepting queries if they detect there<br># is at least an hash slot uncovered (no available node is serving it).<br># This way if the cluster is partially down (for example a range of hash slots<br># are no longer covered) all the cluster becomes, eventually, unavailable.<br># It automatically returns available as soon as all the slots are covered again.<br>#<br># However sometimes you want the subset of the cluster which is working,<br># to continue to accept queries for the part of the key space that is still<br># covered. In order to do so, just set the cluster-require-full-coverage<br># option to no.<br>#<br># cluster-require-full-coverage yes<br><br># This option, when set to yes, prevents replicas from trying to failover its<br># master during master failures. However the master can still perform a<br># manual failover, if forced to do so.<br>#<br># This is useful in different scenarios, especially in the case of multiple<br># data center operations, where we want one side to never be promoted if not<br># in the case of a total DC failure.<br>#<br># cluster-replica-no-failover no<br><br># In order to setup your cluster make sure to read the documentation<br># available at <a href="http://redis.io" target="_blank" rel="noopener">http://redis.io</a> web site.<br><br>########################## CLUSTER DOCKER/NAT support  ########################<br><br># In certain deployments, Redis Cluster nodes address discovery fails, because<br># addresses are NAT-ted or because ports are forwarded (the typical case is<br># Docker and other containers).<br>#<br># In order to make Redis Cluster working in such environments, a static<br># configuration where each node knows its public address is needed. The<br># following two options are used for this scope, and are:<br>#<br># </em> cluster-announce-ip<br># <em> cluster-announce-port<br># </em> cluster-announce-bus-port<br>#<br># Each instruct the node about its address, client port, and cluster message<br># bus port. The information is then published in the header of the bus packets<br># so that other nodes will be able to correctly map the address of the node<br># publishing the information.<br>#<br># If the above options are not used, the normal Redis Cluster auto-detection<br># will be used instead.<br>#<br># Note that when remapped, the bus port may not be at the fixed offset of<br># clients port + 10000, so you can specify any port and bus-port depending<br># on how they get remapped. If the bus-port is not set, a fixed offset of<br># 10000 will be used as usually.<br>#<br># Example:<br>#<br># cluster-announce-ip 10.1.1.5<br># cluster-announce-port 6379<br># cluster-announce-bus-port 6380<br><br>################################## SLOW LOG ###################################<br><br># The Redis Slow Log is a system to log queries that exceeded a specified<br># execution time. The execution time does not include the I/O operations<br># like talking with the client, sending the reply and so forth,<br># but just the time needed to actually execute the command (this is the only<br># stage of command execution where the thread is blocked and can not serve<br># other requests in the meantime).<br>#<br># You can configure the slow log with two parameters: one tells Redis<br># what is the execution time, in microseconds, to exceed in order for the<br># command to get logged, and the other parameter is the length of the<br># slow log. When a new command is logged the oldest one is removed from the<br># queue of logged commands.<br><br># The following time is expressed in microseconds, so 1000000 is equivalent<br># to one second. Note that a negative number disables the slow log, while<br># a value of zero forces the logging of every command.<br>slowlog-log-slower-than 10000<br><br># There is no limit to this length. Just be aware that it will consume memory.<br># You can reclaim memory used by the slow log with SLOWLOG RESET.<br>slowlog-max-len 128<br><br>################################ LATENCY MONITOR ##############################<br><br># The Redis latency monitoring subsystem samples different operations<br># at runtime in order to collect data related to possible sources of<br># latency of a Redis instance.<br>#<br># Via the LATENCY command this information is available to the user that can<br># print graphs and obtain reports.<br>#<br># The system only logs operations that were performed in a time equal or<br># greater than the amount of milliseconds specified via the<br># latency-monitor-threshold configuration directive. When its value is set<br># to zero, the latency monitor is turned off.<br>#<br># By default latency monitoring is disabled since it is mostly not needed<br># if you don’t have latency issues, and collecting data has a performance<br># impact, that while very small, can be measured under big load. Latency<br># monitoring can easily be enabled at runtime using the command<br># “CONFIG SET latency-monitor-threshold <milliseconds>“ if needed.<br>latency-monitor-threshold 0<br><br>############################# EVENT NOTIFICATION ##############################<br><br># Redis can notify Pub/Sub clients about events happening in the key space.<br># This feature is documented at <a href="http://redis.io/topics/notifications" target="_blank" rel="noopener">http://redis.io/topics/notifications</a><br>#<br># For instance if keyspace events notification is enabled, and a client<br># performs a DEL operation on key “foo” stored in the Database 0, two<br># messages will be published via Pub/Sub:<br>#<br># PUBLISH <strong>keyspace@0</strong>:foo del<br># PUBLISH <strong>keyevent@0</strong>:del foo<br>#<br># It is possible to select the events that Redis will notify among a set<br># of classes. Every class is identified by a single character:<br>#<br>#  K     Keyspace events, published with <strong>keyspace@<db></db></strong> prefix.<br>#  E     Keyevent events, published with <strong>keyevent@<db></db></strong> prefix.<br>#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, …<br>#  $     String commands<br>#  l     List commands<br>#  s     Set commands<br>#  h     Hash commands<br>#  z     Sorted set commands<br>#  x     Expired events (events generated every time a key expires)<br>#  e     Evicted events (events generated when a key is evicted for maxmemory)<br>#  A     Alias for g$lshzxe, so that the “AKE” string means all the events.<br>#<br>#  The “notify-keyspace-events” takes as argument a string that is composed<br>#  of zero or multiple characters. The empty string means that notifications<br>#  are disabled.<br>#<br>#  Example: to enable list and generic events, from the point of view of the<br>#           event name, use:<br>#<br>#  notify-keyspace-events Elg<br>#<br>#  Example 2: to get the stream of the expired keys subscribing to channel<br>#             name <strong>keyevent@0</strong>:expired use:<br>#<br>#  notify-keyspace-events Ex<br>#<br>#  By default all notifications are disabled because most users don’t need<br>#  this feature and the feature has some overhead. Note that if you don’t<br>#  specify at least one of K or E, no events will be delivered.<br>notify-keyspace-events “”<br><br>############################### ADVANCED CONFIG ###############################<br><br># Hashes are encoded using a memory efficient data structure when they have a<br># small number of entries, and the biggest entry does not exceed a given<br># threshold. These thresholds can be configured using the following directives.<br>hash-max-ziplist-entries 512<br>hash-max-ziplist-value 64<br><br># Lists are also encoded in a special way to save a lot of space.<br># The number of entries allowed per internal list node can be specified<br># as a fixed maximum size or a maximum number of elements.<br># For a fixed maximum size, use -5 through -1, meaning:<br># -5: max size: 64 Kb  &lt;– not recommended for normal workloads<br># -4: max size: 32 Kb  &lt;– not recommended<br># -3: max size: 16 Kb  &lt;– probably not recommended<br># -2: max size: 8 Kb   &lt;– good<br># -1: max size: 4 Kb   &lt;– good<br># Positive numbers mean store up to <em>exactly</em> that number of elements<br># per list node.<br># The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),<br># but if your use case is unique, adjust the settings as necessary.<br>list-max-ziplist-size -2<br><br># Lists may also be compressed.<br># Compress depth is the number of quicklist ziplist nodes from <em>each</em> side of<br># the list to <em>exclude</em> from compression.  The head and tail of the list<br># are always uncompressed for fast push/pop operations.  Settings are:<br># 0: disable all list compression<br># 1: depth 1 means “don’t start compressing until after 1 node into the list,<br>#    going from either the head or tail”<br>#    So: [head]-&gt;node-&gt;node-&gt;…-&gt;node-&gt;[tail]<br>#    [head], [tail] will always be uncompressed; inner nodes will compress.<br># 2: [head]-&gt;[next]-&gt;node-&gt;node-&gt;…-&gt;node-&gt;[prev]-&gt;[tail]<br>#    2 here means: don’t compress head or head-&gt;next or tail-&gt;prev or tail,<br>#    but compress all nodes between them.<br># 3: [head]-&gt;[next]-&gt;[next]-&gt;node-&gt;node-&gt;…-&gt;node-&gt;[prev]-&gt;[prev]-&gt;[tail]<br># etc.<br>list-compress-depth 0<br><br># Sets have a special encoding in just one case: when a set is composed<br># of just strings that happen to be integers in radix 10 in the range<br># of 64 bit signed integers.<br># The following configuration setting sets the limit in the size of the<br># set in order to use this special memory saving encoding.<br>set-max-intset-entries 512<br><br># Similarly to hashes and lists, sorted sets are also specially encoded in<br># order to save a lot of space. This encoding is only used when the length and<br># elements of a sorted set are below the following limits:<br>zset-max-ziplist-entries 128<br>zset-max-ziplist-value 64<br><br># HyperLogLog sparse representation bytes limit. The limit includes the<br># 16 bytes header. When an HyperLogLog using the sparse representation crosses<br># this limit, it is converted into the dense representation.<br>#<br># A value greater than 16000 is totally useless, since at that point the<br># dense representation is more memory efficient.<br>#<br># The suggested value is ~ 3000 in order to have the benefits of<br># the space efficient encoding without slowing down too much PFADD,<br># which is O(N) with the sparse encoding. The value can be raised to<br># ~ 10000 when CPU is not a concern, but space is, and the data set is<br># composed of many HyperLogLogs with cardinality in the 0 - 15000 range.<br>hll-sparse-max-bytes 3000<br><br># Streams macro node max size / items. The stream data structure is a radix<br># tree of big nodes that encode multiple items inside. Using this configuration<br># it is possible to configure how big a single node can be in bytes, and the<br># maximum number of items it may contain before switching to a new node when<br># appending new stream entries. If any of the following settings are set to<br># zero, the limit is ignored, so for instance it is possible to set just a<br># max entires limit by setting max-bytes to 0 and max-entries to the desired<br># value.<br>stream-node-max-bytes 4096<br>stream-node-max-entries 100<br><br># Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in<br># order to help rehashing the main Redis hash table (the one mapping top-level<br># keys to values). The hash table implementation Redis uses (see dict.c)<br># performs a lazy rehashing: the more operation you run into a hash table<br># that is rehashing, the more rehashing “steps” are performed, so if the<br># server is idle the rehashing is never complete and some more memory is used<br># by the hash table.<br>#<br># The default is to use this millisecond 10 times every second in order to<br># actively rehash the main dictionaries, freeing memory when possible.<br>#<br># If unsure:<br># use “activerehashing no” if you have hard latency requirements and it is<br># not a good thing in your environment that Redis can reply from time to time<br># to queries with 2 milliseconds delay.<br>#<br># use “activerehashing yes” if you don’t have such hard requirements but<br># want to free memory asap when possible.<br>activerehashing yes<br><br># The client output buffer limits can be used to force disconnection of clients<br># that are not reading data from the server fast enough for some reason (a<br># common reason is that a Pub/Sub client can’t consume messages as fast as the<br># publisher can produce them).<br>#<br># The limit can be set differently for the three different classes of clients:<br>#<br># normal -&gt; normal clients including MONITOR clients<br># replica  -&gt; replica clients<br># pubsub -&gt; clients subscribed to at least one pubsub channel or pattern<br>#<br># The syntax of every client-output-buffer-limit directive is the following:<br>#<br># client-output-buffer-limit <class> <hard limit=""> <soft limit=""> <soft seconds=""><br>#<br># A client is immediately disconnected once the hard limit is reached, or if<br># the soft limit is reached and remains reached for the specified number of<br># seconds (continuously).<br># So for instance if the hard limit is 32 megabytes and the soft limit is<br># 16 megabytes / 10 seconds, the client will get disconnected immediately<br># if the size of the output buffers reach 32 megabytes, but will also get<br># disconnected if the client reaches 16 megabytes and continuously overcomes<br># the limit for 10 seconds.<br>#<br># By default normal clients are not limited because they don’t receive data<br># without asking (in a push way), but just after a request, so only<br># asynchronous clients may create a scenario where data is requested faster<br># than it can read.<br>#<br># Instead there is a default limit for pubsub and replica clients, since<br># subscribers and replicas receive data in a push fashion.<br>#<br># Both the hard or the soft limit can be disabled by setting them to zero.<br>client-output-buffer-limit normal 0 0 0<br>client-output-buffer-limit replica 256mb 64mb 60<br>client-output-buffer-limit pubsub 32mb 8mb 60<br><br># Client query buffers accumulate new commands. They are limited to a fixed<br># amount by default in order to avoid that a protocol desynchronization (for<br># instance due to a bug in the client) will lead to unbound memory usage in<br># the query buffer. However you can configure it here if you have very special<br># needs, such us huge multi/exec requests or alike.<br>#<br># client-query-buffer-limit 1gb<br><br># In the Redis protocol, bulk requests, that are, elements representing single<br># strings, are normally limited ot 512 mb. However you can change this limit<br># here.<br>#<br># proto-max-bulk-len 512mb<br><br># Redis calls an internal function to perform many background tasks, like<br># closing connections of clients in timeout, purging expired keys that are<br># never requested, and so forth.<br>#<br># Not all tasks are performed with the same frequency, but Redis checks for<br># tasks to perform according to the specified “hz” value.<br>#<br># By default “hz” is set to 10. Raising the value will use more CPU when<br># Redis is idle, but at the same time will make Redis more responsive when<br># there are many keys expiring at the same time, and timeouts may be<br># handled with more precision.<br>#<br># The range is between 1 and 500, however a value over 100 is usually not<br># a good idea. Most users should use the default of 10 and raise this up to<br># 100 only in environments where very low latency is required.<br>hz 10<br><br># Normally it is useful to have an HZ value which is proportional to the<br># number of clients connected. This is useful in order, for instance, to<br># avoid too many clients are processed for each background task invocation<br># in order to avoid latency spikes.<br>#<br># Since the default HZ value by default is conservatively set to 10, Redis<br># offers, and enables by default, the ability to use an adaptive HZ value<br># which will temporary raise when there are many connected clients.<br>#<br># When dynamic HZ is enabled, the actual configured HZ will be used as<br># as a baseline, but multiples of the configured HZ value will be actually<br># used as needed once more clients are connected. In this way an idle<br># instance will use very little CPU time while a busy instance will be<br># more responsive.<br>dynamic-hz yes<br><br># When a child rewrites the AOF file, if the following option is enabled<br># the file will be fsync-ed every 32 MB of data generated. This is useful<br># in order to commit the file to the disk more incrementally and avoid<br># big latency spikes.<br>aof-rewrite-incremental-fsync yes<br><br># When redis saves RDB file, if the following option is enabled<br># the file will be fsync-ed every 32 MB of data generated. This is useful<br># in order to commit the file to the disk more incrementally and avoid<br># big latency spikes.<br>rdb-save-incremental-fsync yes<br><br># Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good<br># idea to start with the default settings and only change them after investigating<br># how to improve the performances and how the keys LFU change over time, which<br># is possible to inspect via the OBJECT FREQ command.<br>#<br># There are two tunable parameters in the Redis LFU implementation: the<br># counter logarithm factor and the counter decay time. It is important to<br># understand what the two parameters mean before changing them.<br>#<br># The LFU counter is just 8 bits per key, it’s maximum value is 255, so Redis<br># uses a probabilistic increment with logarithmic behavior. Given the value<br># of the old counter, when a key is accessed, the counter is incremented in<br># this way:<br>#<br># 1. A random number R between 0 and 1 is extracted.<br># 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).<br># 3. The counter is incremented only if R &lt; P.<br>#<br># The default lfu-log-factor is 10. This is a table of how the frequency<br># counter changes with a different number of accesses with different<br># logarithmic factors:<br>#<br># +——–+————+————+————+————+————+<br># | factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |<br># +——–+————+————+————+————+————+<br># | 0      | 104        | 255        | 255        | 255        | 255        |<br># +——–+————+————+————+————+————+<br># | 1      | 18         | 49         | 255        | 255        | 255        |<br># +——–+————+————+————+————+————+<br># | 10     | 10         | 18         | 142        | 255        | 255        |<br># +——–+————+————+————+————+————+<br># | 100    | 8          | 11         | 49         | 143        | 255        |<br># +——–+————+————+————+————+————+<br>#<br># NOTE: The above table was obtained by running the following commands:<br>#<br>#   redis-benchmark -n 1000000 incr foo<br>#   redis-cli object freq foo<br>#<br># NOTE 2: The counter initial value is 5 in order to give new objects a chance<br># to accumulate hits.<br>#<br># The counter decay time is the time, in minutes, that must elapse in order<br># for the key counter to be divided by two (or decremented if it has a value<br># less &lt;= 10).<br>#<br># The default value for the lfu-decay-time is 1. A Special value of 0 means to<br># decay the counter every time it happens to be scanned.<br>#<br># lfu-log-factor 10<br># lfu-decay-time 1<br><br>########################### ACTIVE DEFRAGMENTATION #######################<br>#<br># WARNING THIS FEATURE IS EXPERIMENTAL. However it was stress tested<br># even in production and manually tested by multiple engineers for some<br># time.<br>#<br># What is active defragmentation?<br># ——————————-<br>#<br># Active (online) defragmentation allows a Redis server to compact the<br># spaces left between small allocations and deallocations of data in memory,<br># thus allowing to reclaim back memory.<br>#<br># Fragmentation is a natural process that happens with every allocator (but<br># less so with Jemalloc, fortunately) and certain workloads. Normally a server<br># restart is needed in order to lower the fragmentation, or at least to flush<br># away all the data and create it again. However thanks to this feature<br># implemented by Oran Agra for Redis 4.0 this process can happen at runtime<br># in an “hot” way, while the server is running.<br>#<br># Basically when the fragmentation is over a certain level (see the<br># configuration options below) Redis will start to create new copies of the<br># values in contiguous memory regions by exploiting certain specific Jemalloc<br># features (in order to understand if an allocation is causing fragmentation<br># and to allocate it in a better place), and at the same time, will release the<br># old copies of the data. This process, repeated incrementally for all the keys<br># will cause the fragmentation to drop back to normal values.<br>#<br># Important things to understand:<br>#<br># 1. This feature is disabled by default, and only works if you compiled Redis<br>#    to use the copy of Jemalloc we ship with the source code of Redis.<br>#    This is the default with Linux builds.<br>#<br># 2. You never need to enable this feature if you don’t have fragmentation<br>#    issues.<br>#<br># 3. Once you experience fragmentation, you can enable this feature when<br>#    needed with the command “CONFIG SET activedefrag yes”.<br>#<br># The configuration parameters are able to fine tune the behavior of the<br># defragmentation process. If you are not sure about what they mean it is<br># a good idea to leave the defaults untouched.<br><br># Enabled active defragmentation<br># activedefrag yes<br><br># Minimum amount of fragmentation waste to start active defrag<br># active-defrag-ignore-bytes 100mb<br><br># Minimum percentage of fragmentation to start active defrag<br># active-defrag-threshold-lower 10<br><br># Maximum percentage of fragmentation at which we use maximum effort<br># active-defrag-threshold-upper 100<br><br># Minimal effort for defrag in CPU percentage<br># active-defrag-cycle-min 5<br><br># Maximal effort for defrag in CPU percentage<br># active-defrag-cycle-max 75<br><br># Maximum number of set/hash/zset/list fields that will be processed from<br># the main dictionary scan<br># active-defrag-max-scan-fields 1000<br>–&gt;
</soft></soft></hard></class></milliseconds></bytes></password></master-password></masterport></masterip>  
	</div>
		<div style="padding: 10px 44px 30px 44px;" >
<div style="border: 1px dashed #e0e0e0; padding: 10px 10px 10px 10px; background-color: #fffeee; background-repeat: no-repeat; background-attachment: scroll; background-position: 1% 50%; -moz-background-size: auto auto; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;">
<div style="float:left;margin-top:0px;">
<img src="/img/weixin.jpg" width="125px" height="125px" style="border:1px solid #ccc; margin: 6px 5px 0px 0px"/>
</div>
<div>
 <p style="margin-top:0px;">作者署名：<b><a target="_blank" href="http://researchlab.github.io/">朴实的一线攻城狮</a></b>
<br />本文标题：<b><a href="/2018/10/26/redis-22-configuration/" target="_blank" title="redis-22-configuration">redis-22-configuration</a></b> 
<br />本文出处：<b><a href="/2018/10/26/redis-22-configuration/" target="_blank" title="redis-22-configuration">http://researchlab.github.io/2018/10/26/redis-22-configuration/</a></b>
<br />版权声明：本文由<b><a href="/about" target="_blank" title="Lee Hong">Lee Hong</a></b>创作和发表,采用<b>署名(BY)</b>-<b>非商业性使用(NC)</b>-<b>相同方式共享(SA)</b>国际许可协议进行许可,转载请注明作者及出处, 否则保留追究法律责任的权利。 </p>
</div>
</div>
</div>

   	       
		<footer class="article-footer clearfix">
<div class="article-catetags">


</div>



	<div class="article-share" id="share">
	
	<div class="share-jiathis">
	  
<div class="jiathis_style_24x24">
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_tqq"></a>
	<a class="jiathis_button_qzone"></a>
    <a class="jiathis_button_googleplus"></a>
	<a class="jiathis_button_douban"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
    var jiathis_config={
    data_track_clickback:true,
    sm:"copy,renren,cqq",
    pic:"",
    summary:"",
    
  </script> 
<script type="text/javascript" src="//v3.jiathis.com/code/jia.js?uid=
2084050" charset="utf-8"></script>      


	 </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2018/11/07/mysql-16-transaction-isolation-level-and-acid-review/" title="mysql专题16 事务隔离级别及ACID知识回顾">
  <strong>上一篇：</strong><br/>
  <span>
  mysql专题16 事务隔离级别及ACID知识回顾</span>
</a>
</div>


<div class="next">
<a href="/2018/10/15/redis-17-replication/"  title="redis专题17 主从同步系列问题">
 <strong>下一篇：</strong><br/> 
 <span>redis专题17 主从同步系列问题
</span>
</a>
</div>

</nav>

	
<!-- gitment评论框 start -->
	<div id="gitment" class="ds-thread"></div>
	<link rel="stylesheet" href="https://github.com/researchlab/gitment/blob/master/style/default.css">
	<script src="https://github.com/researchlab/gitment/blob/master/dist/gitment.browser.js"></script>
	<script>
	  var gitment = new Gitment({
	    id: 'lFri Oct 26 2018 14:06:46 GMT+0800', // 可选。建议为Fri Oct 26 2018 14:06:46 GMT+0800
	    owner: 'researchlab', // 可以是你的GitHub用户名，也可以是github id
	    repo: 'researchlab.github.io', //可以是你的任意一个repo，推荐使用githubpage所在的repo
	    oauth: {
	      client_id: 'e4971ec4c4fdbefb392f',
	      client_secret: 'e5001b2dda2dcb9a9c66417991be57836c17a72b',
	    },
	  })
	  gitment.render('gitment')
</script>


</div>  

      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>
<div id="asidepart">

  <div class="widget tag">
<!--<hr noshade color="#ccc">-->
<!-- <p style="text-align:center">Mike.Lee</p> -->
<p margin="0" style="text-align:center">
<a class="ahref" href="http://researchlab.github.io/about/">
<img id="aboutpic"  src="/img/qzly.png" alt="@一线攻城狮" height="200" width="200" style="box-shadow: 0px 0px 2px 2px #9edeff;border-radius: 8px;" >
</a></p>
<p style="text-align:center"><font size="2" color="grey">关注微信公众号 @一线攻城狮</font></p>
<div style="display:block; margin-top:10px; padding: 0px 4px 4px 0; border-top: dashed 1px #ccc; text-align:left;"></div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div style="float:left;position:absolute;"><font size="2" >总访问:<span id="busuanzi_value_site_pv"></span>次</font></div>
<div style="float:right;"><font size="2" >总访客:<span id="busuanzi_value_site_uv"></span>人</font></div>

<div style="margin-top:30px; padding: 5px 4px 4px 0; border-top: dashed 1px #ccc; text-align:left;"></div>
</div>



  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
		  
			<li><a href="/categories/DevOps/" title="DevOps">DevOps<sup>13</sup></a></li>
		  
		
		  
			<li><a href="/categories/Hexo/" title="Hexo">Hexo<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/MQ/" title="MQ">MQ<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/algorithm/" title="algorithm">algorithm<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/docker-practice/" title="docker-practice">docker-practice<sup>8</sup></a></li>
		  
		
		  
			<li><a href="/categories/go-bootcamp/" title="go-bootcamp">go-bootcamp<sup>6</sup></a></li>
		  
		
		  
			<li><a href="/categories/go-pattern/" title="go-pattern">go-pattern<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/golang/" title="golang">golang<sup>23</sup></a></li>
		  
		
		  
			<li><a href="/categories/java/" title="java">java<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/javascript/" title="javascript">javascript<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/k8s/" title="k8s">k8s<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/mysql专题/" title="mysql专题">mysql专题<sup>16</sup></a></li>
		  
		
		  
			<li><a href="/categories/php/" title="php">php<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/redis专题/" title="redis专题">redis专题<sup>17</sup></a></li>
		  
		
		</ul>
</div>



  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/golang/" title="golang">golang<sup>26</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>18</sup></a></li>
			
		
			
				<li><a href="/tags/redis/" title="redis">redis<sup>17</sup></a></li>
			
		
			
				<li><a href="/tags/docker/" title="docker">docker<sup>9</sup></a></li>
			
		
			
				<li><a href="/tags/setcookie/" title="setcookie">setcookie<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/tcp/" title="tcp">tcp<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/cache/" title="cache">cache<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/concurrency/" title="concurrency">concurrency<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Hexo/" title="Hexo">Hexo<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Blog/" title="Blog">Blog<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/minikube/" title="minikube">minikube<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/cloud-computing/" title="cloud computing">cloud computing<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/rpc/" title="rpc">rpc<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/getcookie/" title="getcookie">getcookie<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/ticker/" title="ticker">ticker<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/cache-invalid/" title="cache-invalid">cache-invalid<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/vendoring/" title="vendoring">vendoring<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/godep/" title="godep">godep<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/govendor/" title="govendor">govendor<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/glide/" title="glide">glide<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="http://blog.csdn.net/xiaolongwang2010" target="_blank" title="小龙王2010csdn技术博客">Linux/c/c++</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <iframe width="100%" height="550" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=1&ptype=1&speed=0&skin=1&isTitle=1&noborder=1&isWeibo=1&isFans=1&uid=5141203275&verifier=a533edf5&dpc=1"></iframe>


</aside>
</div>

    </div>
    <footer><div id="footer" >
	
	
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/researchlab/lightman" target="_blank" title="lightman">lightman</a> ©2016 - 2021 
		
		<a href="/about" target="_blank" title="Lee Hong">Lee Hong</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>




<script type="text/javascript">
  var duoshuoQuery = {short_name:"gamedp"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 







<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
</html>
