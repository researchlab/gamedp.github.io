<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>一线攻城狮</title>
  
  <subtitle>十年磨一剑，一步一步脚踏实地的耕种</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://researchlab.github.io/"/>
  <updated>2018-11-09T01:39:38.574Z</updated>
  <id>http://researchlab.github.io/</id>
  
  <author>
    <name>Lee Hong</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>从生产者消费者模型深入学习golang channel</title>
    <link href="http://researchlab.github.io/2018/11/08/producer-consumer-go-channel/"/>
    <id>http://researchlab.github.io/2018/11/08/producer-consumer-go-channel/</id>
    <published>2018-11-08T19:53:14.000Z</published>
    <updated>2018-11-09T01:39:38.574Z</updated>
    
    <content type="html"><![CDATA[<p>从生产者消费者模型探究回顾golang channel注意事项; 实例探究no buffer及buffer channel;<br><a id="more"></a></p><h2 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h2><p>golang channel 分为无缓冲channel及缓冲channel, 具体体现在创建channel时是否制定channel size, </p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//no buffer channel</span></span><br><span class="line">ch := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//buffer channel</span></span><br><span class="line">ch := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span> bufSize)</span><br></pre></td></tr></table></figure><ul><li>无缓冲channel 默认channel大小为1, 写入一个值后需要被读取之后才能继续写入, 否则写阻塞;</li><li>缓冲channel 的大小是初始时的bufSize, 可连续写入bufSize值, 然后等待读取, 当len(channel) &lt; bufSize时才可以继续写入, 否则写阻塞;</li><li>channel 中没有值时 则读阻塞;</li><li>channel 常用在同步, pipe, 无锁设计等场景中;</li></ul><h3 id="写值"><a href="#写值" class="headerlink" title="写值"></a>写值</h3><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ch &lt;- in</span><br></pre></td></tr></table></figure><ul><li>非写阻塞时可以写入值;</li></ul><h3 id="读值"><a href="#读值" class="headerlink" title="读值"></a>读值</h3><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">out := &lt;-ch </span><br><span class="line"></span><br><span class="line">out, ok := &lt;- ch</span><br></pre></td></tr></table></figure><ul><li>非读阻塞时可以读取值;</li><li>当ok 为false时, 表示channel已被关闭;</li></ul><h3 id="关闭"><a href="#关闭" class="headerlink" title="关闭"></a>关闭</h3><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">close</span>(ch)</span><br></pre></td></tr></table></figure><ul><li>只要当写channel写入完毕后则应立即关闭channel; 而读channel则可以不需要处理;</li></ul><blockquote><p>更多参考<a href="https://tour.golang.org/concurrency/4" target="_blank" rel="noopener">Range and close</a></p></blockquote><h3 id="for循环读"><a href="#for循环读" class="headerlink" title="for循环读"></a>for循环读</h3><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x := <span class="keyword">range</span> ch &#123;</span><br><span class="line">        <span class="comment">//do something with x</span></span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><ul><li>当使用for range 从管道读取数据的时候，管道没有数据，那么循环会阻塞，只有当管道被关闭的时候，for 循环才会结束</li></ul><h2 id="生产者消费者模型"><a href="#生产者消费者模型" class="headerlink" title="生产者消费者模型"></a>生产者消费者模型</h2><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//producer_consumer.go</span></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">N = <span class="number">100000</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Producer</span><span class="params">(out <span class="keyword">chan</span>&lt;- <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">1</span>; i &lt; N; i++ &#123;</span><br><span class="line">out &lt;- i</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">close</span>(out)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Consumer</span><span class="params">(in &lt;-<span class="keyword">chan</span> <span class="keyword">int</span>, out <span class="keyword">chan</span>&lt;- <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> x := <span class="keyword">range</span> in &#123;</span><br><span class="line">out &lt;- x</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">close</span>(out)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试case </p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//producer_consumer_test.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">producerconsumer</span><span class="params">(in <span class="keyword">chan</span> <span class="keyword">int</span>, out <span class="keyword">chan</span> <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">go</span> Producer(in)</span><br><span class="line"><span class="keyword">go</span> Consumer(in, out)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x := <span class="keyword">range</span> out &#123;</span><br><span class="line">_ = x</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestNoBufferChan</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">in, out := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>), <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line">producerconsumer(in, out)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestBufferChan</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">bufLen := <span class="number">100</span></span><br><span class="line">in, out := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, bufLen), <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, bufLen)</span><br><span class="line">producerconsumer(in, out)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">BenchmarkNoBufferChan</span><span class="params">(b *testing.B)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; b.N; i++ &#123;</span><br><span class="line">in, out := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>), <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line">producerconsumer(in, out)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">BenchmarkBufferChan</span><span class="params">(b *testing.B)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; b.N; i++ &#123;</span><br><span class="line">bufLen := <span class="number">100</span></span><br><span class="line">in, out := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, bufLen), <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, bufLen)</span><br><span class="line">producerconsumer(in, out)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>output </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">➜  make bench</span><br><span class="line">[Benchmark] running Benchmark</span><br><span class="line">=== RUN   TestCloseWriteChanException</span><br><span class="line">--- PASS: TestCloseWriteChanException (2.01s)</span><br><span class="line">=== RUN   TestCloseReadChanException</span><br><span class="line">--- PASS: TestCloseReadChanException (1.00s)</span><br><span class="line">=== RUN   TestNoBufferChan</span><br><span class="line">--- PASS: TestNoBufferChan (0.09s)</span><br><span class="line">=== RUN   TestBufferChan</span><br><span class="line">--- PASS: TestBufferChan (0.02s)</span><br><span class="line">goos: darwin</span><br><span class="line">goarch: amd64</span><br><span class="line">pkg: github.com/researchlab/experiments/channel</span><br><span class="line">BenchmarkNoBufferChan-8         20  84429085 ns/op</span><br><span class="line">BenchmarkBufferChan-8           50  22295688 ns/op</span><br><span class="line">PASS</span><br><span class="line">ok  github.com/researchlab/experiments/channel6.045s</span><br></pre></td></tr></table></figure><p>更多分析及完整源码可参见 <a href="https://github.com/researchlab/experiments/tree/master/channel" target="_blank" rel="noopener">github-channel</a></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>回顾了channel两种类型(no buffer/buffer channel);</li><li>只有写channel需要close, 而读channel 则可以不需要关心; 需要注意channel 在多个goroutine中的close问题;</li><li>channel 是非常常用的一种结果, 常见于业务同步, buffer pipe, timeout, 无锁设计等场景中; </li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从生产者消费者模型探究回顾golang channel注意事项; 实例探究no buffer及buffer channel;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="golang" scheme="http://researchlab.github.io/categories/golang/"/>
    
    
      <category term="golang" scheme="http://researchlab.github.io/tags/golang/"/>
    
      <category term="channel" scheme="http://researchlab.github.io/tags/channel/"/>
    
  </entry>
  
  <entry>
    <title>mysql专题16 事务隔离级别及ACID知识回顾</title>
    <link href="http://researchlab.github.io/2018/11/07/mysql-16-transaction-isolation-level-and-acid-review/"/>
    <id>http://researchlab.github.io/2018/11/07/mysql-16-transaction-isolation-level-and-acid-review/</id>
    <published>2018-11-07T19:10:48.000Z</published>
    <updated>2018-11-09T01:39:38.570Z</updated>
    
    <content type="html"><![CDATA[<p>事务指的是满足<code>ACID</code>特性的一组操作,<code>mysql</code>中可以通过<code>commit</code>提交一个事务,也可以使用<code>rollback</code>进行回滚。 在并发场景中很难保证事务的<code>Isolation</code>特性, 即无法保证临界资源的排它性操作, 从而引发数据一致性问题, 临界资源互斥问题显然需要借助加锁来解决, 在并发事务中就需要用锁的并发控制来处理;<br><a id="more"></a><br>根据在事务处理中对临界资源加锁及释放锁的阶段不同,可分为三种加锁方式, 即<code>mysql</code>的<code>三级封锁协议</code>, <code>三级封锁协议</code>可分别解决数据丢失, 脏读, 不可重复读问题,即<code>mysql</code>事务隔离级别的读未提交, 读已提交, 可重读; </p><p>此外还有第四种隔离级别, 即事务串行化, 即把并行转换为串行; 下文将通过实际案例分析精要回顾事务及事务隔离级别等相关知识; </p><blockquote><p> 实际情况下, 在读已提交及可重读读两中隔离级别下, <code>mysql</code>/Oracle/PgSQL等是利用MVCC来处理事务，防止加锁，来提高访问效率;</p></blockquote><h2 id="事务命令"><a href="#事务命令" class="headerlink" title="事务命令"></a>事务命令</h2><h3 id="查看当前隔离级别"><a href="#查看当前隔离级别" class="headerlink" title="查看当前隔离级别"></a>查看当前隔离级别</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">dev@testdb&gt;show variables like '%iso%';</span><br><span class="line">+<span class="comment">-----------------------+-----------------+</span></span><br><span class="line">| Variable_name         | Value           |</span><br><span class="line">+<span class="comment">-----------------------+-----------------+</span></span><br><span class="line">| transaction_isolation | REPEATABLE-READ |</span><br><span class="line">+<span class="comment">-----------------------+-----------------+</span></span><br><span class="line"></span><br><span class="line">dev@testdb&gt;select @@transaction_isolation;</span><br><span class="line">+<span class="comment">-------------------------+</span></span><br><span class="line">| @@transaction_isolation |</span><br><span class="line">+<span class="comment">-------------------------+</span></span><br><span class="line">| REPEATABLE-READ         |</span><br><span class="line">+<span class="comment">-------------------------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><h3 id="设置事务隔离级别"><a href="#设置事务隔离级别" class="headerlink" title="设置事务隔离级别"></a>设置事务隔离级别</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dev@testdb&gt;set transaction isolation level repeatable read;</span><br><span class="line">dev@testdb&gt;set transaction_isolation='read-uncommitted';</span><br><span class="line">dev@testdb&gt;set transaction_isolation='read-committed';</span><br><span class="line">dev@testdb&gt;set transaction_isolation='serializable';</span><br><span class="line">dev@testdb&gt;set transaction_isolation='repeatable-read';</span><br></pre></td></tr></table></figure><h3 id="查看系统锁情况"><a href="#查看系统锁情况" class="headerlink" title="查看系统锁情况"></a>查看系统锁情况</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dev@testdb&gt;show status like 'innodb_row_lock%';</span><br><span class="line">+<span class="comment">-------------------------------+-------+</span></span><br><span class="line">| Variable_name                 | Value |</span><br><span class="line">+<span class="comment">-------------------------------+-------+</span></span><br><span class="line">| Innodb_row_lock_current_waits | 0     |</span><br><span class="line">| Innodb_row_lock_time          | 0     |</span><br><span class="line">| Innodb_row_lock_time_avg      | 0     |</span><br><span class="line">| Innodb_row_lock_time_max      | 0     |</span><br><span class="line">| Innodb_row_lock_waits         | 0     |</span><br><span class="line">+<span class="comment">-------------------------------+-------+</span></span><br><span class="line">5 rows in <span class="keyword">set</span> (<span class="number">0.04</span> sec)</span><br></pre></td></tr></table></figure><ul><li>查看当前系统锁的情况, 当系统锁争用比较严重的时候, <code>Innodb_row_lock_waits</code>和<code>Innodb_row_lock_time_avg</code>的值会比较高;</li></ul><h3 id="事务提交及回滚"><a href="#事务提交及回滚" class="headerlink" title="事务提交及回滚"></a>事务提交及回滚</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">commit, rollback用来确保数据库有足够的剩余空间;</span></span><br><span class="line"><span class="comment">commit,rollback只能用于DML操作, 即insert、update、delet;</span></span><br><span class="line"><span class="comment">rollback操作撤销上一个commit、rollback之后的事务。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">test</span></span><br><span class="line">(</span><br><span class="line"> PROD_ID <span class="built_in">varchar</span>(<span class="number">10</span>) <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line"> PROD_DESC <span class="built_in">varchar</span>(<span class="number">25</span>)  <span class="literal">null</span>,</span><br><span class="line"> <span class="keyword">COST</span> <span class="built_in">decimal</span>(<span class="number">6</span>,<span class="number">2</span>)  <span class="literal">null</span></span><br><span class="line">);</span><br><span class="line"> </span><br><span class="line"><span class="comment">/*禁止自动提交*/</span></span><br><span class="line"><span class="keyword">set</span> autocommit=<span class="number">0</span>;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/*设置事务特性,必须在所有事务开始前设置*/</span></span><br><span class="line"><span class="keyword">set</span> <span class="keyword">transaction</span> <span class="keyword">read</span> <span class="keyword">only</span>;  <span class="comment">/*设置事务只读*/</span></span><br><span class="line"><span class="keyword">set</span> <span class="keyword">transaction</span> <span class="keyword">read</span> write;  <span class="comment">/*设置事务可读、写*/</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">/*开始一次事务*/</span></span><br><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">test</span> <span class="keyword">values</span>(<span class="string">'4456'</span>,<span class="string">'mr right'</span>,<span class="number">46.97</span>);</span><br><span class="line"><span class="keyword">commit</span>;     <span class="comment">/*位置1*/</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">test</span> <span class="keyword">values</span>(<span class="string">'3345'</span>,<span class="string">'mr wrong'</span>,<span class="number">54.90</span>);</span><br><span class="line"><span class="keyword">rollback</span>;    <span class="comment">/*回到位置1,(位置2);上次commit处*/</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">test</span> <span class="keyword">values</span>(<span class="string">'1111'</span>,<span class="string">'mr wan'</span>,<span class="number">89.76</span>);</span><br><span class="line"><span class="keyword">rollback</span>;    <span class="comment">/*回到位置2,上次rollback处*/</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">/*测试保存点savepoint*/</span></span><br><span class="line"><span class="keyword">savepoint</span> point1;</span><br><span class="line"><span class="keyword">update</span> <span class="keyword">test</span></span><br><span class="line"><span class="keyword">set</span> PROD_ID=<span class="number">1</span>;</span><br><span class="line"><span class="keyword">rollback</span> <span class="keyword">to</span> point1;  <span class="comment">/*回到保存点point1*/</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">release</span> <span class="keyword">savepoint</span> point1; <span class="comment">/*删除保存点*/</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">test</span>;</span><br></pre></td></tr></table></figure><h2 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h2><h3 id="原子性-Atomicity"><a href="#原子性-Atomicity" class="headerlink" title="原子性(Atomicity)"></a><strong>原子性(Atomicity)</strong></h3><p>原子性是指事务包含的所有操作要么全部成功,要么全部失败回滚。失败回滚的操作事务,将不能对事务有任何影响。</p><h3 id="一致性-Consistency"><a href="#一致性-Consistency" class="headerlink" title="一致性(Consistency)"></a><strong>一致性(Consistency)</strong></h3><p>一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态,也就是说一个事务执行之前和执行之后都必须处于一致性状态。<br>例如: A和B进行转账操作,A有200块钱,B有300块钱;当A转了100块钱给B之后,他们2个人的总额还是500块钱,不会改变。</p><h3 id="隔离性-Isolation"><a href="#隔离性-Isolation" class="headerlink" title="隔离性(Isolation)"></a><strong>隔离性(Isolation)</strong></h3><p>隔离性是指当多个用户并发访问数据库时,比如同时访问一张表,数据库每一个用户开启的事务,不能被其他事务所做的操作干扰(也就是事务之间的隔离),<font color="red">多个并发事务之间,应当相互隔离</font>。<br>例如:同时有T1和T2两个并发事务,从T1角度来看,T2要不在T1执行之前就已经结束,要么在T1执行完成后才开始。将多个事务隔离开,每个事务都不能访问到其他事务操作过程中的状态;就好比上锁操作,只有一个事务做完了,另外一个事务才能执行。</p><h3 id="持久性-Durability"><a href="#持久性-Durability" class="headerlink" title="持久性(Durability)"></a><strong>持久性(Durability)</strong></h3><p>持久性是指事务的操作,一旦提交,对于数据库中数据的改变是永久性的,即使数据库发生故障也不能丢失已提交事务所完成的改变。</p><h2 id="隔离级别"><a href="#隔离级别" class="headerlink" title="隔离级别"></a>隔离级别</h2><h3 id="未提交读-READ-UNCOMMITTED"><a href="#未提交读-READ-UNCOMMITTED" class="headerlink" title="未提交读(READ UNCOMMITTED)"></a><strong>未提交读(READ UNCOMMITTED)</strong></h3><p>不存在事务隔离级别的时, 会造成数据丢失问题,<br><img src="/2018/11/07/mysql-16-transaction-isolation-level-and-acid-review/ru0.png" alt=""><br>很明显的看出,旺财对A添加的20块不翼而飞了,这就是”数据丢失”,对事务不加任何锁(不存在事务隔离),就会导致这种问题。</p><p>未提交读事务隔离级别,<br>未提交事务隔离级别满足<font color="red">一级封锁协议, 即写数据的时候添加一个X锁(排他锁),也就是在写数据的时候不允许其他事务进行写操作,但是读不受限制,读不加锁</font>。<br><img src="/2018/11/07/mysql-16-transaction-isolation-level-and-acid-review/ru1.png" alt=""><br>这样就可以解决了多个人一起写数据而导致了”数据丢失”的问题,但是会引发新的问题——脏读。</p><p><font color="red">脏读:读取了别人未提交的数据</font>。<br><img src="/2018/11/07/mysql-16-transaction-isolation-level-and-acid-review/ru2.png" alt=""><br>因而引入了另外一个事务隔离级别——读已提交,</p><h3 id="读已提交-READ-COMMITTED"><a href="#读已提交-READ-COMMITTED" class="headerlink" title="读已提交(READ COMMITTED)"></a><strong>读已提交(READ COMMITTED)</strong></h3><p>读已提交满足<font color="red">二级封锁协议, 即写数据的时候加上X锁(排他锁),读数据的时候添加S锁(共享锁),且如果一个数据加了X锁就没法加S锁;同理如果加了S锁就没法加X锁,但是一个数据可以同时存在多个S锁(因为只是读数据),并且规定S锁读取数据,一旦读取完成就立刻释放S锁(不管后续是否还有很多其他的操作,只要是读取了S锁的数据后,就立刻释放S锁)。</font><br><img src="/2018/11/07/mysql-16-transaction-isolation-level-and-acid-review/rc1.png" alt=""><br>这样就解决了脏读的问题,但是又有新的问题出现——不可重复读。</p><p>不可重复读:同一个事务对数据的多次读取的结果不一致。<br><img src="/2018/11/07/mysql-16-transaction-isolation-level-and-acid-review/rc2.png" alt=""><br>解决方法——引入隔离级别更高事务隔离:可重复读</p><h3 id="可重复读-REPEATABLE-READ"><a href="#可重复读-REPEATABLE-READ" class="headerlink" title="可重复读(REPEATABLE READ)"></a><strong>可重复读(REPEATABLE READ)</strong></h3><p>可重复读满足<font color="red">第三级封锁协议, 即对S锁进行修改,之前的S锁是:读取了数据之后就立刻释放S锁,现在修改是:在读取数据的时候加上S锁,但是要直到事务准备提交了才释放该S锁,X锁还是一致。</font><br><img src="/2018/11/07/mysql-16-transaction-isolation-level-and-acid-review/rr1.png" alt=""><br>这样就解决了不可重复读的问题了,但是又有新的问题出现——幻读。</p><p>例如: 有一次旺财对一个”学生表”进行操作,选取了年龄是18岁的所有行, 用X锁锁住, 并且做了修改。</p><p>改完以后旺财再次选择所有年龄是18岁的行, 想做一个确认, 没想到有一行竟然没有修改！</p><p>原来就在旺财查询并修改的的时候, 小强也对学生表进行操作, 他插入了一个新的行,其中的年龄也是18岁！ 虽然两个人的修改都没有问题, 互不影响, 但最终结果并非预期, 即幻读问题;</p><p>解决幻读的方式——串行化</p><h3 id="可串行化-SERIALIZABLE"><a href="#可串行化-SERIALIZABLE" class="headerlink" title="可串行化(SERIALIZABLE)"></a><strong>可串行化(SERIALIZABLE)</strong></h3><p>事务只能一件一件的进行,不能并发进行。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><table><thead><tr><th style="text-align:left">隔离级别</th><th style="text-align:left">数据丢失</th><th style="text-align:left">脏读</th><th style="text-align:left">不可重复读</th><th style="text-align:left">幻读</th></tr></thead><tbody><tr><td style="text-align:left">读未提交</td><td style="text-align:left">NO</td><td style="text-align:left">YES</td><td style="text-align:left">YES</td><td style="text-align:left">YES</td></tr><tr><td style="text-align:left">读已提交</td><td style="text-align:left">NO</td><td style="text-align:left">NO</td><td style="text-align:left">YES</td><td style="text-align:left">YES</td></tr><tr><td style="text-align:left">可重复读</td><td style="text-align:left">NO</td><td style="text-align:left">NO</td><td style="text-align:left">NO</td><td style="text-align:left">YES</td></tr><tr><td style="text-align:left">事务串行化执行</td><td style="text-align:left">NO</td><td style="text-align:left">NO</td><td style="text-align:left">NO</td><td style="text-align:left">NO</td></tr></tbody></table><blockquote><p><code>mysql</code>默认的隔离级别是:可重复读。</p></blockquote><blockquote><p>oracle中只支持2个隔离级别:读已提交和串行化, 默认是读已提交。</p></blockquote><blockquote><p>隔离级别的设置只对当前链接有效;</p></blockquote><h2 id="锁粒度"><a href="#锁粒度" class="headerlink" title="锁粒度"></a>锁粒度</h2><p><code>mysql</code>不同存储引擎支持的锁粒度不同, InnoDB存储引擎支持表锁及行锁, InnoDB存储引擎可支持三种行锁定方式, <font color="red">默认加锁方式是next-key 锁</font>。</p><ol><li>行锁(Record Lock):锁直接加在索引记录上面，锁住的是key。 行锁又分为共享锁(S)与排他锁(X);</li><li>间隙锁(Gap Lock):锁定索引记录间隙，确保索引记录的间隙不变。间隙锁是针对事务隔离级别为可重复读或以上级别而已的。</li><li>Next-Key Lock: 行锁和间隙锁组合起来就叫Next-Key Lock。 </li></ol><p>默认情况下，InnoDB工作在可重复读(Repeatable Read)隔离级别下，并且会以Next-Key Lock的方式对数据行进行加锁，这样可以有效防止幻读的发生。Next-Key Lock是行锁和间隙锁的组合，当InnoDB扫描索引记录的时候，会首先对索引记录加上行锁（Record Lock），再对索引记录两边的间隙加上间隙锁（Gap Lock）。加上间隙锁之后，其他事务就不能在这个间隙修改或者插入记录。</p><h2 id="间隙锁"><a href="#间隙锁" class="headerlink" title="间隙锁"></a>间隙锁</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>间隙锁指对某个记录行范围进行锁定, 如锁定第一行到第三行, 即锁定(1,3) 那第一行至第三行中间就不能进行写入操作, 同时第一行至第三行数据不能进行update/delete等任何修改操作;</p><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p>间隙锁的目的是为了防止幻读，其主要通过两个方面实现这个目:</p><ol><li>防止间隙内有新数据被插入;</li><li>防止已存在的数据, 更新成间隙内的数据;</li></ol><p>间隙锁在InnoDB的唯一作用就是防止其它事务的插入操作，以此来达到防止幻读的发生，所以间隙锁不分什么共享锁与排它锁。 默认情况下，InnoDB工作在Repeatable Read隔离级别下，并且以Next-Key Lock的方式对数据行进行加锁，这样可以有效防止幻读的发生。Next-Key Lock是行锁与间隙锁的组合，当对数据进行条件，范围检索时，对其范围内也许并存在的值进行加锁！当查询的索引含有唯一属性（唯一索引，主键索引）时，Innodb存储引擎会对next-key lock进行优化，将其降为record lock,即仅锁住索引本身，而不是范围！若是普通辅助索引，则会使用传统的next-key lock进行范围锁定！</p><p>要禁止间隙锁的话，可以把隔离级别降为Read Committed，或者开启参数innodb_locks_unsafe_for_binlog。</p><h2 id="RR级别-MVCC-GL-解决幻读问题"><a href="#RR级别-MVCC-GL-解决幻读问题" class="headerlink" title="RR级别+MVCC+GL 解决幻读问题"></a>RR级别+MVCC+GL 解决幻读问题</h2><p>在MVCC并发控制中，读操作可以分成两类:快照读 (snapshot read)与当前读 (current read)。</p><ol><li>快照读，读取的是记录的可见版本 (有可能是历史版本)，不用加锁。</li><li>当前读，读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录。 </li></ol><p>在一个支持MVCC并发控制的系统中，哪些读操作是快照读？哪些操作又是当前读呢？以<code>mysql</code> InnoDB为例: </p><p>快照读:简单的select操作，属于快照读，不加锁。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">table</span> <span class="keyword">where</span> ?;</span><br></pre></td></tr></table></figure><p>当前读:特殊的读操作，插入/更新/删除操作，属于当前读，需要加锁。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">table</span> <span class="keyword">where</span> ? <span class="keyword">lock</span> <span class="keyword">in</span> <span class="keyword">share</span> <span class="keyword">mode</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">table</span> <span class="keyword">where</span> ? <span class="keyword">for</span> <span class="keyword">update</span>;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> <span class="keyword">values</span> (…);</span><br><span class="line"><span class="keyword">update</span> <span class="keyword">table</span> <span class="keyword">set</span> ? <span class="keyword">where</span> ?;</span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> <span class="keyword">table</span> <span class="keyword">where</span> ?;</span><br></pre></td></tr></table></figure><p>所有以上的语句，都属于当前读，读取记录的最新版本。并且，读取之后，还需要保证其他并发事务不能修改当前记录，对读取记录加锁。其中，除了第一条语句，对读取记录加S锁 (共享锁)外，其他的操作，都加的是X锁 (排它锁)。 </p><p>回顾4种隔离级别:<br>Read Uncommited<br>可以读取未提交记录。此隔离级别，不会使用，忽略。</p><p>Read Committed (RC)<br>快照读忽略，本文不考虑。</p><p>针对当前读，RC隔离级别保证对读取到的记录加锁 (record lock)，存在幻读现象。</p><p>Repeatable Read (RR)<br>快照读忽略，本文不考虑。</p><p>针对当前读，RR隔离级别保证对读取到的记录加锁 (记录锁)，同时保证对读取的范围加锁，新的满足查询条件的记录不能够插入 (间隙锁)，不存在幻读现象。</p><p>Serializable<br>从MVCC并发控制退化为基于锁的并发控制。不区别快照读与当前读，所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)。</p><p>Serializable隔离级别下，读写冲突，因此并发度急剧下降，在<code>mysql/InnoDB</code>下不建议使用。<br>对于快照读来说，幻读的解决是依赖mvcc解决。而对于当前读则依赖于gap-lock解决。</p><p>此外, 对于快照读来说，幻读的解决是依赖mvcc解决。而对于当前读则依赖于gap-lock解决。</p><p>更多参考: <a href="https://www.cnblogs.com/aspirant/p/6920987.html" target="_blank" rel="noopener">Mysql 的InnoDB事务方面的 多版本并发控制如何实现 MVCC</a></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>回顾了事务相关操作命令;</li><li>回顾了事务的ACID特性及四级隔离级别, 三级封锁协议相关知识;</li><li>回顾锁粒度(表锁/行锁(S/X锁)), 及行锁的三种方式(RL,GL, NKL);</li><li>进一步回顾了Gap Lock相关知识;</li><li>回顾了Next Key Lock + MVCC 在RR隔离级别下解决幻读原理;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;事务指的是满足&lt;code&gt;ACID&lt;/code&gt;特性的一组操作,&lt;code&gt;mysql&lt;/code&gt;中可以通过&lt;code&gt;commit&lt;/code&gt;提交一个事务,也可以使用&lt;code&gt;rollback&lt;/code&gt;进行回滚。 在并发场景中很难保证事务的&lt;code&gt;Isolation&lt;/code&gt;特性, 即无法保证临界资源的排它性操作, 从而引发数据一致性问题, 临界资源互斥问题显然需要借助加锁来解决, 在并发事务中就需要用锁的并发控制来处理;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="mysql专题" scheme="http://researchlab.github.io/categories/mysql%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="mysql" scheme="http://researchlab.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>redis专题17 主从同步系列问题</title>
    <link href="http://researchlab.github.io/2018/10/15/redis-17-replication/"/>
    <id>http://researchlab.github.io/2018/10/15/redis-17-replication/</id>
    <published>2018-10-15T19:03:25.000Z</published>
    <updated>2018-11-09T01:39:38.578Z</updated>
    
    <content type="html"><![CDATA[<p>在生产环境中需要用到<code>redis</code>做数据持久化落地数据库时,  一般应搭建专属的<code>redis</code>集群来避免单点故障及单点读写性能问题, 如不是重度<code>redis</code>用户, 数据量压力不是特别大时, 也可以考虑采用<code>redis</code>主从同步架构代替, 本文将试图对<code>redis</code>主从同步原理, 步骤, 配置项, 实践等方面进行学习总结;<br><a id="more"></a></p><h5 id="主从同步目的"><a href="#主从同步目的" class="headerlink" title="主从同步目的"></a>主从同步目的</h5><blockquote><p>一旦主节点宕机, 从节点作为主节点的备份可以随时顶上来;<br>扩展主节点的读能力, 分担主节点读压力;</p></blockquote><h5 id="主从同步原理"><a href="#主从同步原理" class="headerlink" title="主从同步原理"></a>主从同步原理</h5><p><code>redis</code>支持主从复制, <code>redis</code>的主从结构可以采用一主多从或者级联结构, <code>redis</code>主从复制可以根据是否是全量分为全量同步和增量同步,<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">       /  slave-1  /  slave-2-1</span><br><span class="line">Master -  slave-2--   slave-2-2</span><br><span class="line">       \  slave-3  \  slave-2-3</span><br><span class="line">        \ ...      \  ...</span><br><span class="line">          slave-n     slave-2-n</span><br></pre></td></tr></table></figure></p><h6 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h6><p><code>redis</code>全量复制一般发生在<code>slave</code>初始化阶段, 这时<code>slave</code>需要将Master上的所有数据都复制一份, 具体过程如下,</p><ul><li>1.从服务器连接主服务器, 发送<code>sync</code>命令;</li><li>2.主服务器接收到<code>sync</code>命名后, 开始执行<code>bgsave</code>命令生成RDB文件并使用复制积压缓冲区记录此后执行的所有写命令;</li><li>3.主服务器<code>bgsave</code>执行完后, 向所有从服务器发送快照文件, 并在发送期间继续记录被执行的写命令;</li><li>4.从服务器收到快照文件后丢弃所有旧数据, 载入收到的快照;</li><li>5.主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令;</li><li>6.从服务器完成对快照的载入, 开始接收命令请求, 并执行来自主服务器缓冲区的写命令;</li></ul><p>完成上面几个步骤后就完成了从服务器数据初始化的所有操作, 从服务器此时可以接收来自用户的读请求。</p><blockquote><p>若多个从服务器同时发来<code>sync</code>指令, 主服务器也只会执行一次<code>bgsave</code>, 然后把持久化好的RDB文件发给多个下游;</p></blockquote><h6 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a>增量同步</h6><p>在redis2.8之前, redis仅支持<code>sync</code>全量同步操作, <code>sync</code>命令是一个非常耗费资源的操作, 为了解决主从服务器断线重来带来的<code>sync</code>重复复制问题, <code>redis</code>从2.8版本开始, 使用<code>psync</code>命令代替<code>sync</code>命令来执行复制时的同步操作。<br><code>psync</code>命令具有完整重同步<code>(full resynchronization)</code>和增量重同步<code>(partial resynchronization)</code>两种模式, 而增量同步策略大大降低了连接断开的恢复成本。增量同步过程如下,</p><ul><li>1.<code>master</code>端为复制流维护一个内存缓冲区<code>(in-memory backlog)</code>, 记录最近发送的复制流命令;</li><li>2.同时, Master和<code>slave</code>之间都维护一个复制偏移量<code>(replication offset)</code>和当前<code>master</code>服务器<code>ID(Masterrun id)</code>。</li><li>3.当网络断开, <code>slave</code>尝试重连时:<ul><li>a. 如果<code>masterID</code>相同(即仍是断网前的<code>master</code>服务器), 并且从断开时到当前时刻的历史命令依然在<code>master</code>的内存缓冲区中存在, 则Master会将缺失的这段时间的所有命令发送给<code>slave</code>执行, 然后复制工作就可以继续执行了;</li><li>b. 否则, 依然需要全量复制操作;</li></ul></li></ul><blockquote><p>增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令, 从服务器接收并执行收到的写命令。</p></blockquote><p>可见增量重同步功能由以下三个部分构成,</p><ul><li>1.主服务器的复制偏移量<code>(replication offset)</code>和从服务器的复制偏移量;</li><li>2.主服务器的复制积压缓冲区<code>(replication backlog)</code>;</li><li>3.服务器的运行<code>ID(run ID)</code>。</li></ul><p><strong>1.复制偏移量</strong></p><p>执行复制的双方——主服务器和从服务器会分别维护一个复制偏移量,</p><ul><li>主服务器每次向从服务器传播<code>N</code>个字节的数据时, 就将自己的复制偏移量的值加上<code>N</code>;</li><li>从服务器每次收到主服务器传播来的<code>N</code>个字节的数据时, 就将自己的复制偏移量的值加上<code>N</code>;</li></ul><blockquote><p>主从偏移量相同, 则当前主从处于一致状态, 反之则主从状态不一致;</p></blockquote><p>示例分析</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                          --(网络故障断线  )--&gt; slaveA ( offset=10086 )</span><br><span class="line">                        /</span><br><span class="line">                       /</span><br><span class="line">Master ( offset=10119 )-----(成功发送33字节)--&gt; slaveB ( offset=10119 )</span><br><span class="line">                       \</span><br><span class="line">                        \</span><br><span class="line">                          --(成功发送33字节)--&gt; slaveC ( offset=10119 )</span><br></pre></td></tr></table></figure><p>如上示例, 假设从服务器<code>A</code>在断线之后就立即重新连接主服务器成功, 那么接下来, 从服务器将向主服务器发送<code>psync</code>命令, 报告从服务器A当前的复制偏移量为<code>10086</code>, 那么这时, 主服务器应该对从服务器执行完整重同步还是部分重同步呢？如果执行部分重同步的话, 主服务器又如何补偿从服务器<code>A</code>在断线期间丢失的那部分数据呢？以上问题的答案都和复制积压缓冲区有关。</p><p><strong>2.复制积压缓冲区</strong><br>复制积压缓冲区是由主服务器维护的一个固定长度<code>(fixed-size)</code>先进先出<code>(FIFO)</code>队列, 默认大小为<code>1MB</code>。</p><p>和普通先进先出队列随着元素的增加和减少而动态调整长度不同, 固定长度先进先出队列的长度是固定的, 当入队元素的数量大于队列长度时, 最先入队的元素会被弹出, 而新元素会被放入队列。</p><p>当主服务器向从服务器发送命令时, 它不仅会将写命令发送给所有从服务器, 还会将写命令入队到复制积压缓冲区里面, 示意图,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">          --(向从服务器发送命令)--&gt; slaveA</span><br><span class="line">        /</span><br><span class="line">       /</span><br><span class="line">Master -----(向从服务器发送命令)--&gt; slave...</span><br><span class="line">       \</span><br><span class="line">        \</span><br><span class="line">          --(同步将命令写入队列)--&gt; | 复制积压缓冲区队列 |</span><br></pre></td></tr></table></figure><p>因此, 主服务器的复制积压缓冲区里面会保存着一部分最近发送的写命令, 并且复制积压缓冲区会为队列中的每个字节记录相应的复制偏移量, 就像下表所示的那样,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">|偏移量| 10086 | 10087 | 10088 | 10089 |</span><br><span class="line">|字节值|   &apos;*&apos; |   5   | &apos;\r&apos;  | &apos;\n&apos;  |</span><br></pre></td></tr></table></figure><p>当从服务器重新连上主服务器时, 从服务器会通过<code>psync</code>命令将自己的复制偏移量offset发送给主服务器, 主服务器会根据这个复制偏移量来决定对从服务器执行何种同步操作:</p><blockquote><p>如果<code>offset</code>偏移量之后的数据(也即是偏移量<code>offset+1</code>开始的数据)仍然存在于复制积压缓冲区里面, 那么主服务器将对从服务器执行部分重同步操作;</p></blockquote><blockquote><p>相反, 如果<code>offset</code>偏移量之后的数据已经不存在于复制积压缓冲区, 那么主服务器将对从服务器执行完整重同步操作。</p></blockquote><p><strong>根据需要调整复制积压缓冲区的大小</strong></p><p><code>redis</code>为复制积压缓冲区设置的默认大小为<code>1MB</code>, 如果主服务器需要执行大量写命令, 又或者主从服务器断线后重连接所需的时间比较长, 那么这个大小也许并不合适。如果复制积压缓冲区的大小设置得不恰当, 那么<code>psync</code>命令的复制重同步模式就不能正常发挥作用, 因此, 正确估算和设置复制积压缓冲区的大小非常重要。<br>复制积压缓冲区的最小大小可以根据公式<code>second*write_size_per_second</code>来估算:</p><blockquote><p>其中<code>second</code>为从服务器断线后重新连接上主服务器所需的平均时间(以秒计算);</p></blockquote><blockquote><p>而<code>write_size_per_second</code>则是主服务器平均每秒产生的写命令数据量(协议格式的写命令的长度总和);</p></blockquote><p>例如, 如果主服务器平均每秒产生<code>1MB</code>的写数据, 而从服务器断线之后平均要<code>5秒</code>才能重新连接上主服务器, 那么复制积压缓冲区的大小就不能低于<code>5MB</code>。<br>为了安全起见, 可以将复制积压缓冲区的大小设为<code>2*second*write_size_per_second</code>, 这样可以保证绝大部分断线情况都能用部分重同步来处理。<br>可以根据实际需要, 修改配置文件中的<code>repl-backlog-size</code>选项来修改复制积压缓冲区的大小;</p><p><strong>3.服务器运行ID</strong><br>除了复制偏移量和复制积压缓冲区之外, 实现部分重同步还需要用到服务器运行<code>ID(run ID)</code>:</p><blockquote><p>每个<code>redis</code>服务器, 不论主服务器还是从服务, 都会有自己的运行<code>ID</code>;</p></blockquote><blockquote><p>运行<code>ID</code>在服务器启动时自动生成, 由40个随机的十六进制字符组成, 例如<code>53b9b28df8042fdc9ab5e3fcbbbabff1d5dce2b3</code>;</p></blockquote><p>当从服务器对主服务器进行初次复制时, 主服务器会将自己的运行<code>ID</code>传送给从服务器, 而从服务器则会将这个运行<code>ID</code>保存起来(注意哦, 是从服务器保存了主服务器的<code>ID</code>)。</p><p>当从服务器断线并重新连上一个主服务器时, 从服务器将向当前连接的主服务器发送之前保存的运行<code>ID</code>:</p><blockquote><p>如果从服务器保存的运行<code>ID</code>和当前连接的主服务器的运行<code>ID</code>相同, 那么说明从服务器断线之前复制的就是当前连接的这个主服务器, 主服务器可以继续尝试执行部分重同步操作;</p></blockquote><blockquote><p>相反地, 如果从服务器保存的运行<code>ID</code>和当前连接的主服务器的运行<code>ID</code>并不相同, 那么说明从服务器断线之前复制的主服务器并不是当前连接的这个主服务器, 主服务器将对从服务器执行完整重同步操作。</p></blockquote><p><strong>psync命令</strong><br><code>psync</code>命令的调用方法有两种,</p><blockquote><p>如果从服务器以前没有复制过任何主服务器, 或者之前执行过<code>SLAVEOF NO ONE</code>命令, 那么从服务器在开始一次新的复制时将向主服务器发送<code>psync ? -1</code>命令, 主动请求主服务器进行完整重同步(因为这时不可能执行部分重同步);</p></blockquote><blockquote><p>相反地, 如果从服务器已经复制过某个主服务器, 那么从服务器在开始一次新的复制时将向主服务器发送<code>psync &lt;runid&gt; &lt;offset&gt;</code>命令: 其中<code>runid</code>是上一次复制的主服务器的运行<code>ID</code>, 而<code>offset</code>则是从服务器当前的复制偏移量, 接收到这个命令的主服务器会通过这两个参数来判断应该对从服务器执行哪种同步操作。</p></blockquote><h5 id="主从同步策略"><a href="#主从同步策略" class="headerlink" title="主从同步策略"></a>主从同步策略</h5><p><code>redis</code> 的复制是异步进行的, <code>redis3.0</code>开始提供的<code>wait</code>指令可以让异步复制变身同步复制, 确保系统的强一致性,<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; set key value</span><br><span class="line">OK</span><br><span class="line">&gt; wait 1 0</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure></p><p>wait 提供两个参数, 第一个参数是从库的数量<code>N</code>, 第二个参数是时间<code>t</code>, 以毫秒为单位。它表示等待<code>wait</code>指令之前的所有写操作同步到<code>N</code>个从库 (也就是确保<code>N</code>个从库的同步没有滞后), 最多等待时间<code>t</code>。如果时间<code>t=0</code>, 表示无限等待直到<code>N</code>个从库同步完成达成一致。</p><p>假设此时出现了网络分区,<code>wait</code>指令第二个参数时间<code>t=0</code>, 主从同步无法继续进行, <code>wait</code>指令会永远阻塞, <code>redis</code>服务器将丧失可用性。</p><p><strong>主从刚刚连接的时候, 进行全量同步; 全同步结束后, 进行增量同步。当然, 如果有需要, slave在任何时候都可以发起全量同步。redis策略是, 无论如何, 首先会尝试进行增量同步, 如不成功, 要求从机进行全量同步。</strong></p><h5 id="主从同步过程"><a href="#主从同步过程" class="headerlink" title="主从同步过程"></a>主从同步过程</h5><p>从服务器每次启动时, 会立即通过<code>slaveof master-host  master-port</code> 向主服务器发起主从复制同步请求; <code>SLAVEOF</code>命令是一个异步命令, 在完成<code>master-host</code>属性和<code>master-port</code>属性的设置工作之后, 从服务器将向发送<code>SLAVEOF</code>命令的客户端返回<code>OK</code>, 表示复制指令已经被接收, 而实际的复制工作将在<code>OK</code>返回之后才真正开始执行。从服务器开始发起主从复制请求到开始复制主要经历了如下7个步骤,</p><p><strong>步骤1</strong>: 设置主服务器的地址和端口, 通过<code>slaveof</code>指令发起主从复制同步请求,<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:12345&gt; SLAVEOF 127.0.0.1 6379</span><br><span class="line">OK</span><br></pre></td></tr></table></figure></p><p><strong>步骤2</strong>: 建立套接字连接</p><p>在SLAVEOF命令执行之后, 从服务器将根据命令所设置的IP地址和端口, 创建连向主服务器的套接字连接, 如果从服务器创建的套接字能成功连接(connect)到主服务器, 那么从服务器将为这个套接字关联一个专门用于处理复制工作的文件事件处理器, 这个处理器将负责执行后续的复制工作, 比如接收RDB文件, 以及接收主服务器传播来的写命令, 诸如此类。而主服务器在接受(accept)从服务器的套接字连接之后, 将为该套接字创建相应的客户端状态, 并将从服务器看作是一个连接到主服务器的客户端来对待, 这时从服务器将同时具有服务器(server)和客户端(client)两个身份: 从服务器可以向主服务器发送命令请求, 而主服务器则会向从服务器返回命令回复。</p><p><strong>步骤3</strong>: 发送PING命令</p><p>从服务器成为主服务器的客户端之后, 做的第一件事就是向主服务器发送一个PING命令。</p><blockquote><p>通过发送PING命令检查套接字的读写状态;</p></blockquote><blockquote><p>通过PING命令可以检查主服务器能否正常处理命令。</p></blockquote><p>从服务器在发送PING命令之后可能遇到以下三种情况:</p><blockquote><p>主服务器向从服务器返回了一个命令回复, 但从服务器却不能在规定的时限内读取命令回复的内容(timeout), 说明网络连接状态不佳, 从服务器将断开并重新创建连向主服务器的套接字;</p></blockquote><blockquote><p>如果主服务器返回一个错误, 那么表示主服务器暂时没有办法处理从服务器的命令请求, 从服务器也将断开并重新创建连向主服务器的套接字;</p></blockquote><blockquote><p>如果从服务器读取到”PONG”回复, 那么表示主从服务器之间的网络连接状态正常, 那就继续执行下面的复制步骤。</p></blockquote><p><strong>步骤4</strong>: 身份验证</p><p>从服务器在收到主服务器返回的”PONG”回复之后, 下一步要做的就是决定是否进行身份验证:</p><p>如果从服务器设置了masterauth选项, 那么进行身份验证。否则不进行身份认证;<br>在需要进行身份验证的情况下, 从服务器将向主服务器发送一条AUTH命令, 命令的参数为从服务器masterauth选项的值。</p><p>从服务器在身份验证阶段可能遇到的情况有以下几种:</p><blockquote><p>主服务器没有设置requirepass选项, 从服务器没有设置masterauth,那么就继续后面的复制工作;</p></blockquote><blockquote><p>如果从服务器的通过AUTH命令发送的密码和主服务器requirepass选项所设置的密码相同, 那么也继续后面的工作, 否则返回错误invaild password;</p></blockquote><blockquote><p>如果主服务器设置了requireoass选项, 但从服务器没有设置masterauth选项, 那么服务器将返回NOAUTH错误。反过来如果主服务器没有设置requirepass选项, 但是从服务器却设置了materauth选项, 那么主服务器返回no password is set错误;</p></blockquote><p>所有错误到只有一个结果: 中止目前的复制工作, 并从创建套接字开始重新执行复制, 直到身份验证通过, 或者从服务器放弃执行复制为止。</p><p><strong>步骤5</strong>: 发送端口信息</p><p>身份验证步骤之后, 从服务器将执行命令<code>REPLCONF listening-port &lt;port-number&gt;</code>, 向主服务器发送从服务器的监听端口号。</p><p>主服务器在接收到这个命令之后, 会将端口号记录在从服务器所对应的客户端状态的<code>slave_listening_port</code>属性,</p><blockquote><p><code>slave_listening_port</code>属性目前唯一的作用就是在主服务器执行<code>INFO replication</code>命令时打印出从服务器的端口号。</p></blockquote><p><strong>步骤6</strong>: 同步</p><p>在这一步, 从服务器将向主服务器发送<code>psync</code>命令, 执行同步操作, 并将自己的数据库更新至主服务器数据库当前所处的状态。</p><p>需要注意的是在执行同步操作前, 只有从服务器是主服务器的客户端。但是执行同步操作之后, 主服务器也会成为从服务器的客户端,</p><blockquote><p>如果<code>psync</code>命令执行的是完整同步操作, 那么主服务器只有成为了从服务器的客户端才能将保存在缓冲区中的写命令发送给从服务器执行;</p></blockquote><blockquote><p>如果<code>psync</code>命令执行的是部分同步操作, 那么主服务器只有成为了从服务器的客户端才能将保存在复制积压缓冲区中的写命令发送给从服务器执行;</p></blockquote><p><strong>步骤7</strong>: 命令传播</p><p>当完成了同步之后, 主从服务器就会进入命令传播阶段, 这时主服务器只要一直将自己执行的写命令发送给从服务器, 而从服务器只要一直接收并执行主服务器发来的写命令, 就可以保证主从服务器一直保持一致了。</p><p><strong>心跳检测</strong><br>在命令传播阶段, 从服务器默认会以每秒一次的频率, 向主服务器发送命令: <code>REPLCONF ACK &lt;replication_offset&gt;</code></p><p>其中<code>replication_offset</code>是从服务器当前的复制偏移量。</p><p>发送<code>REPLCONF ACK</code>命令对于主从服务器有三个作用:</p><blockquote><p>检测主从服务器的网络连接状态;</p></blockquote><blockquote><p>辅助实现min-slaves选项;</p></blockquote><blockquote><p>检测命令丢失。</p></blockquote><p>检测主从服务器的网络连接状态</p><p>如果主服务器超过一秒钟没有收到从服务器发来的<code>REPLCONF ACK</code>命令, 那么主服务器就知道主从服务器之间的连接出现问题了。</p><p>通过向主服务器发送<code>INFO replication</code>命令, 在列出的从服务器列表的<code>lag</code>一栏中, 我们可以看到相应从服务器最后一次向主服务器发送<code>REPLCONF ACK</code>命令距离现在过了多少秒;</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">10.1.195.19:8001&gt; info replication</span><br><span class="line"><span class="meta">#</span><span class="bash"> Replication</span></span><br><span class="line">role:master</span><br><span class="line">connected_slaves:1</span><br><span class="line">slave0:ip=172.28.0.1,port=6379,state=online,offset=0,lag=1</span><br><span class="line">master_replid:10c63aebd8f09c749d1b26eccb52856b6d894292</span><br><span class="line">master_replid2:0000000000000000000000000000000000000000</span><br><span class="line">master_repl_offset:0</span><br><span class="line">second_repl_offset:-1</span><br><span class="line">repl_backlog_active:1</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:1</span><br><span class="line">repl_backlog_histlen:0</span><br><span class="line">10.1.195.19:8001&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">刚刚发送过 REPLCONF ACK命令</span></span><br><span class="line">slave1:ip=171.28.0.1,port=6379,state=online,offset=197,lag=15</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">15秒之前发送过REPLCONF ACK命令</span></span><br><span class="line"></span><br><span class="line">master_repl_offset:211</span><br><span class="line">repl_backlog_active:1</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:2</span><br><span class="line">repl_backlog_histlen:210</span><br></pre></td></tr></table></figure><p>在一般情况下, <code>lag</code>的值应该在0秒或者1秒之间跳动, 如果超过1秒的话, 那么说明主从服务器之间的连接出现了故障。</p><p><strong>辅助实现min-slaves配置选项</strong></p><p><code>redis</code>的<code>min-slaves-to-write</code>和<code>min-slaves-max-lag</code>两个选项可以防止主服务器在不安全的情况下执行写命令。</p><p>举个例子, 如果我们向主服务器提供以下设置:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">min-slaves-to-write 3</span><br><span class="line">min-slaves-max-lag 10</span><br></pre></td></tr></table></figure></p><p>那么在从服务器的数量少于3个, 或者三个从服务器的延迟<code>(lag)</code>值都大于或等于10秒时, 主服务器将拒绝执行写命令, 这里的延迟值就是上面提到的<code>INFO replication</code>命令的<code>(lag)</code>值。</p><p><strong>检测命令丢失</strong></p><p>我们从命令: <code>REPLCONF ACK &lt;replication_offset&gt;</code>就可以知道, 每发送一次这个命令从服务器都会向主服务器报告一次自己的复制偏移量。那此时尽管主服务器发送给从服务器的<code>SET key value</code>丢失了。也无所谓, 主服务器马上就知道了。</p><h5 id="同步实践"><a href="#同步实践" class="headerlink" title="同步实践"></a>同步实践</h5><p><strong>0.环境准备</strong><br>通过构建如下主从级联架构来进一步实践<code>redis</code>主从复制同步机制,<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">master---&gt; slave01 --&gt; slave02</span><br></pre></td></tr></table></figure></p><p>即<code>master</code>为主服务器, <code>slave01</code>为<code>master</code>从服务器, 同时也是<code>slave02</code>主服务器,  由于要构建多个<code>redis container</code>环境, 为方便起见通过<code>docker-compose</code>来实践,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">version: '3'</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  master-redis:</span><br><span class="line">    image: redis</span><br><span class="line">    container_name: master</span><br><span class="line">    ports:</span><br><span class="line">      - "8001:6379"</span><br><span class="line">    volumes:</span><br><span class="line">      - ~/workbench/docker/docker-compose/redis/conf/redis.conf:/etc/redis/redis.conf</span><br><span class="line">    entrypoint: ["redis-server", "/etc/redis/redis.conf"]</span><br><span class="line"></span><br><span class="line">  slave-redis-01:</span><br><span class="line">    image: redis</span><br><span class="line">    container_name: slave01</span><br><span class="line">    ports:</span><br><span class="line">      - "8002:6379"</span><br><span class="line">    volumes:</span><br><span class="line">      - ~/workbench/docker/docker-compose/redis/conf/redis.conf:/etc/redis/redis.conf</span><br><span class="line">    entrypoint: ["redis-server", "/etc/redis/redis.conf"]</span><br><span class="line"></span><br><span class="line">  slave-redis-02:</span><br><span class="line">    image: redis</span><br><span class="line">    container_name: slave02</span><br><span class="line">    ports:</span><br><span class="line">      - "8003:6379"</span><br><span class="line">    volumes:</span><br><span class="line">      - ~/workbench/docker/docker-compose/redis/conf/redis.conf:/etc/redis/redis.conf</span><br><span class="line">    entrypoint: ["redis-server", "/etc/redis/redis.conf"]</span><br></pre></td></tr></table></figure></p><p>将<code>redis.conf</code>配置做如下修改,</p><ul><li>将<code>bind 127.0.0.1</code> 修改为<code>bind 0.0.0.0</code>;</li><li>将<code>daemonize yes</code> 修改为<code>daemonize no</code>, 让<code>redis</code>运行在前台;</li><li>将<code>protected-mode yes</code>修改为<code>protected-mode no</code>, 在<code>protected-mode yes</code>模式下需要设置密码才能远程访问, 否则<code>redis</code>只接受本地访问;</li></ul><p><strong>1.发送<code>slaveof</code>指令,请求主从同步</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">➜  redis docker-compose up -d</span><br><span class="line">Creating network "redis_default" with the default driver</span><br><span class="line">Creating master  ... done</span><br><span class="line">Creating slave02 ... done</span><br><span class="line">Creating slave01 ... done</span><br><span class="line">➜  redis docker-compose ps</span><br><span class="line"> Name                Command               State           Ports</span><br><span class="line">-------------------------------------------------------------------------</span><br><span class="line">master    redis-server /etc/redis/re ...   Up      0.0.0.0:8001-&gt;6379/tcp</span><br><span class="line">slave01   redis-server /etc/redis/re ...   Up      0.0.0.0:8002-&gt;6379/tcp</span><br><span class="line">slave02   redis-server /etc/redis/re ...   Up      0.0.0.0:8003-&gt;6379/tcp</span><br><span class="line">➜  redis ifconfig |grep inet |grep -v 127.0.0.1</span><br><span class="line">        inet6 ::1 prefixlen 128</span><br><span class="line">        inet6 fe80::1%lo0 prefixlen 64 scopeid 0x1</span><br><span class="line">        inet6 fe80::475:d879:2a90:ac35%en0 prefixlen 64 secured scopeid 0x5</span><br><span class="line">        inet 10.1.195.19 netmask 0xffffff00 broadcast 10.1.195.255</span><br></pre></td></tr></table></figure><p>上述命令, 分别启动了一台<code>master</code>主机, 两台<code>slave01</code>,<code>slave02</code>从机, 并得知当前宿主机ip为<code>10.1.195.19</code></p><p>登录从机发送<code>slaveof</code>指令, 开始主从复制同步,<br>主机<code>master</code> 执行命令,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">➜  docker exec -it master redis-cli -h 10.1.195.19 -p 8001</span><br><span class="line">10.1.195.19:8001&gt; flushdb</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8001&gt; hmset info name mike city shanghai code 110</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8001&gt; hgetall info</span><br><span class="line">1) "name"</span><br><span class="line">2) "mike"</span><br><span class="line">3) "city"</span><br><span class="line">4) "shanghai"</span><br><span class="line">5) "code"</span><br><span class="line">6) "110"</span><br><span class="line">10.1.195.19:8001&gt;</span><br></pre></td></tr></table></figure></p><p>从机<code>slave01</code> 查询命令,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">➜  docker exec -it slave01 redis-cli -h 10.1.195.19 -p 8002</span><br><span class="line">10.1.195.19:8002&gt; slaveof no one</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8002&gt; flushdb</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8002&gt; slaveof 10.1.195.19 8001</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8002&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "info"</span><br><span class="line">10.1.195.19:8002&gt; hgetall info</span><br><span class="line">1) "name"</span><br><span class="line">2) "mike"</span><br><span class="line">3) "city"</span><br><span class="line">4) "shanghai"</span><br><span class="line">5) "code"</span><br><span class="line">6) "110"</span><br><span class="line">10.1.195.19:8002&gt;</span><br></pre></td></tr></table></figure></p><p>从机<code>slave02</code>查询命令,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">➜  docker exec -it slave02 redis-cli -h 10.1.195.19 -p 8003</span><br><span class="line">10.1.195.19:8003&gt; slaveof no one</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8003&gt; flushdb</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8003&gt; slaveof 10.1.195.19 8002</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8003&gt; hgetall info</span><br><span class="line">1) "name"</span><br><span class="line">2) "mike"</span><br><span class="line">3) "city"</span><br><span class="line">4) "shanghai"</span><br><span class="line">5) "code"</span><br><span class="line">6) "110"</span><br><span class="line">10.1.195.19:8003&gt;</span><br></pre></td></tr></table></figure></p><ul><li><code>docker exec -it ${docker-name} redis-cli -h ${localhost-ip} -p ${port}</code>命令登录到各个<code>redis</code>实例服务;</li><li><code>slaveof no one</code>命令将当前<code>redis</code>实例的主从服务;</li><li>从上述实例可见, 通过在<code>master</code>主机中执行<code>hmset</code>命令, 相应的从机以及级联从机也都同步了主机的执行命令, 上述示例显示主从复制同步成功;</li></ul><p>从机配置默认开启了只读模式<code>slave-read-only yes</code>,所以对从机进行修改操作是不许可的, 也不建议这么做;<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">10.1.195.19:8003&gt; flushdb</span><br><span class="line">(error) READONLY You can't write against a read only replicx</span><br><span class="line">10.1.195.19:8003&gt;</span><br></pre></td></tr></table></figure></p><p>当对主机操作<code>flushdb</code>时, 可见从机也执行了<code>flushdb</code>命令<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">10.1.195.19:8001&gt; flushdb</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8001&gt;</span><br><span class="line"></span><br><span class="line">10.1.195.19:8002&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) (empty list or set)</span><br><span class="line">10.1.195.19:8002&gt;</span><br><span class="line"></span><br><span class="line">10.1.195.19:8003&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) (empty list or set)</span><br><span class="line">10.1.195.19:8003&gt;</span><br></pre></td></tr></table></figure></p><p>当关闭<code>master</code>服务后, 对从机服务无影响,  所以从机服务的启动顺序及服务提供 与<code>master</code>主机服务是否已启动及启动顺序无关;</p><p>当然上面<code>docker-compose</code>配置也可以直接配置<code>slaveof</code>参数， 就不需要手动去发起命令, 可参看 <a href="https://github.com/researchlab/docker-envs/tree/master/redis/docker-compose-redis-replication" target="_blank" rel="noopener">docker-compose-redis-replication</a></p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li><code>redis</code>的主从同步是异步进行的, 这意味着主从同步不会影响主逻辑, 也不会降低<code>redis</code>的处理性能。</li><li>主从架构中, 可以考虑关闭主服务器的数据持久化功能, 只让从服务器进行持久化, 这样可以提高主服务器的处理性能。</li><li>在主从架构中, 从服务器通常被设置为只读模式, 这样可以避免从服务器的数据被误修改。但是从服务器仍然可以接受<code>config</code>等指令, 所以还是不应该将从服务器直接暴露到不安全的网络环境中。如果必须如此, 那可以考虑给重要指令进行重命名, 来避免命令被外人误执行。</li><li>主从同步分为<code>全量同步</code>和<code>增量同步</code>, 文中对<code>全量同步</code>和<code>增量同步</code>原理,实现过程进行了阐述分析;</li><li>进一步阐述了主从不同执行策略, 即从机初始连接主机时, 先进行增量同步, 若增量同步失败, 则进行全量同步,  同时可以利用<code>wait</code>指令 将redis主从同步的异步行为转变为同步行为;</li><li>分析了主从同步过程,  主从同步开始至复制, 大致进来7个过程, 1.发起<code>slaveof</code>指令;2.建立套接字连接;3.发送ping指令测试连接状态;4.身份认证;5.发送端口信息;6.同步初始化阶段,从机载入主机RDB,准备接受主机命令;7.增量同步;</li><li>通过docker-compose 构建<code>主-从-从</code>架, 深入实践分析<code>redis</code>主从复制同步过程;</li><li>主从复制是 <code>redis</code> 分布式的基础, <code>redis</code> 的高可用离开了主从复制将无从进行;</li><li>不过复制功能也不是必须的, 如果你将 <code>redis</code> 只用来做缓存, 跟<code>memcache</code>一样来对待, 也就无需要从库做备份, 挂掉了重新启动一下就行。但是只要你使用了 <code>redis</code> 的持久化功能, 就必须认真对待主从复制, 它是系统数据安全的基础保障;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在生产环境中需要用到&lt;code&gt;redis&lt;/code&gt;做数据持久化落地数据库时,  一般应搭建专属的&lt;code&gt;redis&lt;/code&gt;集群来避免单点故障及单点读写性能问题, 如不是重度&lt;code&gt;redis&lt;/code&gt;用户, 数据量压力不是特别大时, 也可以考虑采用&lt;code&gt;redis&lt;/code&gt;主从同步架构代替, 本文将试图对&lt;code&gt;redis&lt;/code&gt;主从同步原理, 步骤, 配置项, 实践等方面进行学习总结;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题16 数据持久化实践</title>
    <link href="http://researchlab.github.io/2018/10/13/redis-16-storage-solution-opt/"/>
    <id>http://researchlab.github.io/2018/10/13/redis-16-storage-solution-opt/</id>
    <published>2018-10-13T19:12:11.000Z</published>
    <updated>2018-11-09T01:39:38.578Z</updated>
    
    <content type="html"><![CDATA[<p>通过示例分析，深入了解<code>redis</code>数据持久化策略执行机制；<br><a id="more"></a></p><h5 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h5><hr><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜ docker run -itd --name lredis -p7002:6379 -v ~/workbench/docker/redis/conf/redis.conf:/etc/redis/redis.conf redis redis-server /etc/redis/redis.conf</span><br></pre></td></tr></table></figure><h5 id="版本日志"><a href="#版本日志" class="headerlink" title="版本日志"></a>版本日志</h5><hr><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜ docker logs -f lredis</span><br><span class="line">1:C 24 Oct 2018 09:24:03.601 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo</span><br><span class="line">1:C 24 Oct 2018 09:24:03.602 # Redis version=5.0.0, bits=64, commit=00000000, modified=0, pid=1, just started</span><br><span class="line">...</span><br><span class="line">1:M 24 Oct 2018 09:24:03.606 # Server initialized</span><br><span class="line">1:M 24 Oct 2018 09:24:03.606 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command &apos;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&apos; as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.</span><br><span class="line">1:M 24 Oct 2018 09:24:03.606 * Ready to accept connections</span><br></pre></td></tr></table></figure><h5 id="RDB方式持久化"><a href="#RDB方式持久化" class="headerlink" title="RDB方式持久化"></a>RDB方式持久化</h5><hr><p><code>Redis</code>默认的持久化方式是<code>RDB</code>，并且默认是打开的。<code>RDB</code>的保存有方式分为<code>主动保存</code>与<code>被动保存</code>。<code>主动保存</code>可以在<code>redis-cli</code>中输入<code>save</code>即可；<code>被动保存</code>需要满足配置文件中设定的触发条件，满足触发条件后，数据才会被保存为快照，正是因为这样才说<code>RDB</code>的数据完整性是比不上<code>AOF</code>;<br>触发保存条件后，会在指定的目录生成一个名为<code>dump.rdb</code>的文件，等到下一次启动<code>Redis</code>时，<code>Redis</code>会去读取该目录下的<code>dump.rdb</code>文件，将里面的数据恢复到<code>Redis</code>;</p><p><code>dump.rdb</code>文件路径,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; config get dir</span><br><span class="line">1) "dir"</span><br><span class="line">2) "/data"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p><p>目前官方默认的触发条件可以在<code>redis.conf</code>中看到,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">save 900 1              #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。</span><br><span class="line"></span><br><span class="line">save 300 10            #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。</span><br><span class="line"></span><br><span class="line">save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。</span><br></pre></td></tr></table></figure></p><p>为了便于测试， 把上面默认的配置修改为，<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">save 900 1              #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。</span><br><span class="line"></span><br><span class="line">save 300 10            #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。</span><br><span class="line"></span><br><span class="line">save 20 5        #在20秒之后，如果至少有5个key发生变化，则dump内存快照。</span><br></pre></td></tr></table></figure></p><ol><li><strong><code>RDB</code>被动触发保存实践</strong><br>input<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; set a 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set b 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set c 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set d 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set e 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set f 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "a"</span><br><span class="line">   2) "e"</span><br><span class="line">   3) "b"</span><br><span class="line">   4) "d"</span><br><span class="line">   5) "f"</span><br><span class="line">   6) "c"</span><br></pre></td></tr></table></figure></li></ol><p><code>RDB</code>被动保存成功生成了<code>rdb</code>文件及日志,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker exec -it lredis ls /data</span><br><span class="line">dump.rdb</span><br></pre></td></tr></table></figure></p><p>日志记录,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1:M 24 Oct 2018 09:47:49.394 * DB loaded from disk: 0.000 seconds</span><br><span class="line">1:M 24 Oct 2018 09:47:49.394 * Ready to accept connections</span><br><span class="line">1:M 24 Oct 2018 09:48:48.758 * 5 changes in 20 seconds. Saving...</span><br><span class="line">1:M 24 Oct 2018 09:48:48.759 * Background saving started by pid 25</span><br><span class="line">25:C 24 Oct 2018 09:48:48.768 * DB saved on disk</span><br><span class="line">25:C 24 Oct 2018 09:48:48.769 * RDB: 0 MB of memory used by copy-on-write</span><br><span class="line">1:M 24 Oct 2018 09:48:48.860 * Background saving terminated with success</span><br></pre></td></tr></table></figure></p><p>日志提示<code>redis</code>检测到<code>20</code>秒内有至少<code>5</code>条记录被改动，满足<code>redis.conf</code>中对于<code>RDB</code>数据保存的条件，所以这里执行数据保存操作，并且提示开辟了一个<code>25</code>的进程出来执行保存操作，最后提示保存成功;</p><p>现在将redis进程kill，哪些数据会被保存？</p><p>通过命令<code>docker restart lredis</code>模拟<code>Redis</code>异常关闭，然后再启动<code>Redis</code>，再次查看之前<code>set</code>设置的内容,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "b"</span><br><span class="line">   2) "e"</span><br><span class="line">   3) "f"</span><br><span class="line">   4) "d"</span><br><span class="line">   5) "a"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p><p>发现<code>c</code>不见了， 可见<code>RDB</code>方式的数据完整性是不可靠的，除非断掉的那一刻正好是满足触发条件的条数;</p><p>关闭<code>RDB</code>方式持久化<br>修改<code>redis.conf</code>配置为,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">save ""</span><br><span class="line"><span class="meta">#</span><span class="bash">save 900 1</span></span><br><span class="line"><span class="meta">#</span><span class="bash">save 300 10</span></span><br><span class="line"><span class="meta">#</span><span class="bash">save 20 5</span></span><br></pre></td></tr></table></figure></p><p>重复上述<code>RDB</code>被动保存过程,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">➜ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "a"</span><br><span class="line">   2) "d"</span><br><span class="line">   3) "c"</span><br><span class="line">   4) "e"</span><br><span class="line">   5) "b"</span><br><span class="line">127.0.0.1:6379&gt; set f 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set i 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set j 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "a"</span><br><span class="line">   2) "j"</span><br><span class="line">   3) "f"</span><br><span class="line">   4) "d"</span><br><span class="line">   5) "c"</span><br><span class="line">   6) "e"</span><br><span class="line">   7) "b"</span><br><span class="line">   8) "i"</span><br><span class="line">127.0.0.1:6379&gt; exit</span><br><span class="line">➜ docker restart lredis</span><br><span class="line">lredis</span><br><span class="line">➜ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "e"</span><br><span class="line">   2) "d"</span><br><span class="line">   3) "b"</span><br><span class="line">   4) "c"</span><br><span class="line">   5) "a"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p><p>发现后面添加的<code>3</code>条记录并没有被保存，恢复数据的时候仅仅只是恢复了之前的<code>5</code>条。并且观察<code>Redis</code>服务端窗口日志，并未发现像之前一样的触发保存的提示，证明<code>RDB</code>方式已经被关闭;</p><p>通过配置文件关闭被动触发，那么主动关闭是否还会生效呢？</p><ol start="2"><li><strong><code>RDB</code>主动保存实践</strong><br>通过<code>del</code>命令删除几条记录，然后输入<code>save</code>命令执行保存操作,<br>input opt<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "e"</span><br><span class="line">   2) "d"</span><br><span class="line">   3) "b"</span><br><span class="line">   4) "c"</span><br><span class="line">   5) "a"</span><br><span class="line">127.0.0.1:6379&gt; del e d</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "b"</span><br><span class="line">   2) "c"</span><br><span class="line">   3) "a"</span><br><span class="line">127.0.0.1:6379&gt; save</span><br><span class="line">OK</span><br></pre></td></tr></table></figure></li></ol><p>log output<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1:M 24 Oct 2018 10:09:55.295 * Ready to accept connections</span><br><span class="line">1:M 24 Oct 2018 10:14:28.366 * DB saved on disk</span><br></pre></td></tr></table></figure></p><p>然后执行 <code>docker restart lredis</code>,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker restart lredis</span><br><span class="line">lredis</span><br><span class="line">➜  ~ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "a"</span><br><span class="line">   2) "c"</span><br><span class="line">   3) "b"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p><p>可以看到当<code>RDB</code>被动保存关闭后，可以通过主动<code>save</code>保存成功, 证明主动关闭不受 配置文件的影响;</p><p>除了save还有其他的保存方式么？</p><p><code>Redis</code>提供了<code>save</code>和<code>bgsave</code>这两种不同的保存方式, 并且这两个方式在执行的时候都会调用<code>rdbSave</code>函数，但它们调用的方式各有不同:</p><blockquote><p><code>save</code>直接调用<code>rdbSave</code>方法, 阻塞<code>Redis</code>主进程，直到保存完成为止。在主进程阻塞期间，服务器不能处理客户端的任何请求。</p></blockquote><blockquote><p><code>bgsave</code>则<code>fork</code>出一个子进程，子进程负责调用<code>rdbSave</code>，并在保存完成之后向主进程发送信号，通知保存已完成。因为<code>rdbSave</code>在子进程被调用，所以 <code>Redis</code>服务器在<code>bgsave</code>执行期间仍然可以继续处理客户端的请求。</p></blockquote><p>显然， <code>save</code>是同步操作, <code>bgsave</code>是异步操作。bgsave命令的使用方法和save命令的使用方法是一样的,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "a"</span><br><span class="line">   2) "c"</span><br><span class="line">   3) "b"</span><br><span class="line">127.0.0.1:6379&gt; set e 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set d 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; bgsave</span><br><span class="line">Background saving started</span><br></pre></td></tr></table></figure></p><p><code>redis</code>除了提供<code>save</code>和<code>bgsave</code>来保存数据外, 还可以通过<code>shutdown</code>命令来保存数据，不过要让<code>shutdown</code>保存数据生效需要打开持久化配置才行，即应将<code>redis.conf</code>中的配置从<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">save ""</span><br></pre></td></tr></table></figure></p><p>修改为如下，打开被动保存持久化配置才生效;<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure></p><p>总结<code>RDB</code>持久化有<code>被动保存</code>和<code>主动保存</code>两种方式，</p><blockquote><p>被动保存即通过<code>redis.conf</code>通过保存条件触发被动保存，这种情况数据有可能丢失;<br>主动保存即通过显示执行<code>save</code>, <code>bgsave</code>,<code>shutdown(在被动保存配置下才生效)</code>命令，这种情况数据不会丢失;</p></blockquote><h5 id="AOF方式持久化"><a href="#AOF方式持久化" class="headerlink" title="AOF方式持久化"></a>AOF方式持久化</h5><hr><p><code>redis</code>默认没有开启<code>AOF</code>，需要修改redis.conf配置文件中开启,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 将appendonly改为 yes</span></span><br><span class="line">appendonly yes</span><br></pre></td></tr></table></figure></p><p><code>AOF</code>可以需要设置同步方式<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">appendfsync always  # 每次有数据修改发生时都会写入AOF文件（安全但是费时）。</span><br><span class="line">appendfsync everysec  # 每秒钟同步一次，该策略为AOF的缺省策略。</span><br><span class="line">appendfsync no  # 从不同步。高效但是数据不会被持久化。</span><br></pre></td></tr></table></figure></p><p>根据上面的设置重启<code>redis</code>后，可见<code>data</code>目录下已创建了<code>aof</code>空文件,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker exec -it lredis ls -lh /data</span><br><span class="line">total 4.0K</span><br><span class="line">-rw-r--r-- 1 redis redis   0 Oct 24 10:31 appendonly.aof</span><br><span class="line">-rw-r--r-- 1 redis redis 122 Oct 24 10:20 dump.rdb</span><br></pre></td></tr></table></figure></p><p>input<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; set name china</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set age 80</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set city "shanghai.china"</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "age"</span><br><span class="line">   2) "name"</span><br><span class="line">   3) "city"</span><br><span class="line">127.0.0.1:6379&gt; quit</span><br><span class="line">➜  ~ docker exec -it lredis cat /data/appendonly.aof</span><br><span class="line">*2</span><br><span class="line"><span class="meta">$</span><span class="bash">6</span></span><br><span class="line">SELECT</span><br><span class="line"><span class="meta">$</span><span class="bash">1</span></span><br><span class="line">0</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">name</span><br><span class="line"><span class="meta">$</span><span class="bash">5</span></span><br><span class="line">china</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">age</span><br><span class="line"><span class="meta">$</span><span class="bash">2</span></span><br><span class="line">80</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">city</span><br><span class="line"><span class="meta">$</span><span class="bash">14</span></span><br><span class="line">shanghai.china</span><br><span class="line">➜  ~ docker exec -it lredis ls -lh /data</span><br><span class="line">total 8.0K</span><br><span class="line">-rw-r--r-- 1 redis redis 131 Oct 24 10:35 appendonly.aof</span><br><span class="line">-rw-r--r-- 1 redis redis 122 Oct 24 10:20 dump.rdb</span><br></pre></td></tr></table></figure></p><p>由上可见, <code>appendonly.aof</code>文件由<code>0</code>增大到<code>131</code> bytes, 可见<code>AOF</code>方式持久化成功了， 可以看见<code>appendonly.aof</code>文件中不仅仅保存了设置的变量及值，这些变量及值前后还有一些特殊的符号，这正是根据<code>redis</code>采用的<code>RESP</code>文本协议生成的， 详情可见之前总结的 <a href="http://researchlab.github.io/2018/10/09/redis-12-resp/">redis专题12 redis通信协议</a><br>分析<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">14</span></span><br><span class="line">shanghai.china</span><br><span class="line">多字符用$开头， $后边紧跟字符串的长度, 然后是 \r\n, 然后是字符串值本身</span><br></pre></td></tr></table></figure></p><blockquote><p><code>AOF</code> 同样也会把<code>del</code>等执行命令保存到<code>AOF</code>文件中;</p></blockquote><blockquote><p>当关闭<code>RDB</code>持久化方式， 只打开<code>AOF</code>方式时， 显示执行<code>save</code>和<code>bgsave</code> 都会将当前数据同时保存到<code>AOF</code>文件和<code>RDB</code>文件中;</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">➜ docker exec -it lredis ls -lh /data</span><br><span class="line">total 0</span><br><span class="line">-rw-r--r-- 1 redis redis 0 Oct 24 10:55 appendonly.aof</span><br><span class="line">➜ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; set name china</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set age 80</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; quit</span><br><span class="line">➜ docker exec -it lredis ls -lh /data</span><br><span class="line">total 4.0K</span><br><span class="line">-rw-r--r-- 1 redis redis 87 Oct 24 10:55 appendonly.aof</span><br><span class="line">➜ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; set city shanghai</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; save</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; quit</span><br><span class="line">➜ docker exec -it lredis ls -lh /data</span><br><span class="line">total 8.0K</span><br><span class="line">-rw-r--r-- 1 redis redis 124 Oct 24 10:56 appendonly.aof</span><br><span class="line">-rw-r--r-- 1 redis redis 131 Oct 24 10:56 dump.rdb</span><br><span class="line">➜ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; set local library</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; bgsave</span><br><span class="line">Background saving started</span><br><span class="line">127.0.0.1:6379&gt; quit</span><br><span class="line">➜ docker exec -it lredis ls -lh /data</span><br><span class="line">total 8.0K</span><br><span class="line">-rw-r--r-- 1 redis redis 161 Oct 24 10:56 appendonly.aof</span><br><span class="line">-rw-r--r-- 1 redis redis 146 Oct 24 10:56 dump.rdb</span><br><span class="line">➜ docker exec -it lredis cat /data/appendonly.aof</span><br><span class="line">*2</span><br><span class="line"><span class="meta">$</span><span class="bash">6</span></span><br><span class="line">SELECT</span><br><span class="line"><span class="meta">$</span><span class="bash">1</span></span><br><span class="line">0</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">name</span><br><span class="line"><span class="meta">$</span><span class="bash">5</span></span><br><span class="line">china</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">age</span><br><span class="line"><span class="meta">$</span><span class="bash">2</span></span><br><span class="line">80</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">city</span><br><span class="line"><span class="meta">$</span><span class="bash">8</span></span><br><span class="line">shanghai</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">5</span></span><br><span class="line">local</span><br><span class="line"><span class="meta">$</span><span class="bash">7</span></span><br><span class="line">library</span><br></pre></td></tr></table></figure><p>从<code>RDB</code>方式切换到<code>AOF</code>方式<br>在<code>Redis2.2</code>或以上版本，可以在不重启的情况下，从<code>RDB</code>切换到<code>AOF</code>,<br>为最新的<code>dump.rdb</code>文件创建一个备份、将备份放到一个安全的地方。执行以下两条命令:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli config set appendonly yes</span><br><span class="line">redis-cli config set save “”</span><br></pre></td></tr></table></figure></p><blockquote><p>执行的第一条命令开启了<code>AOF</code>功能: <code>Redis</code>会阻塞直到初始<code>AOF</code>文件创建完成为止, 之后<code>Redis</code>会继续处理命令请求, 并开始将写入命令追加到<code>AOF</code>文件末尾;<br>通过上述<code>CONFIG SET</code>命令设置的配置， 在重启<code>redis</code>服务器之后将失效，重启会依然按照之前的配置启动，所以建议在<code>redis.conf</code>配置中也应同步修改;</p></blockquote><h5 id="备份建议"><a href="#备份建议" class="headerlink" title="备份建议"></a>备份建议</h5><hr><p>确保你的数据有完整的备份，磁盘故障、节点失效等问题问题可能让你的数据消失不见， 不进行备份是非常危险的。<br><code>Redis</code>对于数据备份是非常友好的， 因为你可以在服务器运行的时候对<code>RDB</code>文件进行复制, RDB 文件一旦被创建, 就不会进行任何修改。 当服务器要创建一个新的<code>RDB</code>文件时，先将文件的内容保存在一个临时文件里面, 当临时文件写入完毕时, 程序才使用<code>rename(2)</code>原子地用临时文件替换原来的<code>RDB</code>文件。<br>即无论何时, 复制<code>RDB</code>文件都是绝对安全的。</p><blockquote><p>创建一个定期任务, 每小时将一个<code>RDB</code>文件备份到一个文件夹, 并且每天将一个<code>RDB</code>文件备份到另一个文件夹;</p></blockquote><blockquote><p>确保快照的备份都带有相应的日期和时间信息, 每次执行定期任务脚本时, 使用 find 命令来删除过期的快照, 比如保留最近<code>48</code>小时内的每小时快照, 还可以保留最近一两个月的每日快照;</p></blockquote><blockquote><p>至少每天一次, 将<code>RDB</code> 备份到你的数据中心之外, 或者至少是备份到你运行<code>Redis</code>服务器的物理机器之外;</p></blockquote><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><hr><ul><li>为实践<code>redis</code>持久化机制，创建了<code>docker</code>容器环境;</li><li>针对<code>RDB</code>方式持久化，分别测试了其主动保存和被动保存机制， 被动保存存在丢数据的可能，而主动保存则不会， 被动保存通过配置触发保存条件实现, 主动保存主要通过显示执行<code>save</code>,<code>bgsave</code>,<code>shutdown(需开启被动保存)</code>来执行数据保存操作;</li><li>针对<code>AOF</code>方式持久化进行了实例分析测试，<code>AOF</code> 开启后自动保存操作记录到<code>AOF</code>文件， 当显示执行<code>save</code>, <code>bgsave</code>,<code>shutdown</code>操作时也会自动保存数据到<code>AOF</code>和<code>RDB</code>文件中；</li><li>探讨了在不停服情况下从<code>RDB</code>方式切换至<code>AOF</code>的方法，并给出了几点备份建议;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;通过示例分析，深入了解&lt;code&gt;redis&lt;/code&gt;数据持久化策略执行机制；&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题15 事务系列问题</title>
    <link href="http://researchlab.github.io/2018/10/12/redis-15-transaction/"/>
    <id>http://researchlab.github.io/2018/10/12/redis-15-transaction/</id>
    <published>2018-10-12T15:39:41.000Z</published>
    <updated>2018-11-09T01:39:38.578Z</updated>
    
    <content type="html"><![CDATA[<p>为了确保连续多个操作的原子性, 一个成熟的数据库通常都会有事务支持, <code>Redis</code> 也不例外, <code>Redis</code> 通过<code>MULTI</code>, <code>DISCARD</code>, <code>EXEC</code>, <code>WATCH</code>和<code>UNWATCH</code> 五个命令来实现事务功能;<br><a id="more"></a></p><h5 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h5><p>事务提供了一种”将多个命令打包， 然后一次性、按顺序地执行”的机制, 并且事务在执行的期间不会主动中断 —— 服务器在执行完事务中的所有命令之后, 才会继续处理其他客户端的其他命令。</p><h5 id="Redis事务"><a href="#Redis事务" class="headerlink" title="Redis事务"></a><code>Redis</code>事务</h5><p>一个基本<code>Redis</code>事务从MULIT命令开始一个事务, 然后将多个命令入队到事务中， 最后由<code>EXEC</code>命令触发事务,</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; `MULTI`</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set name mike</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; incr name</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; set city shanghai</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; get city</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; `EXEC`</span><br><span class="line">1) OK</span><br><span class="line">2) (error) ERR value is not an integer or out of range</span><br><span class="line">3) OK</span><br><span class="line">4) "mike"</span><br><span class="line">5) "shanghai"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><ul><li><code>MULTI</code>命令唯一做的就是, 将客户端的 <code>Redis</code>_<code>MULTI</code> 选项打开, 让客户端从非事务状态切换到事务状态;</li><li>当客户端处于非事务状态下时， 所有发送给服务器端的命令都会立即被服务器执行; 当客户端进入事务状态之后, 服务器在收到来自客户端的命令时, 不会立即执行命令, 而是将这些命令全部放进一个事务队列里, 然后返回QUEUED, 表示命令已入队;</li><li>事务队列里的所有命令被执行完之后, <code>EXEC</code>命令会将回复队列作为自己的执行结果返回给客户端, 客户端从事务状态返回到非事务状态, 事务执行完毕;</li><li>从上述示例中可得当<code>incr name</code>失败后, 依然继续执行后继的<code>set city</code>等命令，可见<code>Redis</code>事务不保证执行<code>原子性</code>操作, 仅满足<code>隔离性</code>执行;</li></ul><p>事务与非事务状态的区别<br>事务中的命令和普通命令在执行上还是有一点区别的，其中最重要的两点是：</p><blockquote><p>非事务状态下的命令以单个命令为单位执行，前一个命令和后一个命令的客户端不一定是同一个; 而事务状态则是以一个事务为单位，执行事务队列中的所有命令:除非当前事务执行完毕，否则服务器不会中断事务，也不会执行其他客户端的其他命令;</p></blockquote><blockquote><p>在非事务状态下, 执行命令所得的结果会立即被返回给客户端; 而事务则是将所有命令的结果集合到回复队列，再作为<code>EXEC</code>命令的结果返回给客户端;</p></blockquote><ul><li>并不是所有的命令都会被放进事务队列, 其中的例外就是<code>EXEC</code>, <code>DISCARD</code>, <code>MULTI</code>和<code>WATCH</code>及<code>UNWATCH</code>命令;</li></ul><blockquote><p><code>DISCARD</code> 命令用于取消一个事务, 它清空客户端的整个事务队列, 然后将客户端从事务状态调整回非事务状态, 最后返回字符串OK给客户端, 说明事务已被取消;</p></blockquote><blockquote><p><code>Redis</code>的事务是不可嵌套的, 当客户端已经处于事务状态, 而客户端又再向服务器发送<code>MULTI</code>时, 服务器只是简单地向客户端发送一个错误, 然后继续等待其他命令的入队; <code>MULTI</code>命令的发送不会造成整个事务失败, 也不会修改事务队列中已有的数据;</p></blockquote><blockquote><p><code>WATCH</code>只能在客户端进入事务状态之前执行, 在事务状态下发送 <code>WATCH</code> 命令会引发一个错误, 但它不会造成整个事务失败, 也不会修改事务队列中已有的数据(和前面处理 <code>MULTI</code> 的情况一样);</p></blockquote><blockquote><p><code>WATCH</code>命令用于在事务开始之前监视任意数量的键, 当调用<code>EXEC</code>命令执行事务时, 如果任意一个被监视的键已经被其他客户端修改了, 那么整个事务不再执行, 直接返回失败;</p></blockquote><h5 id="与MySQL事务的区别"><a href="#与MySQL事务的区别" class="headerlink" title="与MySQL事务的区别"></a>与<code>MySQL</code>事务的区别</h5><p>在<code>MySQL</code>中只有使用了Innodb数据库引擎的数据库或表才支持事务;</p><blockquote><p>事务使用的目的是统一管理insert, update, delete 这些write操作，以此来维护数据完整性。</p></blockquote><p><strong>命令区别</strong><br><code>MySQL</code></p><blockquote><p><code>BEGIN</code>: 显式地开启一个事务;<br><code>COMMIT</code>: 提交事务，将对数据库进行的所有修改变成为永久性的;<br><code>ROLLBACK</code>: 结束用户的事务，并撤销正在进行的所有未提交的修改;</p></blockquote><p><code>Redis</code></p><blockquote><p><code>MULTI</code>: 标记事务的开始;<br><code>EXEC</code>: 执行事务的commands队列;<br><code>DISCARD</code>: 结束事务，并清除commands队列;</p></blockquote><p><strong>默认状态</strong><br><code>MySQL</code></p><blockquote><p><code>MySQL</code>会默认开启一个事务，且缺省设置是自动提交，即，每成功执行一个SQL，一个事务就会马上 <code>COMMIT</code>。所以不能<code>ROLLBACK</code>。</p></blockquote><p><code>Redis</code></p><blockquote><p><code>Redis</code>默认不会开启事务，即command会立即执行，而不会排队。并不支持<code>ROLLBACK</code></p></blockquote><p><strong>使用方式</strong><br><code>MySQL</code>包含两种</p><blockquote><p>用<code>BEGIN</code>, <code>ROLLBACK</code>, <code>COMMIT</code> 显式开启并控制一个 <code>新的</code> Transaction。<br>执行命令<code>SET AUTOCOMMIT=0</code>, 用来禁止当前会话自动<code>COMMIT</code>, 控制默认开启的事务。</p></blockquote><p><code>Redis</code></p><blockquote><p>用<code>MULTI</code>, <code>EXEC</code>, <code>DISCARD</code>, 显式开启并控制一个<code>Transaction</code>(注意这里没有强调<code>新的</code>, 因为默认是不会开启事务的);</p></blockquote><p><strong>实现原理</strong><br>显然<code>Redis</code>与<code>MySQL</code>中事务的区别其根本原因就是实现不同方式造成的;</p><p><code>MySQL</code></p><blockquote><p><code>MySQL</code>实现事务，是基于<code>UNDO/REDO</code>日志;<br><code>UNDO日志</code>记录修改前状态, <code>ROLLBACK</code>基于<code>UNDO日志</code>实现;<br><code>REDO日志</code>记录修改后的状态, <code>COMMIT</code>基于<code>REDO日志</code>实现;<br>在<code>MySQL</code>中无论是否开启事务, 每一个<code>SQL</code>都会被立即执行并返回执行结果。但是事务开启后执行后的状态只是记录在<code>REDO日志</code>, 执行<code>COMMIT</code>, 数据才会被写入磁盘。</p></blockquote><p><code>Redis</code></p><blockquote><p><code>Redis</code>实现事务, 是基于<code>COMMANDS</code>队列;<br>如果没有开启事务, <code>command</code>将会被立即执行并返回执行结果, 并且直接写入磁盘;<br>如果事务开启, <code>command</code>不会被立即执行, 而是排入队列并返回排队状态。调用<code>EXCE</code>才会执行<code>COMMANDS</code>队列;</p></blockquote><h5 id="不支持回滚"><a href="#不支持回滚" class="headerlink" title="不支持回滚"></a>不支持回滚</h5><p><code>Redis</code>事务不支持回滚, 官方解释, </p><blockquote><p><code>Redis</code>命令只会因为错误的语法而失败(并且这些问题不能在入队时发现), 或是命令用在了错误类型的键上面; 从实用性的角度来说, 失败的命令是由编程错误造成的, 而这些错误应该在开发的过程中被发现, 而不应该出现在生产环境中;<br>因为不需要对回滚进行支持，所以<code>Redis</code>的内部可以保持简单且快速;</p></blockquote><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>事务提供了一种将多个命令打包, 然后一次性, 有序地执行的机制; 且在执行过程中不会被中断, 所有事务命令执行完之后, 事务才能结束;</li><li>多个命令会被入队到事务队列中，然后按先进先出（FIFO）的顺序执行;</li><li><code>Redis</code>事务仅保证了事务的隔离执行; 不保证原子性：<code>Redis</code>同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚;</li><li>可以通过管道技术对事务进行优化;</li><li>通过<code>WATCH</code>命令在事务执行之前监控了多个Keys，倘若在<code>WATCH</code>之后有任何Key的值发生了变化，<code>EXEC</code>命令执行的事务都将被放弃，同时返回Null<code>MULTI</code>-bulk应答以通知调用者事务执行失败</li><li>悲观锁(Pessimistic Lock), 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁;</li><li>乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改, 所以不会上锁, 但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，乐观锁策略:提交版本必须大于记录当前版本才能执行更新;</li><li>对比分析了<code>Redis</code>事务与<code>MySQL</code>事务的异同点;</li><li>从官方解释中阐述为何<code>Redis</code>事务没有必要支持回滚机制;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;为了确保连续多个操作的原子性, 一个成熟的数据库通常都会有事务支持, &lt;code&gt;Redis&lt;/code&gt; 也不例外, &lt;code&gt;Redis&lt;/code&gt; 通过&lt;code&gt;MULTI&lt;/code&gt;, &lt;code&gt;DISCARD&lt;/code&gt;, &lt;code&gt;EXEC&lt;/code&gt;, &lt;code&gt;WATCH&lt;/code&gt;和&lt;code&gt;UNWATCH&lt;/code&gt; 五个命令来实现事务功能;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题14 性能提升之管道技术</title>
    <link href="http://researchlab.github.io/2018/10/11/redis-14-pipeline/"/>
    <id>http://researchlab.github.io/2018/10/11/redis-14-pipeline/</id>
    <published>2018-10-11T15:37:51.000Z</published>
    <updated>2018-11-09T01:39:38.578Z</updated>
    
    <content type="html"><![CDATA[<p>用<code>redis管道技术</code>对执行结果没有互相依赖，对结果响应也无需立即获得的命令集批量提交到<code>redis</code>服务器的方式，能在一定程度上提升<code>redis</code>性能，性能提升的原因主要是TCP连接中减少了<code>交互往返</code>的时间。<br><a id="more"></a></p><blockquote><p><code>Redis管道(Pipeline)</code>本身并不是<code>Redis</code>服务器直接提供的技术，这个技术本质上是由客户端提供的，跟服务器没有什么直接的关系。</p></blockquote><h5 id="消息交互"><a href="#消息交互" class="headerlink" title="消息交互"></a>消息交互</h5><p><code>redis</code>是使用客户端-服务器模型的TCP服务器，称为请求/响应协议。<br>这意味着通常一个请求是通过以下步骤完成的:</p><blockquote><p>客户端向服务器发送查询，并通常以阻塞的方式从套接字读取服务器响应。<br>服务器处理命令并将响应发送回客户端。</p></blockquote><p>每一个<code>redis</code>命令request/response都需要经历一个<code>RTT</code>(Round-Trip Time 往返时间), 如果需要执行很多短小的命令，这些往返时间的开销是很大的，在此情形下，redis提出了<code>管道</code>来提高执行效率。</p><h5 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h5><blockquote><p>如果client执行一些相互之间无关的命令或者不需要获取命令的返回值，那么redis允许你连续发送多条命令，而不需要等待前面命令执行完毕;</p></blockquote><blockquote><p>比如我们执行3条INCR命令，如果使用管道，理论上只需要一个RTT+3条命令的执行时间即可，如果不适用管道，那么可能需要额外的两个RTT时间;</p></blockquote><blockquote><p>因此，管道相当于批处理脚本，相当于是命令集;</p></blockquote><blockquote><p>执行管道命令中, <code>redis</code>必须在处理完所有命令前先缓存起所有命令的处理结果。打包的命令越多，缓存消耗内存也越多。所以并不是打包的命令越多越好。具体多少合适需要根据具体情况测试。</p></blockquote><p><strong>注意</strong></p><blockquote><p>执行<code>管道</code>命令期间将<code>独占</code>链接，此期间将不能进行非<code>管道</code>类型的其他操作，直到管道关闭；</p></blockquote><blockquote><p>如果<code>管道</code>的指令集很庞大，为了不干扰链接中的其他操作，建议为<code>管道</code>操作新建Client链接，让<code>管道</code>和其他正常操作分离在2个client中; </p></blockquote><blockquote><p>不过<code>管道</code>事实上所能容忍的操作个数，和socket-output缓冲区大小/返回结果的数据尺寸都有很大的关系；同时也意味着每个redis-server同时所能支撑的管道链接的个数，也是有限的，这将受限于server的物理内存或网络接口的缓冲能力。</p></blockquote><h5 id="压力测试"><a href="#压力测试" class="headerlink" title="压力测试"></a>压力测试</h5><p>Redis 自带了一个压力测试工具redis-benchmark，使用这个工具就可以进行管道测试。</p><p>对一个普通的<code>set</code>指令进行压测，QPS 大约<code>6w/s</code>。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  02 docker exec -it redisbloom redis-benchmark -t set -q</span><br><span class="line">SET: 64350.06 requests per second</span><br></pre></td></tr></table></figure></p><p><code>-P</code>参数，表示单个管道内并行的请求数量，看下面<code>P=2</code>，QPS 达到了<code>8w/s</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it redisbloom redis-benchmark -t set -q -P 2</span><br><span class="line">SET: 89365.51 requests per second</span><br></pre></td></tr></table></figure><p>再看看<code>P=5</code>，<code>QPS</code>达到了<code>10w/s</code>。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  02 docker exec -it redisbloom redis-benchmark -t set -q -P 5</span><br><span class="line">SET: 106723.59 requests per second</span><br></pre></td></tr></table></figure></p><p>但如果再继续提升<code>P</code>参数，发现<code>QPS</code>已经上不去了。这是为什么呢？</p><p>因为这里<code>CPU</code>处理能力已经达到了瓶颈，<code>Redis</code>的单线程<code>CPU</code>已经飙到了<code>100%</code>，所以无法再继续提升了。</p><p>深入理解管道本质<br>接下来我们深入分析一个请求交互的流程，真实的情况是它很复杂，因为要经过网络协议栈，这个就得深入内核了。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">client ---&gt; request  ---&gt; send buffer ---&gt; NIC ---&gt; Gateway Router ---&gt; NIC ---&gt; recv buffer ---&gt; request  ---&gt; server </span><br><span class="line">                                                                                                                 |</span><br><span class="line">client &lt;--- response &lt;--- recv buffer &lt;--- NIC &lt;--- Gateway Router &lt;--- NIC &lt;--- send buffer &lt;--- response &lt;---  V</span><br></pre></td></tr></table></figure></p><p>上图就是一个完整的请求交互流程图,</p><ol><li>客户端进程调用<code>write</code>将消息写到操作系统内核为套接字分配的发送缓冲<code>send buffer</code>;</li><li>客户端操作系统内核将发送缓冲的内容发送到<code>网卡</code>，<code>网卡</code>硬件将数据通过「路由」送到服务器的<code>网卡</code>;</li><li>服务器操作系统内核将<code>网卡</code>的数据放到内核为套接字分配的接收缓冲<code>recv buffer</code>;</li><li>服务器进程调用<code>read</code>从接收缓冲中取出消息进行处理;</li><li>服务器进程调用<code>write</code>将响应消息写到内核为套接字分配的发送缓冲<code>send buffer</code>;</li><li>服务器操作系统内核将发送缓冲的内容发送到<code>网卡</code>，<code>网卡</code>硬件将数据通过「路由」送到客户端的<code>网卡</code>。</li><li>客户端操作系统内核将<code>网卡</code>的数据放到内核为套接字分配的接收缓冲<code>recv buffer</code>;</li><li>客户端进程调用<code>read</code>从接收缓冲中取出消息返回给上层业务逻辑进行处理;</li></ol><blockquote><p><code>write</code>操作不是等到对方收到消息才会返回。<code>write</code>操作只负责将数据写到本地操作系统内核的发送缓冲然后就返回了。剩下的事交给操作系统内核异步将数据送到目标机器。但是如果发送缓冲满了，那么就需要等待缓冲空出空闲空间来，这个就是写操作<code>IO</code>操作的真正耗时。</p></blockquote><blockquote><p><code>read</code>操作不是从目标机器拉取数据。<code>read</code>操作只负责将数据从本地操作系统内核的接收缓冲中取出来就了事了。但是如果缓冲是空的，那么就需要等待数据到来，这个就是读操作<code>IO</code>操作的真正耗时。</p></blockquote><p>所以对于<code>value = redis.get(key)</code>这样一个简单的请求来说，<code>write</code>操作几乎没有耗时，直接写到发送缓冲就返回，而<code>read</code>就会比较耗时了，因为它要等待消息经过网络路由到目标机器处理后的响应消息,再回送到当前的内核读缓冲才可以返回。这才是一个网络来回的真正开销。</p><p>而对于管道来说，连续的<code>write</code>操作根本就没有耗时，之后第一个<code>read</code>操作会等待一个网络的来回开销，然后所有的响应消息就都已经回送到内核的读缓冲了，后续的<code>read</code>操作直接就可以从缓冲拿到结果，瞬间就返回了。</p><h5 id="管道VS事务"><a href="#管道VS事务" class="headerlink" title="管道VS事务"></a>管道VS事务</h5><blockquote><p>管道和事务是不同的，pipeline只是表达”交互”中操作的传递的方向性，pipeline也可以在事务中运行，也可以不在。</p></blockquote><blockquote><p>无论如何，pipeline中发送的每个command都会被server立即执行，如果执行失败，将会在此后的相应结果集中得到信息；也就是pipeline并不是表达”所有command都一起成功”的语义，管道中前面命令失败，后面命令不会有影响，继续执行。</p></blockquote><blockquote><p>简单来说就是管道中的命令是没有关系的，它们只是像管道一样流水发给server，而不是串行执行，仅此而已; 但是如果pipeline的操作被封装在事务中，那么将有事务来确保操作的成功与失败。</p></blockquote><blockquote><p>pipeline 只是把多个redis指令一起发出去，redis并没有保证这些指定的执行是原子的；multi相当于一个redis的transaction的，保证整个操作的原子性，避免由于中途出错而导致最后产生的数据不一致</p></blockquote><h5 id="管道VS脚本"><a href="#管道VS脚本" class="headerlink" title="管道VS脚本"></a>管道VS脚本</h5><blockquote><p>使用管道可能在效率上比使用script要好，但是有的情况下只能使用script。因为在执行后面的命令时, 无法得到前面命令的结果，就像事务一样，所以如果需要在后面命令中使用前面命令的value等结果，则只能使用script或者事务+watch;</p></blockquote><blockquote><p>使用Redis脚本(在Redis版本2.6+), 可以使用执行服务器端所需的大量工作的脚本更高效地处理一些pipelining用例;</p></blockquote><blockquote><p>脚本的一大优势是它能够以最小的延迟读取和写入数据，使得读取，计算，写入等操作非常快速(在这种情况下, 流水线操作无法提供帮助, 因为客户端先需要读命令的回应, 它才可以调用写命令);</p></blockquote><blockquote><p>有时，应用程序可能还想在管道中发送<code>EVAL</code>或<code>EVALSHA</code>命令。这是完全可能的，Redis通过SCRIPT LOAD命令明确地支持它(它保证可以调用EVALSHA而没有失败的风险);</p></blockquote><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>从分析<code>redis</code>采用<code>tcp</code>消息协议入手, 为进一步提升<code>redis</code>性能的角度，探讨了<code>管道</code>技术在<code>redis</code>中的应用;  </li><li>进一步分析了管道的原理, 因为<code>redis</code>需要在处理完管道命令集前把之前的结果先缓存下来，所以管道并不是打包的命令越多越好，因为打包的命令越多占用的缓存也会相应的增大, 同时在执行管道命令完成前, 同一个<code>redis</code>连接无法继续执行非管道命令;</li><li>通过消息交互示例， 进一步深入分析了管道的本质，管道打包多条命令为客服端–服务端节省了往返(RTT)等待耗时, 因而进一步提升了<code>redis</code>性能;</li><li>最后对比分析了<code>管道</code>与<code>redis事务</code>, <code>redis脚本</code>之间的区别， 进一步阐述了<code>管道</code>，<code>事务</code>, <code>脚本</code>各自适用的场景;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;用&lt;code&gt;redis管道技术&lt;/code&gt;对执行结果没有互相依赖，对结果响应也无需立即获得的命令集批量提交到&lt;code&gt;redis&lt;/code&gt;服务器的方式，能在一定程度上提升&lt;code&gt;redis&lt;/code&gt;性能，性能提升的原因主要是TCP连接中减少了&lt;code&gt;交互往返&lt;/code&gt;的时间。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题13 数据存储与持久化</title>
    <link href="http://researchlab.github.io/2018/10/10/redis-13-data-storage-solution/"/>
    <id>http://researchlab.github.io/2018/10/10/redis-13-data-storage-solution/</id>
    <published>2018-10-10T12:36:10.000Z</published>
    <updated>2018-11-09T01:39:38.574Z</updated>
    
    <content type="html"><![CDATA[<p><code>redis</code>提供两种方式进行持久化，一种是<code>RDB</code>快照持久化(原理是将Reids在内存中的数据库记录压缩后定时dump到磁盘上的<code>RDB</code>持久化,存储紧凑)，另外一种是<code>AOF</code>(append only file)持久化(原理是将Reids的操作日志以追加的方式写入文件), <code>AOF</code> 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载<code>AOF</code>日志进行指令重放，这个时间就会无比漫长。所以需要定期进行<code>AOF</code>重写，给<code>AOF</code>日志进行瘦身。<br><a id="more"></a></p><h4 id="RDB快照原理"><a href="#RDB快照原理" class="headerlink" title="RDB快照原理"></a><code>RDB</code>快照原理</h4><p><code>RDB</code>(快照/内存快照)，就是<code>redis</code>按照一定的时间周期将目前服务中的所有数据全部写入到磁盘中。<br>我们知道<code>redis</code>是单线程程序，这个线程要同时负责多个客户端套接字的并发读写操作和内存数据结构的逻辑读写。</p><p>在服务线上请求的同时，<code>redis</code> 还需要进行内存快照，内存快照要求<code>redis</code> 必须进行文件IO操作，可<strong>文件IO操作是不能使用多路复用API</strong>。那该怎么办呢？</p><p><code>redis</code>使用操作系统的多进程<code>COW(Copy On Write) 机制</code>来实现快照持久化。</p><p><code>redis</code> 在持久化时会<code>fork</code>一个子进程，<strong>快照持久化完全交给子进程来处理，父进程继续处理客户端请求</strong>。子进程做数据持久化，它不会修改现有的内存数据结构，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。但是父进程不一样，它必须持续服务客户端请求，然后对内存数据结构进行不间断的修改。</p><p>这个时候就会使用操作系统的<code>COW机制</code>来进行数据段页面的分离。数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改。这时子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据。</p><p>随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，内存就会持续增长。但是也不会超过原有数据内存的<code>2</code>倍大小。另外一个<code>redis</code>实例里冷数据占的比例往往是比较高的，所以很少会出现所有的页面都会被分离，被分离的往往只有其中一部分页面。每个页面的大小只有<code>4K</code>，一个 <code>redis</code>实例里面一般都会有成千上万的页面。<br>原理过程<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">0.假设现在redis数据存储在内存的A区;</span><br><span class="line">1.此时因配置或某种原因触发了RDB快照事件;</span><br><span class="line">2.触发RDB快照事件后，父进程会先fork出一个子进程, 把处理RDB快照的事情完全交给这个子进程处理，而父进程则继续处理来自客服端的请求;</span><br><span class="line">3.子进程会先将当前内存A区数据压缩, 然后dump刷盘到一个临时RDB文件中, 当dump完成后，再将这个临时RDB文件替换之前的RDB文件, 然后子进程结束退出;</span><br><span class="line">4.同样，在子进程处理快照dump过程中, 如果父进程接收到新的客服端请求，则父进程需要先拷贝一份内存A区中相关数据页的信息到内存B区，然后在B区上完成客服端的请求; </span><br><span class="line">5.当父进程完成新的客服端请求后，发现子进程已经完成了RDB快照处理， 则将刚才更新的B区数据取替换A区数据, 如果子进程还没有完成则等待;</span><br></pre></td></tr></table></figure></p><h5 id="AOF-原理"><a href="#AOF-原理" class="headerlink" title="AOF 原理"></a><code>AOF</code> 原理</h5><p><code>AOF</code>日志存储的是<code>redis</code>服务器的顺序指令序列，<code>AOF</code>日志<strong>只记录对内存进行修改的指令记录(查询/删除指令是不记录的)</strong>。<br>假设 <code>AOF</code> 日志记录了自<code>redis</code>实例创建以来所有的修改性指令序列，那么就可以通过对一个空的<code>redis</code> 实例顺序执行所有的指令，也就是「重放」，来恢复<code>redis</code>当前实例的内存数据结构的状态。</p><p><code>redis</code>会在收到客户端修改指令后，进行参数校验进行逻辑处理后，如果没问题，就立即将该指令文本存储到<code>AOF</code>日志中，也就是先执行指令才将日志存盘。这点不同于<code>leveldb、hbase</code>等存储引擎，它们都是先存储日志再做逻辑处理。</p><p><code>redis</code> 在长期运行的过程中，<code>AOF</code> 的日志会越变越长。如果实例宕机重启，重放整个 <code>AOF</code> 日志会非常耗时，导致长时间<code>redis</code>无法对外提供服务。所以需要对 <code>AOF</code> 日志瘦身。</p><p><strong>AOF重写</strong><br><code>redis</code> 提供了<code>bgrewrite AOF</code>指令用于对 <code>AOF</code> 日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历转换成一系列 <code>redis</code> 的操作指令，序列化到一个新的 <code>AOF</code> 日志文件中。序列化完毕后再将操作期间发生的增量 <code>AOF</code> 日志追加到这个新的 <code>AOF</code> 日志文件中，追加完毕后就立即替代旧的 <code>AOF</code> 日志文件了，瘦身工作就完成了。</p><p><strong>fsync</strong><br><code>AOF</code> 日志是以文件的形式存在的，当程序对 <code>AOF</code> 日志文件进行写操作时，实际上是将内容写到了内核为文件描述符分配的一个内存缓存中，然后内核会异步将脏数据刷回到磁盘的。</p><p>这就意味着如果机器突然宕机，<code>AOF</code> 日志内容可能还没有来得及完全刷到磁盘中，这个时候就会出现日志丢失。那该怎么办？ 可以通过开启<code>fsync</code>配置来强制同步刷盘, 过于频繁的<code>fsync</code>会严重拖慢<code>redis</code>性能，所以在生产环境的服务器中，<code>redis</code> 通常是每隔<code>1s</code>左右执行一次<code>fsync</code>操作, 在保持高性能的同时，尽可能使得数据少丢失。</p><h5 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h5><p>重启 <code>redis</code> 时，我们很少使用 <code>RDB</code> 来恢复内存状态，因为会丢失大量数据。我们通常使用 <code>AOF</code> 日志重放，但是重放 <code>AOF</code> 日志性能相对 <code>RDB</code> 来说要慢很多，这样在<code>redis</code> 实例很大的情况下，启动需要花费很长的时间。</p><p><code>redis4.0</code>为了解决这个问题，带来了一个新的持久化选项——混合持久化。将 <code>RDB</code> 文件的内容和增量的 <code>AOF</code> 日志文件存在一起。这里的 <code>AOF</code> 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 <code>AOF</code> 日志，通常这部分 <code>AOF</code> 日志很小。</p><p>于是在<code>redis</code> 重启的时候，可以先加载 <code>RDB</code> 的内容，然后再重放增量 <code>AOF</code> 日志就可以完全替代之前的 <code>AOF</code> 全量文件重放，重启效率因此大幅得到提升。</p><h5 id="RDB优势"><a href="#RDB优势" class="headerlink" title="RDB优势"></a>RDB优势</h5><blockquote><p> 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。</p></blockquote><blockquote><p>对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。</p></blockquote><blockquote><p> 性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。</p></blockquote><blockquote><p> 相比于AOF机制，如果数据集很大，RDB的启动效率会更高。</p></blockquote><h5 id="RDB劣势"><a href="#RDB劣势" class="headerlink" title="RDB劣势"></a>RDB劣势</h5><blockquote><p>如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。</p></blockquote><blockquote><p>由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。</p></blockquote><h4 id="AOF优势"><a href="#AOF优势" class="headerlink" title="AOF优势"></a>AOF优势</h4><blockquote><p>该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言，我想大家都能正确的理解它。</p></blockquote><blockquote><p>由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。</p></blockquote><blockquote><p> 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。</p></blockquote><blockquote><p>AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。</p></blockquote><h5 id="AOF劣势"><a href="#AOF劣势" class="headerlink" title="AOF劣势"></a>AOF劣势</h5><blockquote><p> 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</p></blockquote><blockquote><p>根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。</p></blockquote><h5 id="常用配置"><a href="#常用配置" class="headerlink" title="常用配置"></a>常用配置</h5><p><strong>RDB持久化配置</strong><br>Redis会将数据集的快照dump到dump.rdb文件中。此外，我们也可以通过配置文件来修改Redis服务器dump快照的频率，在打开6379.conf文件之后，我们搜索save，可以看到下面的配置信息:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">save 900 1              #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。</span><br><span class="line"></span><br><span class="line">save 300 10            #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。</span><br><span class="line"></span><br><span class="line">save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。</span><br></pre></td></tr></table></figure></p><p><strong>AOF持久化配置</strong><br>在Redis的配置文件中存在三种同步方式，它们分别是:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">appendfsync always     #每次有数据修改发生时都会写入AOF文件。</span><br><span class="line"></span><br><span class="line">appendfsync everysec  #每秒钟同步一次，该策略为AOF的缺省策略。</span><br><span class="line"></span><br><span class="line">appendfsync no          #从不同步。高效但是数据不会被持久化。</span><br></pre></td></tr></table></figure></p><h5 id="过期策略"><a href="#过期策略" class="headerlink" title="过期策略"></a>过期策略</h5><p><strong>RDB过期key处理策略</strong></p><blockquote><p>已过期的键不会被保存到新创建的RDB文件中。举个例子，如果数据库中包含三个键k1、k2、k3，并且k2已经过期，那么当执行SAVE命令或者BGSAVE命令时，程序只会将k1和k3的数据保存到RDB文件中，而k2则会被忽略。因此，数据库中包含过期键不会对生成新的RDB文件造成影响。</p></blockquote><p>在启动Redis服务器时，如果服务器开启了RDB功能，那么服务器将对RDB文件进行载入:</p><blockquote><p>如果服务器以主服务器模式运行，那么在载入RDB文件时，程序会对文件中保存的键进行检查，未过期的键会被载入到数据库中，而过期键则会被忽略，所以过期键对载入RDB文件的主服务器不会造成影响；</p></blockquote><blockquote><p>如果服务器以从服务器模式运行，那么在载入RDB文件时，文件中保存的所有键，不论是否过期，都会被载入到数据库中。不过，因为主从服务器在进行数据同步的时候，从服务器的数据库就会被清空，所以一般来讲，过期键对载入RDB文件的从服务器也不会造成影响；</p></blockquote><p><strong>AOF过期key处理策略</strong></p><blockquote><p>当服务器以AOF持久化模式运行时，如果数据库中的某个键已经过期，但它还没有被惰性删除或者定期删除，那么AOF文件不会因为这个过期键而产生任何影响。<strong>当过期键被惰性删除或者定期删除之后，程序会向AOF文件追加（append）一条DEL命令，来显式地记录该键已被删除。</strong></p></blockquote><blockquote><p>和生成RDB文件时类似，在执行AOF重写的过程中，程序会对数据库中的键进行检查，已过期的键不会被保存到重写后的AOF文件中。举个例子，如果数据库中包含三个键k1、k2、k3，并且k2已经过期，那么在进行重写工作时，程序只会对k1和k3进行重写，而k2则会被忽略。</p></blockquote><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>在<code>redis</code>数据存储持久化机制上, 探讨了<code>RDB快照</code> 和 <code>AOF</code>两种持久化方案，对其原理,区别等进行了进一步的说明;</li><li>进一步探讨了<code>redis.4.0</code>提供的混合持久化方案;</li><li>归类总结了<code>RDB</code>和<code>AOF</code>两种方案的优缺点;</li><li>从经验出发， 进一步总结了实际中常用的配置方案;</li><li>进一步总结了<code>RDB</code>和<code>AOF</code>对过期key的处理策略;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;redis&lt;/code&gt;提供两种方式进行持久化，一种是&lt;code&gt;RDB&lt;/code&gt;快照持久化(原理是将Reids在内存中的数据库记录压缩后定时dump到磁盘上的&lt;code&gt;RDB&lt;/code&gt;持久化,存储紧凑)，另外一种是&lt;code&gt;AOF&lt;/code&gt;(append only file)持久化(原理是将Reids的操作日志以追加的方式写入文件), &lt;code&gt;AOF&lt;/code&gt; 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载&lt;code&gt;AOF&lt;/code&gt;日志进行指令重放，这个时间就会无比漫长。所以需要定期进行&lt;code&gt;AOF&lt;/code&gt;重写，给&lt;code&gt;AOF&lt;/code&gt;日志进行瘦身。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题12 redis通信协议</title>
    <link href="http://researchlab.github.io/2018/10/09/redis-12-resp/"/>
    <id>http://researchlab.github.io/2018/10/09/redis-12-resp/</id>
    <published>2018-10-09T15:34:03.000Z</published>
    <updated>2018-11-09T01:39:38.574Z</updated>
    
    <content type="html"><![CDATA[<p>Redis的客户端与服务端采用一种叫做<code>RESP(REdis Serialization Protocol)</code>的网络通信协议交换数据。 这种协议采用明文传输，易读也易解析。<code>Redis</code>客户端采用此协议格式来对服务端发送不同的命令，服务端会根据具体的操作而返回具体的答复。客户端和服务端采用的是简单的<code>请求-响应</code>模型进行通信的。<br><a id="more"></a></p><h5 id="RESP"><a href="#RESP" class="headerlink" title="RESP"></a>RESP</h5><p><code>RESP(Redis Serialization Protocol)</code>是 Redis序列化协议的简写。它是一种直观的文本协议，优势在于实现异常简单，解析性能极好。</p><p>Redis协议将传输的结构数据分为<code>5</code>种最小单元类型，单元结束时统一加上回车换行符号<code>\r\n</code>。</p><blockquote><p>单行字符串 以<code>+</code>符号开头。<br>多行字符串 以<code>$</code>符号开头，后跟字符串长度。<br>整数值 以<code>:</code>符号开头，后跟整数的字符串形式。<br>错误消息 以<code>-</code>符号开头。<br>数组 以<code>*</code>号开头，后跟数组的长度。</p></blockquote><p><strong>单行字符串</strong> <code>hello world</code><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">+hello world\r\n</span><br></pre></td></tr></table></figure></p><p><strong>多行字符串</strong> <code>hello world</code><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">11\r\nhello world\r\n</span></span><br></pre></td></tr></table></figure></p><p>多行字符串当然也可以表示单行字符串。</p><p><strong>整数</strong> <code>1024</code><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:1024\r\n</span><br></pre></td></tr></table></figure></p><p><strong>错误</strong> 参数类型错误<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-WRONGTYPE Operation against a key holding the wrong kind of value\r\n</span><br></pre></td></tr></table></figure></p><p><strong>数组</strong> <code>[1,2,3]</code><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*3\r\n:1\r\n:2\r\n:3\r\n</span><br></pre></td></tr></table></figure></p><p><code>NULL</code>用多行字符串表示，不过长度要写成<code>-1</code>。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">-1\r\n</span></span><br></pre></td></tr></table></figure></p><p><strong>空串</strong> 用多行字符串表示，长度填<code>0</code>。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">0\r\n\r\n</span></span><br></pre></td></tr></table></figure></p><p><strong>注:</strong> 这里有两个<code>\r\n</code>。为什么是两个?因为两个<code>\r\n</code>之间,隔的是空串。</p><h5 id="客户端-gt-服务器"><a href="#客户端-gt-服务器" class="headerlink" title="客户端 -&gt; 服务器"></a>客户端 -&gt; 服务器</h5><p><strong>客户端向服务器发送的指令只有一种格式，多行字符串数组</strong>。比如一个简单的<code>set</code>指令<code>set learn redis</code>会被序列化成下面的字符串。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*3\r\n$3\r\nset\r\n$6\r\nlearn\r\n$8\r\nredis\r\n</span><br></pre></td></tr></table></figure></p><h5 id="服务器-gt-客户端"><a href="#服务器-gt-客户端" class="headerlink" title="服务器 -&gt; 客户端"></a>服务器 -&gt; 客户端</h5><p>服务器向客户端回复的响应要支持多种数据结构，所以消息响应在结构上要复杂不少。不过再复杂的响应消息也是以上<code>5</code>中基本类型的组合。</p><p><strong>1.单行字符串响应</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set learn redis</span><br><span class="line">OK</span><br></pre></td></tr></table></figure></p><p>这里的<code>OK</code>就是单行响应，没有使用引号括起来。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">+OK</span><br></pre></td></tr></table></figure></p><p><strong>2.错误响应</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; incr learn </span><br><span class="line">(error) ERR value is not an integer or out of range</span><br></pre></td></tr></table></figure></p><p>试图对一个字符串进行自增，服务器抛出一个通用的错误。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-ERR value is not an integer or out of range</span><br></pre></td></tr></table></figure></p><p><strong>3.整数响应</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; incr books</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure></p><p>这里的<code>1</code>就是整数响应<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:1</span><br></pre></td></tr></table></figure></p><p><strong>4.多行字符串响应</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; get learn </span><br><span class="line">"redis"</span><br></pre></td></tr></table></figure></p><p><u>这里使用双引号括起来的字符串就是多行字符串响应</u></p><p><strong>5.数组响应</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hset shanghai num 021</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; hset shanghai date 10.1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; hset shanghai abbr sh</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; hgetall shanghai</span><br><span class="line">1) "num"</span><br><span class="line">2) "021"</span><br><span class="line">3) "date"</span><br><span class="line">4) "10.1"</span><br><span class="line">5) "abbr"</span><br><span class="line">6) "sh"</span><br></pre></td></tr></table></figure></p><p>这里的<code>hgetall</code>命令返回的就是一个数组，第<code>0|2|4</code>位置的字符串是<code>hash</code>表的<code>key</code>，第<code>1|3|5</code>位置的字符串是<code>value</code>，客户端负责将数组组装成字典再返回。</p><p><strong>6.嵌套</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "shanghai"</span><br><span class="line">   2) "learn"</span><br></pre></td></tr></table></figure></p><p><code>scan</code>命令用来扫描服务器包含的所有<code>key</code>列表，它是以游标的形式获取，一次只获取一部分。</p><p><code>scan</code>命令返回的是一个嵌套数组。数组的第一个值表示游标的值，如果这个值为零，说明已经遍历完毕。如果不为零，使用这个值作为<code>scan</code>命令的参数进行下一次遍历。数组的第二个值又是一个数组，这个数组就是<code>key</code>列表。</p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li><code>Redis</code>协议里有大量冗余的回车换行符，但是这不影响它成为互联网技术领域非常受欢迎的一个文本协议。有很多开源项目使用<code>RESP</code>作为它的通讯协议。在技术领域性能并不总是一切，还有简单性、易理解性和易实现性，这些都需要进行适当权衡。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis的客户端与服务端采用一种叫做&lt;code&gt;RESP(REdis Serialization Protocol)&lt;/code&gt;的网络通信协议交换数据。 这种协议采用明文传输，易读也易解析。&lt;code&gt;Redis&lt;/code&gt;客户端采用此协议格式来对服务端发送不同的命令，服务端会根据具体的操作而返回具体的答复。客户端和服务端采用的是简单的&lt;code&gt;请求-响应&lt;/code&gt;模型进行通信的。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题11 线程IO模型</title>
    <link href="http://researchlab.github.io/2018/10/08/redis-11-redisio/"/>
    <id>http://researchlab.github.io/2018/10/08/redis-11-redisio/</id>
    <published>2018-10-08T15:31:15.000Z</published>
    <updated>2018-11-09T01:39:38.574Z</updated>
    
    <content type="html"><![CDATA[<p><code>Redis</code>是单进程单线程模型的KV数据库,那为什么还常应用在高并发场景中? 其中一个重要原因是<code>Redis</code>是一个<strong>单进程单线程</strong>且采用<strong>多路I/O复用模型，非阻塞IO</strong>技术, 使之可以同时处理多个连接请求(减少网络IO耗时), 也不需要关心锁，线程切换等资源消耗问题;<br><a id="more"></a></p><h5 id="redis为什么设计为单线程"><a href="#redis为什么设计为单线程" class="headerlink" title="redis为什么设计为单线程"></a>redis为什么设计为单线程</h5><p>官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，<strong>Redis的瓶颈最有可能是机器内存的大小或者网络带宽</strong>。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦)。</p><blockquote><p>正因为<code>Redis</code>是单线程，所以要小心使用那些时间复杂度为<code>O(n)</code>级别的<code>Redis</code>指令，一不小心就可能会导致<code>Redis</code>卡顿。</p></blockquote><blockquote><p>但单线程的方式无法发挥多核CPU 性能，不过可通过在单机开多个Redis 实例来完善;</p></blockquote><blockquote><p>多线程处理可能涉及到锁, 多线程处理会涉及到线程切换而消耗CPU</p></blockquote><blockquote><p>多进程单线程模型: <code>Nginx</code>(单进程启动只有一个进程, 多进程启动时会有一个Master,多个worker进程), <code>Node.js</code></p></blockquote><blockquote><p>单进程多线程模型: <code>MySQL</code>, <code>Memcached</code></p></blockquote><blockquote><p>进程是一个实体。每一个进程都有它自己的地址空间，一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region)</p></blockquote><blockquote><p>一个进程中至少有一个线程。线程可以利用进程所拥有的资源，在引入线程的操作系统中，通常都是把进程作为分配资源的基本单位，而把线程作为独立运行和独立调度的基本单位，由于线程比进程更小，基本上不拥有系统资源，故对它的调度所付出的开销就会小得多，能更高效的提高系统多个程序间并发执行的程度。</p></blockquote><blockquote><p>进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。</p></blockquote><h5 id="Redis单线程为什么还能这么快？"><a href="#Redis单线程为什么还能这么快？" class="headerlink" title="Redis单线程为什么还能这么快？"></a><code>Redis</code>单线程为什么还能这么快？</h5><ul><li><p>完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；</p></li><li><p>数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；</p></li><li><p>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；</p></li><li><p>使用多路I/O复用模型，非阻塞IO；</p></li><li><p>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；</p></li></ul><p><code>Redis</code>单线程如何处理那么多的并发客户端连接？<br>因为<code>Redis</code>采用了<code>多路IO复用</code>及<code>非阻塞IO</code>技术, <code>多路IO复用</code>模型是利用<code>select、poll、epoll</code>可以同时监察多个流的<code>IO</code>事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。</p><blockquote><p><strong>多路</strong>指的是多个网络连接，<strong>复用</strong>指的是复用同一个线程。<br>采用<code>多路IO复用</code>技术可以让单个线程高效的处理多个连接请求(尽量减少网络IO的时间消耗)，且<code>Redis</code>在内存中操作数据的速度非常快(内存内的操作不会成为这里的性能瓶颈)，主要以上两点造就了<code>Redis</code>具有很高的吞吐量。</p></blockquote><h5 id="非阻塞IO"><a href="#非阻塞IO" class="headerlink" title="非阻塞IO"></a>非阻塞IO</h5><p>当我们调用套接字的读写方法，默认它们是阻塞的，比如read方法要传递进去一个参数n，表示最多读取这么多字节后再返回，如果一个字节都没有，那么线程就会卡在那里，直到新的数据到来或者连接关闭了，read方法才可以返回，线程才能继续处理。而write方法一般来说不会阻塞，除非内核为套接字分配的写缓冲区已经满了，write方法就会阻塞，直到缓存区中有空闲空间挪出来了。</p><p><strong>非阻塞IO</strong> 在套接字对象上提供了一个选项<code>Non_Blocking</code>，当这个选项打开时，读写方法不会阻塞，而是能读多少读多少，能写多少写多少。<strong>能读多少取决于内核为套接字分配的读缓冲区内部的数据字节数，能写多少取决于内核为套接字分配的写缓冲区的空闲空间字节数</strong>。读方法和写方法都会通过返回值来告知程序实际读写了多少字节。</p><p>有了<code>非阻塞IO</code>意味着线程在读写<code>IO</code>时可以不必再阻塞了，读写可以瞬间完成然后线程可以继续干别的事了。</p><h5 id="事件轮询-多路复用"><a href="#事件轮询-多路复用" class="headerlink" title="事件轮询 (多路复用)"></a>事件轮询 (<code>多路复用</code>)</h5><p><code>非阻塞IO</code>有个问题，那就是线程要读数据，结果读了一部分就返回了，线程如何知道何时才应该继续读。也就是当数据到来时，线程如何得到通知。写也是一样，如果缓冲区满了，写不完，剩下的数据何时才应该继续写，线程也应该得到通知。</p><p><strong>事件轮询API</strong> 就是用来解决这个问题的，最简单的<code>事件轮询API</code>是<code>select函数</code>，它是操作系统提供给用户程序的<code>API</code>。输入是读写描述符列表<code>read_fds &amp; write_fds</code>，输出是与之对应的可读可写事件。同时还提供了一个<code>timeout</code>参数，如果没有任何事件到来，那么就最多等待<code>timeout</code>时间，线程处于阻塞状态。一旦期间有任何事件到来，就可以立即返回。时间过了之后还是没有任何事件到来，也会立即返回。拿到事件后，线程就可以继续挨个处理相应的事件。处理完了继续过来轮询。于是线程就进入了一个死循环，我们把这个死循环称为事件循环，一个循环为一个周期。</p><p>每个客户端套接字<code>socket</code>都有对应的读写文件描述符。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">read_events, write_events = select(read_fds, write_fds, timeout)</span><br><span class="line">for event in read_events:</span><br><span class="line">    handle_read(event.fd)</span><br><span class="line">for event in write_events:</span><br><span class="line">    handle_write(event.fd)</span><br><span class="line">handle_others()  # 处理其它事情，如定时任务等</span><br></pre></td></tr></table></figure></p><p>因为我们通过<code>select</code>系统调用同时处理多个通道描述符的读写事件，因此我们将这类系统调用称为<code>多路复用</code> API。现代操作系统的<code>多路复用</code> API 已经不再使用<code>select</code>系统调用，而改用<code>epoll(linux)</code>和<code>kqueue(freebsd &amp; macosx)</code>，因为<code>select</code>系统调用的性能在描述符特别多时性能会非常差。它们使用起来可能在形式上略有差异，但是本质上都是差不多的，都可以使用上面的伪代码逻辑进行理解。</p><p>服务器套接字<code>serversocket</code>对象的读操作是指调用<code>accept</code>接受客户端新连接。何时有新连接到来，也是通过<code>select</code>系统调用的读事件来得到通知的。</p><h5 id="指令队列"><a href="#指令队列" class="headerlink" title="指令队列"></a>指令队列</h5><p><code>Redis</code> 会将每个客户端套接字都关联一个指令队列。客户端的指令通过队列来排队进行顺序处理，先到先服务。</p><h5 id="响应队列"><a href="#响应队列" class="headerlink" title="响应队列"></a>响应队列</h5><p><code>Redis</code> 同样也会为每个客户端套接字关联一个响应队列。<code>Redis</code> 服务器通过响应队列来将指令的返回结果回复给客户端。 如果队列为空，那么意味着连接暂时处于空闲状态，不需要去获取写事件，也就是可以将当前的客户端描述符从<code>write_fds</code>里面移出来。等到队列有数据了，再将描述符放进去。避免<code>select</code>系统调用立即返回写事件，结果发现没什么数据可以写。出这种情况的线程会飙高<code>CPU</code>。</p><h5 id="定时任务"><a href="#定时任务" class="headerlink" title="定时任务"></a>定时任务</h5><p>服务器处理要响应<code>IO</code>事件外，还要处理其它事情。比如定时任务就是非常重要的一件事。如果线程阻塞在<code>select</code>系统调用上，定时任务将无法得到准时调度。那<code>Redis</code>是如何解决这个问题的呢？</p><p><code>Redis</code> 的定时任务会记录在一个称为最小堆的数据结构中。这个堆中，最快要执行的任务排在堆的最上方。在每个循环周期，<code>Redis</code> 都会将最小堆里面已经到点的任务立即进行处理。处理完毕后，将最快要执行的任务还需要的时间记录下来，这个时间就是<code>select</code>系统调用的timeout参数。因为 <code>Redis</code> 知道未来timeout时间内，没有其它定时任务需要处理，所以可以安心睡眠timeout的时间。</p><p><code>Nginx</code>和<code>Node</code>的事件处理原理和<code>Redis</code>也是类似的</p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>引用官方说明，阐述了为何<code>Redis</code>被设计为单线程模型; </li><li>进一步阐述了为何单线程模型设计的<code>Redis</code>可以非常快的处理高并发等场景的原因;</li><li>对多路复用IO模型及非阻塞IO技术进行了原理阐述及分析;</li><li>此外注意到截止目前最新redis文档版本已更新到redis5.0，并引入新的数据类型<code>stream</code>，并对<code>HyperLogLog</code>等作出了很多优化改进;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;是单进程单线程模型的KV数据库,那为什么还常应用在高并发场景中? 其中一个重要原因是&lt;code&gt;Redis&lt;/code&gt;是一个&lt;strong&gt;单进程单线程&lt;/strong&gt;且采用&lt;strong&gt;多路I/O复用模型，非阻塞IO&lt;/strong&gt;技术, 使之可以同时处理多个连接请求(减少网络IO耗时), 也不需要关心锁，线程切换等资源消耗问题;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>mysql专题15 性能优化之数据库结构优化</title>
    <link href="http://researchlab.github.io/2018/10/08/mysql-15-database-structure-optimization/"/>
    <id>http://researchlab.github.io/2018/10/08/mysql-15-database-structure-optimization/</id>
    <published>2018-10-08T10:20:57.000Z</published>
    <updated>2018-11-09T01:39:38.570Z</updated>
    
    <content type="html"><![CDATA[<p>除了常见的SQL语句优化及索引优化等数据库优化手段外, 对数据库结构进行优化也是可以考虑的一个重要方向;<br><a id="more"></a></p><p>从以下几个方面来探讨数据库结构方面的优化实践,</p><ul><li>列<ul><li>数据类型优化</li></ul></li><li>数据表<ul><li>范式化优化</li><li>反范式化优化</li><li>垂直拆分</li><li>水平拆分</li></ul></li></ul><h2 id="列数据类型优化"><a href="#列数据类型优化" class="headerlink" title="列数据类型优化"></a>列数据类型优化</h2><p>如何选择合适的列数据类型?</p><ol><li>使用可以存下目标数据的最小的数据类型;</li><li>使用简单的数据类型, Int要比varchar类型在mysql处理上简单;</li><li>尽可能的使用NOT NULL定义字段;</li><li>尽量少用text类型, 非用不可时最好考虑分表;</li></ol><h3 id="示例分析"><a href="#示例分析" class="headerlink" title="示例分析"></a>示例分析</h3><p>使用int类型存储日期时间, 利用FROM_UNIXTIME(), UNIX_TIMESTAMP()两个函数进行转换;</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">test</span>(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span> auto_increment <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">timestr <span class="built_in">int</span>,</span><br><span class="line">primary <span class="keyword">key</span> (<span class="keyword">id</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">test</span> (timestr) <span class="keyword">values</span>(<span class="keyword">unix_timestamp</span>(<span class="string">'2016-06-11 12:11:00'</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> FROM_UNIXTIME(timestr) <span class="keyword">from</span> <span class="keyword">test</span>;</span><br></pre></td></tr></table></figure><ul><li>在具体使用时也应用结合业务使用场景来进行优化，如业务经常需要对时间进行各种格式化转换, 甚至需要在不同的语言中转换, 则应存储成标准的时间格式 time.Time, 以免引起精度损失问题;</li></ul><p>使用bigint来存储IP地址, 利用INET_ATON(), INET_NTOA()两个函数进行转换;</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> sessions(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span> auto_increment <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">ipaddr <span class="built_in">bigint</span>,</span><br><span class="line">primary <span class="keyword">key</span> (<span class="keyword">id</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sessions(ipaddr) <span class="keyword">values</span>(<span class="keyword">inet_aton</span>(<span class="string">'192.168.0.1'</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">inet_ntoa</span>(ipaddr) <span class="keyword">from</span> sessions;</span><br></pre></td></tr></table></figure><ul><li>bigint 大概需要8个字节， 而varchar大概需要15个字节</li></ul><h2 id="表范式化优化"><a href="#表范式化优化" class="headerlink" title="表范式化优化"></a>表范式化优化</h2><p>表范式化一般指第三设计范式, 即要求数据表中不存在非关键字段对任意候选键字段的传递函数依赖则符合第三范式;</p><h3 id="示例分析-1"><a href="#示例分析-1" class="headerlink" title="示例分析"></a>示例分析</h3><table><thead><tr><th style="text-align:left">商品名</th><th style="text-align:left">价格</th><th style="text-align:left">重量</th><th style="text-align:left">有效期</th><th style="text-align:left">分类</th><th style="text-align:left">分类描述</th></tr></thead><tbody><tr><td style="text-align:left">可乐</td><td style="text-align:left">3.00</td><td style="text-align:left">250ml</td><td style="text-align:left">2015.6</td><td style="text-align:left">饮料</td><td style="text-align:left">碳酸饮料</td></tr><tr><td style="text-align:left">雪碧</td><td style="text-align:left">3.00</td><td style="text-align:left">250ml</td><td style="text-align:left">2015.6</td><td style="text-align:left">饮料</td><td style="text-align:left">碳酸饮料</td></tr></tbody></table><p>显然上述商品表中存在如下传递函数依赖关系<br>(商品名)–&gt;(分类)–&gt;(分类描述)</p><p>也就是说存在非关键字”分类描述”对关键字”商品名”的传递函数依赖; 显然不符合第三设计范式, 不符合设计范式一般存在4大问题, </p><ol><li>数据冗余(分类, 分类描述) 对同一分类商品是一样的;</li><li>数据插入异常; 插入了就能查到, 没有数据就查不到某些关键信息;</li><li>更新异常;</li><li>删除异常;</li></ol><p>一般这种问题可以通过将表设计拆分为两张实体表, 另外在增加一个关系表; 如, </p><p>商品表(商品ming,价格,重量,有效期)</p><p>分类表(分类,分类描述)</p><p>商品分类(分类, 商品名)</p><h2 id="表反范式化优化"><a href="#表反范式化优化" class="headerlink" title="表反范式化优化"></a>表反范式化优化</h2><p>反范式化是指为了查询效率的考虑把原本符合第三范式的表适当的增加冗余, 以达到优化查询效率的目的, 反范式化是一种以空间来换取时间的操作;</p><h3 id="示例分析-2"><a href="#示例分析-2" class="headerlink" title="示例分析"></a>示例分析</h3><p>用户表(用户ID,姓名,电话,地址,邮编)<br>订单表(订单ID,用户ID,下单时间,支付类型,订单状态)<br>订单商品表(订单ID, 商品ID, 商品数量,商品价格)<br>商品表(商品ID,名称,描述,过期时间)</p><p>问题: 查询订单详情</p><p>常规sql</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> b.用户名, b.电话, b.地址, a.订单<span class="keyword">ID</span>, <span class="keyword">sum</span>(c.商品价格*c.商品数量) <span class="keyword">as</span> 订单价格 <span class="keyword">from</span> 订单表 a </span><br><span class="line"><span class="keyword">join</span> 用户表 b <span class="keyword">on</span> a.用户<span class="keyword">ID</span> = b.用户<span class="keyword">ID</span> </span><br><span class="line"><span class="keyword">join</span> 订单商品表 c <span class="keyword">on</span> c.订单<span class="keyword">ID</span> = b.订单<span class="keyword">ID</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> b.用户名, b.电话, b.地址, a.订单<span class="keyword">ID</span>;</span><br></pre></td></tr></table></figure><p>上述查询显然要关联多张表; 此外在group by 中如果存在非关键字索引字段， 则可能使用临时表来辅助查询, 那这样效率就比较低; </p><p>可以通过将订单表中冗余一部分用户信息, 这样可以通过查询订单表一张表即可完成查询需求;</p><p>订单表(订单ID,用户ID,下单时间,支付类型,订单状态,订单价格,用户名,电话,地址)</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> 用户名, 电话, 地址, 订单<span class="keyword">ID</span>,  订单价格 <span class="keyword">from</span> 订单表</span><br></pre></td></tr></table></figure><h2 id="表垂直拆分"><a href="#表垂直拆分" class="headerlink" title="表垂直拆分"></a>表垂直拆分</h2><p>表的垂直拆分, 就是把原来有很多列的表拆分为多个表, 垂直拆分原则, </p><ol><li>把不常用的字段单独存放到一张表中;</li><li>把大字段独立放到一个表中;</li><li>把可能存在关联关系常用字段放到一张表中;</li></ol><h2 id="表水平拆分"><a href="#表水平拆分" class="headerlink" title="表水平拆分"></a>表水平拆分</h2><p>表的水平拆分是为了解决单表的数据量过大的问题, 水平拆分的表每一个表的结构都是完全一致的; 通过取某个primary key 或者uniquekey 的值进行hash计算然后决定把数据存入tb1,tb2,…,tbn中某个表中; </p><p>但在以下场景中对sql操作会带来一些挑战,<br>1.跨分区表进行数据查询;<br>2.统计及后台报表操作;</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>选择合适的列字段类型; </li><li>启用空间换时间的办法, 做一些反范式化设计冗余字段提高查询等操作效率;</li><li>针对数据表字段过多及数据量过多的情况的两种简单设计技巧的说明, 实际情况中会通过分库分表来做, 可以封装一套mysql来支持， 也可以采用现成的开源db, 如tidb等方案;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;除了常见的SQL语句优化及索引优化等数据库优化手段外, 对数据库结构进行优化也是可以考虑的一个重要方向;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="mysql专题" scheme="http://researchlab.github.io/categories/mysql%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="mysql" scheme="http://researchlab.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>redis专题10 海量数据扫描神器之scan</title>
    <link href="http://researchlab.github.io/2018/10/07/redis-10-scan/"/>
    <id>http://researchlab.github.io/2018/10/07/redis-10-scan/</id>
    <published>2018-10-07T17:11:41.000Z</published>
    <updated>2018-11-09T01:39:38.574Z</updated>
    
    <content type="html"><![CDATA[<p>用<code>redis</code>模糊匹配<code>key</code>时，官方建议不要使用<code>keys</code>或<code>smembers</code>，他们的时间复杂度都是<code>O(N)</code>,使用<code>scan</code>，<code>zscan</code>，<code>hscan</code>等。<code>scan</code>系列增量式迭代命令每次执行的复杂度为<code>O(1)</code>， 对数据集进行一次完整迭代的复杂度为<code>O(N)</code>， 其中<code>N</code>为数据集中的元素数量。相比<code>keys</code>命令执行时会阻塞掉整个<code>redis</code>线程而言，<code>scan</code>系列则是通过游标分步进行的，不会阻塞<code>redis</code>线程, 且在同一时间，可以有任意多个客户端对同一数据集进行迭代。<br><a id="more"></a></p><p><code>keys</code>有两个显著缺点,</p><ul><li>没有<code>offset, limit</code>参数，一次性吐出所有满足条件的<code>key</code>, 万一实例中有几百w个<code>key</code>满足条件, 当你看到满屏的字符串刷的没有尽头时，你就知道难受了。</li><li><code>keys</code>算法是遍历算法, 复杂度是<code>O(n)</code>，如果实例中有千万级以上的<code>key</code>，这个指令就会导致<code>Redis</code>服务卡顿, 所有读写<code>Redis</code>的其它的指令都会被延后甚至会超时报错，因为<code>Redis</code>是单线程程序，顺序执行所有指令，其它指令必须等到当前的<code>keys</code>指令执行完了才可以继续。</li></ul><p><code>redis</code>为了解决这个问题, 它在2.8版本中加入了<code>scan</code>系列增量式迭代命令。<code>scan</code>相比<code>keys</code>具备有以下特点:</p><ul><li>复杂度虽然也是<code>O(n)</code>，但是它是通过游标分步进行的，不会阻塞线程;</li><li>提供<code>limit</code>参数，可以控制每次返回结果的最大条数, <code>limit</code>只是一个<code>hint</code>，返回的结果可多可少;</li><li>同<code>keys</code>一样，它也提供模式匹配功能;</li><li>服务器不需要为游标保存状态，游标的唯一状态就是<code>scan</code>返回给客户端的游标整数;</li><li>返回的结果可能会有重复，需要客户端去重复，这点非常重要;</li><li>遍历的过程中如果有数据修改，改动后的数据能不能遍历到是不确定的;</li><li>单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零;</li></ul><blockquote><p>当然<code>增量式迭代命令</code>也不是没有缺点, 如使用<code>SMEMBERS</code>命令可以返回集合键当前包含的所有元素， 但是对于<code>SCAN</code>这类增量式迭代命令来说， 因为在对键进行增量式迭代的过程中，键可能会被修改，所以增量式迭代命令只能对被返回的元素提供有限的保证(offer limited guarantees about the returned elements)。</p></blockquote><blockquote><p>同一个元素可能会被返回多次。<code>scan</code>系列命令无法保证同一元素被多次返回, 所以处理重复元素的工作交由应用程序负责处理(过滤/幂等操作)。</p></blockquote><p><strong>scan</strong></p><blockquote><p>命令: <code>SCAN cursor [MATCH pattern] [COUNT count]</code></p><blockquote><p><code>count</code>表示每次迭代中应该从数据集里最多返回多少元素, 默认值为10, 用户可以在每次迭代时随机修改此值;</p></blockquote></blockquote><blockquote><blockquote><p>在迭代一个足够大的、由哈希表实现的数据库、集合键、哈希键或者有序集合键时, 如果用户没有使用<code>match</code>选项, 那么命令返回的元素数量通常和<code>COUNT</code>选项指定的一样, 或者比<code>COUNT</code>选项指定的数量稍多一些。</p></blockquote></blockquote><blockquote><blockquote><p>在迭代一个编码为整数集合(<code>intset</code>, 一个只由整数值构成的小集合), 或者编码为压缩列表<code>ziplist</code>, 由不同值构成的一个小哈希或者一个小有序集合)时, 增量式迭代命令通常会无视<code>COUNT</code>选项指定的值， 在第一次迭代就将数据集包含的所有元素都返回给用户。</p></blockquote></blockquote><blockquote><blockquote><p><code>match</code>表示对返回的元素再进行模式匹配并将匹配结果最终返回, <strong>需要注意的是, 对元素的模式匹配工作是在命令从数据集中取出元素之后, 向客户端返回元素之前的这段时间内进行的, 所以如果被迭代的数据集中只有少量元素和模式相匹配, 那么迭代命令或许会在多次执行中都不返回任何元素。</strong></p></blockquote></blockquote><blockquote><p>功能: 用于迭代当前数据库中的数据库键;</p></blockquote><blockquote><p>返回值: <code>SCAN</code>命令的回复是一个包含两个元素的数组, 第一个数组元素是用于进行下一次迭代的新游标, 而第二个数组元素则是一个数组, 这个数组中包含了所有被迭代的元素。</p><blockquote><p>当返回的新游标为0 表示当前迭代全部完成;</p></blockquote></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; keys key*</span><br><span class="line">1) "key11"</span><br><span class="line">2) "key2"</span><br><span class="line">3) "key22"</span><br><span class="line">4) "key222"</span><br><span class="line">5) "key1"</span><br><span class="line">6) "key111"</span><br><span class="line">127.0.0.1:6379&gt; scan 0 match key1* count 10</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "key111"</span><br><span class="line">   2) "key11"</span><br><span class="line">   3) "key1"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><h5 id="字典结构"><a href="#字典结构" class="headerlink" title="字典结构"></a>字典结构</h5><p>在<code>redis</code>中所有的<code>key</code>都存储在一个很大的字典中, 即一维数组 + 二维链表结构, 示例,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">0</span><br><span class="line">1 -&gt;e-&gt;f-&gt;h</span><br><span class="line">2</span><br><span class="line">3 -&gt;g-&gt;x</span><br><span class="line">4</span><br><span class="line">5 -&gt;a-&gt;c</span><br></pre></td></tr></table></figure></p><p><code>scan</code>指令返回的游标就是第一维数组的位置索引，我们将这个位置索引称为槽<code>(slot)</code>。如果不考虑字典的扩容缩容，直接按数组下标挨个遍历就行了。<code>count</code>参数就表示需要遍历的槽位数，之所以返回的结果可能多可能少，是因为不是所有的槽位上都会挂接链表，有些槽位可能是空的，还有些槽位上挂接的链表上的元素可能会有多个。每一次遍历都会将<code>count</code>数量的槽位上挂接的所有链表元素进行模式匹配过滤后，一次性返回给客户端。</p><blockquote><p><code>scan</code>的遍历顺序非常特别。它不是从第一维数组的第<code>0</code>位一直遍历到末尾，而是采用了高位进位加法来遍历。之所以使用这样特殊的方式进行遍历，是考虑到字典的扩容和缩容时避免槽位的遍历重复和遗漏。</p></blockquote><p>redis字典扩容采用了·渐进式rehash`操作。</p><p><code>渐进式rehash</code>会同时保留旧数组和新数组，然后在定时任务中以及后续对<code>hash</code>的指令操作中渐渐地将旧数组中挂接的元素迁移到新数组上。这意味着要操作处于<code>rehash</code>中的字典，需要同时访问新旧两个数组结构。如果在旧数组下面找不到元素，还需要去新数组下面去寻找。</p><p><code>scan</code>也需要考虑这个问题，对与<code>rehash</code>中的字典，它需要同时扫描新旧槽位，然后将结果融合后返回给客户端。</p><p><code>scan</code>系列命令目前共计4条,</p><blockquote><p><code>SCAN</code>  命令用于迭代当前数据库中的数据库键;<br><code>SSCAN</code> 命令用于迭代集合键中的元素;<br><code>HSCAN</code> 命令用于迭代哈希键中的键值对;<br><code>ZSCAN</code> 命令用于迭代有序集合中的元素(包括元素成员和元素分值);</p></blockquote><h5 id="定位大key"><a href="#定位大key" class="headerlink" title="定位大key"></a>定位大key</h5><p>为了避免对线上<code>redis</code>带来卡顿，这就要用到<code>scan</code>指令，对于扫描出来的每一个<code>key</code>，使用<code>type</code>指令获得<code>key</code>的类型，然后使用相应数据结构的<code>size</code>或者<code>len</code>方法来得到它的大小，对于每一种类型，保留大小的前<code>N</code>名作为扫描结果展示出来。</p><p>上面这样的过程<code>redis</code>官方已经在<code>redis-cli</code>指令中提供了这样的扫描功能，我们可以直接拿来即用。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 6370 –-bigkeys</span><br></pre></td></tr></table></figure></p><p>如果你担心这个指令会大幅抬升<code>redis</code>的<code>ops</code>导致线上报警，还可以增加一个休眠参数。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 6370 –-bigkeys -i 0.1</span><br></pre></td></tr></table></figure></p><p>上面这个指令每隔<code>100</code>条<code>scan</code>指令就会休眠<code>0.1s,</code>ops`就不会剧烈抬升，但是扫描的时间会变长。</p><p>可进一步参考 <a href="https://mp.weixin.qq.com/s/ufoLJiXE0wU4Bc7ZbE9cDQ" target="_blank" rel="noopener">美团针对Redis Rehash机制的探索和实践</a></p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>从<code>redis</code>模糊匹配场景分析入手，引入<code>keys</code>和<code>scan</code>系列增量迭代式命令方法，结合使用场景对其优劣进行了比较说明;</li><li>阐述了<code>scan</code>遍历方法，并对字典扩容进行了简单探讨;</li><li>从定位大<code>key</code>场景出发，引出了<code>redis-cli</code>已支持的 <code>--bigkeys</code>命令， 可以非常方便的协助用户定位大<code>key</code>问题;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;用&lt;code&gt;redis&lt;/code&gt;模糊匹配&lt;code&gt;key&lt;/code&gt;时，官方建议不要使用&lt;code&gt;keys&lt;/code&gt;或&lt;code&gt;smembers&lt;/code&gt;，他们的时间复杂度都是&lt;code&gt;O(N)&lt;/code&gt;,使用&lt;code&gt;scan&lt;/code&gt;，&lt;code&gt;zscan&lt;/code&gt;，&lt;code&gt;hscan&lt;/code&gt;等。&lt;code&gt;scan&lt;/code&gt;系列增量式迭代命令每次执行的复杂度为&lt;code&gt;O(1)&lt;/code&gt;， 对数据集进行一次完整迭代的复杂度为&lt;code&gt;O(N)&lt;/code&gt;， 其中&lt;code&gt;N&lt;/code&gt;为数据集中的元素数量。相比&lt;code&gt;keys&lt;/code&gt;命令执行时会阻塞掉整个&lt;code&gt;redis&lt;/code&gt;线程而言，&lt;code&gt;scan&lt;/code&gt;系列则是通过游标分步进行的，不会阻塞&lt;code&gt;redis&lt;/code&gt;线程, 且在同一时间，可以有任意多个客户端对同一数据集进行迭代。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>mysql专题14 性能优化之索引优化</title>
    <link href="http://researchlab.github.io/2018/10/07/mysql-14-index-optimization/"/>
    <id>http://researchlab.github.io/2018/10/07/mysql-14-index-optimization/</id>
    <published>2018-10-07T08:53:28.000Z</published>
    <updated>2018-11-09T01:39:38.570Z</updated>
    
    <content type="html"><![CDATA[<p>索引优化也是数据库优化的一个重要方向, 本文将从实践结合理论的角度回顾索引相关知识, 同时通过实例分析进一步学习索引选择及优化过程;<br><a id="more"></a></p><h2 id="创建合适索引原则"><a href="#创建合适索引原则" class="headerlink" title="创建合适索引原则"></a>创建合适索引原则</h2><p>如何选择合适的列创建索引?</p><ol><li><p>在where从句, group by 从句, order by 从句, on 从句中出现的列;</p></li><li><p>索引字段越小越好;</p></li><li><p>离散度大的列放到联合索引的前面;</p></li></ol><p>例如,</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> payment <span class="keyword">where</span> staff_id = <span class="number">2</span> <span class="keyword">and</span> customer_id = <span class="number">580</span>;</span><br></pre></td></tr></table></figure><p>是index(staff_id, customer_id) 好还是index(customer_id, staff_id)好? </p><p>由于customer_id的离散度更大, 所以应该使用index(customer_id, staff_id)</p><h2 id="索引优化SQL"><a href="#索引优化SQL" class="headerlink" title="索引优化SQL"></a>索引优化SQL</h2><p>通常情况下, 索引可以提高查询效率, 但是会影响insert/update/delete这种修改语句, 降低写入效率, 索引并不是建立得越多越好, 但实际情况下过多的索引不但会影响写入同时也会影响查询效率, 因为在查询时首选要选择用哪个索引来进行查询, 如果索引多, 分析的就多, 从而分析过程就很长;</p><p>所以不见要知道如何选择合适的列创建索引, 也需要知道如何维护和删除重复和冗余的索引;</p><h3 id="重复索引"><a href="#重复索引" class="headerlink" title="重复索引"></a>重复索引</h3><p>重复索引指相同的列以相同的顺序建立的同类型的索引, </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">test</span>(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span> <span class="keyword">not</span> <span class="literal">null</span> primary <span class="keyword">key</span>,</span><br><span class="line"><span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">10</span>) <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">title <span class="built_in">varchar</span>(<span class="number">50</span>) <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line"><span class="keyword">unique</span>(<span class="keyword">id</span>)</span><br><span class="line">) <span class="keyword">engine</span> = <span class="keyword">InnoDB</span>;</span><br></pre></td></tr></table></figure><p>如上primary key 与ID列的上的索引这种情况即为重复索引;</p><h3 id="冗余索引"><a href="#冗余索引" class="headerlink" title="冗余索引"></a>冗余索引</h3><p>冗余索引是指多个索引的前缀列相同, 或是在联合索引中包含了主键的索引, </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">test</span>(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span> <span class="keyword">not</span> <span class="literal">null</span> primary <span class="keyword">key</span>,</span><br><span class="line"><span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">10</span>) <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">title <span class="built_in">varchar</span>(<span class="number">10</span>) <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line"><span class="keyword">key</span>(<span class="keyword">name</span>,<span class="keyword">id</span>)</span><br><span class="line">)<span class="keyword">engine</span>=<span class="keyword">InnoDB</span>;</span><br></pre></td></tr></table></figure><p>上述sql中key(name,id)就是一个冗余索引; 因为这个联合索引包含了主键索引;</p><h3 id="查询重复及冗余索引"><a href="#查询重复及冗余索引" class="headerlink" title="查询重复及冗余索引"></a>查询重复及冗余索引</h3><p>实例分析,</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; use information_schema;</span><br><span class="line"></span><br><span class="line">mysql&gt; select</span><br><span class="line">    -&gt; a.table_schema as 'database',</span><br><span class="line">    -&gt; a.table_name as 'table_name',</span><br><span class="line">    -&gt; a.index_name as 'index_one',</span><br><span class="line">    -&gt; b.index_name as 'index_two',</span><br><span class="line">    -&gt; a.column_name as 'duplicate_col_name'</span><br><span class="line">    -&gt; from statistics a</span><br><span class="line">    -&gt; join statistics b on</span><br><span class="line">    -&gt; a.table_schema = b.table_schema and</span><br><span class="line">    -&gt; a.table_name = b.table_name and</span><br><span class="line">    -&gt; a.seq_in_index = b.seq_in_index and</span><br><span class="line">    -&gt; a.column_name = b.column_name</span><br><span class="line">    -&gt; where a.seq_in_index = 1 and a.index_name &lt;&gt; b.index_name;</span><br><span class="line">+<span class="comment">-----------+--------------+-------------+-------------+--------------------+</span></span><br><span class="line">| database  | table_name   | index_one   | index_two   | duplicate_col_name |</span><br><span class="line">+<span class="comment">-----------+--------------+-------------+-------------+--------------------+</span></span><br><span class="line">| employees | departments  | dept_name   | dept_name_2 | dept_name          |</span><br><span class="line">| employees | departments  | dept_name_2 | dept_name   | dept_name          |</span><br><span class="line">| employees | dept_manager | PRIMARY     | emp_no      | emp_no             |</span><br><span class="line">| employees | dept_manager | emp_no      | PRIMARY     | emp_no             |</span><br><span class="line">+<span class="comment">-----------+--------------+-------------+-------------+--------------------+</span></span><br><span class="line">4 rows in <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br></pre></td></tr></table></figure><p>上述sql语句用于查询所有数据库中存在重复前缀索引, 需要用到information_schema 元数据表中的一些信息所有需要注意use information_schema数据库下执行;</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> departments (</span><br><span class="line">    dept_no     <span class="built_in">CHAR</span>(<span class="number">4</span>)         <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">    dept_name   <span class="built_in">VARCHAR</span>(<span class="number">40</span>)     <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">    PRIMARY <span class="keyword">KEY</span> (dept_no),</span><br><span class="line">    <span class="keyword">UNIQUE</span>  <span class="keyword">KEY</span> (dept_name),</span><br><span class="line"><span class="keyword">KEY</span> (dept_name)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> dept_manager (</span><br><span class="line">   emp_no       <span class="built_in">INT</span>             <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">   dept_no      <span class="built_in">CHAR</span>(<span class="number">4</span>)         <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">   from_date    <span class="built_in">DATE</span>            <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">   <span class="keyword">to_date</span>      <span class="built_in">DATE</span>            <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">   <span class="keyword">FOREIGN</span> <span class="keyword">KEY</span> (emp_no)  <span class="keyword">REFERENCES</span> employees (emp_no)    <span class="keyword">ON</span> <span class="keyword">DELETE</span> <span class="keyword">CASCADE</span>,</span><br><span class="line">   <span class="keyword">FOREIGN</span> <span class="keyword">KEY</span> (dept_no) <span class="keyword">REFERENCES</span> departments (dept_no) <span class="keyword">ON</span> <span class="keyword">DELETE</span> <span class="keyword">CASCADE</span>,</span><br><span class="line">   PRIMARY <span class="keyword">KEY</span> (emp_no,dept_no),</span><br><span class="line"><span class="keyword">KEY</span> (emp_no)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>从上述分析及表结构可以看出, </p><ul><li>在departments中UNIQUE KEY和KEY中存在重复索引;</li><li>在dept_manager中PRIMARY KEY和KEY中存在冗余索引;</li></ul><h2 id="pt-duplicate-key-checker"><a href="#pt-duplicate-key-checker" class="headerlink" title="pt-duplicate-key-checker"></a>pt-duplicate-key-checker</h2><p>上面通过SQL语句可以查询到重复及冗余索引, 也可以通过工具来查询, 如使用pt-duplicate-key-checker工具检查重复及冗余索引,</p><p>这个工具使用非常简单, 只需要提供下面几个参数即可,</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pt-duplicate-key-checker \</span><br><span class="line">-uroot \</span><br><span class="line">-p 'pwd' \</span><br><span class="line">-h 127.0.0.1</span><br></pre></td></tr></table></figure><p>同时这个工具还会提供一个修订的SQL方案供参考;</p><h2 id="索引维护"><a href="#索引维护" class="headerlink" title="索引维护"></a>索引维护</h2><h3 id="删除不用索引"><a href="#删除不用索引" class="headerlink" title="删除不用索引"></a>删除不用索引</h3><p>因业务变更等因素, 有些索引会不在被使用, 此时最好将其删除; 目前MySQL中还没有记录索引的使用情况, 但是在PerconMySQL和MariaDB中可以通过INDEX_STATISTICS表来查看哪些索引未使用, 但是在MySQL中目前只能通过慢查日志配合pt-index-usage工具来进行索引使用情况的分析, pt-index-usage 工具使用也非常简单, </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pt-index-usage \ </span><br><span class="line">-uroot -p 'pwd' \</span><br><span class="line">mysql-slow.log</span><br></pre></td></tr></table></figure><p>注意如果是主从集群, 则工具分析时应对所有慢查日志进行分析;</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>优先将where/group by/order by/on从句中出现的列 创建索引; 并且索引字段越小越好; 如创建联合索引时, 建议将离散度大的列放在联合索引的前面;</li><li>不但要选择合适的列创建索引, 同时也应将重复及冗余索引删除;</li><li>pt-duplicate-key-checker及pt-index-usage工具的联合使用, 可以帮助查询到重复及冗余和未使用的索引;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;索引优化也是数据库优化的一个重要方向, 本文将从实践结合理论的角度回顾索引相关知识, 同时通过实例分析进一步学习索引选择及优化过程;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="mysql专题" scheme="http://researchlab.github.io/categories/mysql%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="mysql" scheme="http://researchlab.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>redis专题09 geo地理位置模块</title>
    <link href="http://researchlab.github.io/2018/10/06/redis-09-geohash/"/>
    <id>http://researchlab.github.io/2018/10/06/redis-09-geohash/</id>
    <published>2018-10-06T17:09:06.000Z</published>
    <updated>2018-11-09T01:39:38.574Z</updated>
    
    <content type="html"><![CDATA[<p><code>redis3.2</code>版本里面新增的一个功能就是对<code>GEO(地理位置)</code>的支持。意味着可以用<code>redis</code>来实现查找<code>附件的人</code>的等搜索功能了；<br><a id="more"></a><br>地图元素的位置数据使用二维的经纬度表示，经度范围 (-180, 180]，纬度范围 (-90, 90]，纬度正负以赤道为界，北正南负，经度正负以本初子午线 (英国格林尼治天文台) 为界，东正西负。</p><p>当两个元素的距离不是很远时，可以直接使用勾股定理就能算得元素之间的距离。我们平时使用的「附近的人」的功能，元素距离都不是很大，勾股定理算距离足矣。不过需要注意的是，经纬度坐标的密度不一样 (地球是一个椭圆)，勾股定律计算平方差时之后再求和时，需要按一定的系数比加权求和，如果不求精确的话，也可以不必加权。</p><p>问题：经度总共360度，维度总共只有180度，为什么距离密度不是2:1？</p><p>现在，如果要计算「附近的人」，也就是给定一个元素的坐标，然后计算这个坐标附近的其它元素，按照距离进行排序，该如何下手？<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">假设待计算坐标为(x,y),以这个坐标为圆点, r为半径，进行搜索其附近的元素</span><br></pre></td></tr></table></figure></p><p>如果现在元素的经纬度坐标使用关系数据库 (元素<code>id</code>, 经度<code>x</code>, 纬度<code>y</code>) 存储，你该如何计算？</p><p>首先，你不可能通过遍历来计算所有的元素和目标元素的距离然后再进行排序，这个计算量太大了，性能指标肯定无法满足。一般的方法都是通过矩形区域来限定元素的数量，然后对区域内的元素进行全量距离计算再排序。这样可以明显减少计算量。如何划分矩形区域呢？ 可以指定一个半径<code>r</code>，使用一条<code>SQL</code>就可以圈出来。当用户对筛出来的结果不满意，那就扩大半径继续筛选。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id from positions where x0-r &lt; x &lt; x0+r and y0-r &lt; y &lt; y0+r</span><br></pre></td></tr></table></figure></p><p>为了满足高性能的矩形区域算法，数据表需要在经纬度坐标加上双向复合索引(x, y)，这样可以最大优化查询性能。</p><p>但是数据库查询性能毕竟有限，如果「附近的人」查询请求非常多，在高并发场合，这可能并不是一个很好的方案。</p><h5 id="GeoHash算法"><a href="#GeoHash算法" class="headerlink" title="GeoHash算法"></a>GeoHash算法</h5><p>业界比较通用的地理位置距离排序算法是<code>GeoHash</code>算法，<code>redis</code>也使用<code>GeoHash</code>算法。<code>GeoHash</code>算法将二维的经纬度数据映射到一维的整数，这样所有的元素都将在挂载到一条线上，距离靠近的二维坐标映射到一维后的点之间距离也会很接近。当我们想要计算「附近的人时」，首先将目标位置映射到这条线上，然后在这个一维的线上获取附近的点就行了。</p><p>那这个映射算法具体是怎样的呢？ 它将整个地球看成一个二维平面，然后划分成了一系列正方形的方格，就好比围棋棋盘。所有的地图元素坐标都将放置于唯一的方格中。方格越小，坐标越精确。然后对这些方格进行整数编码，越是靠近的方格编码越是接近。那如何编码呢？一个最简单的方案就是切蛋糕法。设想一个正方形的蛋糕摆在你面前，二刀下去均分分成四块小正方形，这四个小正方形可以分别标记为 00,01,10,11 四个二进制整数。然后对每一个小正方形继续用二刀法切割一下，这时每个小小正方形就可以使用 4bit 的二进制整数予以表示。然后继续切下去，正方形就会越来越小，二进制整数也会越来越长，精确度就会越来越高。</p><h5 id="redis-Geo模块应用"><a href="#redis-Geo模块应用" class="headerlink" title="redis Geo模块应用"></a>redis Geo模块应用</h5><p><code>Geo</code>地理模块到目前为止提供了6条命令:</p><table><thead><tr><th>序号</th><th>命令</th><th>备注</th></tr></thead><tbody><tr><td>1</td><td><code>geoadd</code></td><td>将指定的地理空间位置(纬度, 经度, 名称)添加到指定的key中</td></tr><tr><td>2</td><td><code>geodist</code></td><td>返回两个给定位置之间的距离</td></tr><tr><td>3</td><td><code>geohash</code></td><td>返回一个或多个位置元素的<code>Geohash</code>表示</td></tr><tr><td>4</td><td><code>geopos</code></td><td>从key里返回所有给定位置元素的位置(经度和纬度)</td></tr><tr><td>5</td><td><code>georadius</code></td><td>以给定的经纬度为中心， 返回键包含的位置元素当中， 与中心的距离不超过给定最大距离的所有位置元素</td></tr><tr><td>6</td><td><code>georadiusbymember</code></td><td>查找给定元素给定范围内的元素值</td></tr></tbody></table><p><strong><code>geoadd</code></strong></p><blockquote><p>命令: <code>GEOADD key longitude latitude member [longitude latitude member ...]</code><br>命令描述: 将指定的地理空间位置(纬度, 经度, 名称)添加到指定的key中;<br>返回值: 添加到sorted set元素的数目, 但不包括已更新score的元素;<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geoadd location 116.111 39.111 position.one</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; geoadd location 116.333 39.333 position.two 116.555 39.556 position.three</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p></blockquote><p><strong><code>geodist</code></strong></p><blockquote><p>命令: <code>GEODIST key member1 member2 [unit]</code><br>命令描述: 返回两个给定位置之间的距离。如果两个位置之间的其中一个不存在,  那么命令返回空值。指定单位的参数 unit 必须是以下单位的其中一个:</p><blockquote><p><code>m</code> 表示单位为米;<br><code>km</code> 表示单位为千米;<br><code>mi</code> 表示单位为英里;<br><code>ft</code> 表示单位为英尺;</p></blockquote></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geodist location position.one position.three m</span><br><span class="line">"62520.6181"</span><br><span class="line">127.0.0.1:6379&gt; geodist location position.one position.three km</span><br><span class="line">"62.5206"</span><br><span class="line">127.0.0.1:6379&gt; geodist location position.one position.five m</span><br><span class="line">(nil)</span><br></pre></td></tr></table></figure><p><strong><code>geohash</code></strong></p><blockquote><p>命令: <code>GEOHASH key member [member ...]</code><br>命令描述: 返回一个或多个位置元素的<code>Geohash</code>表示。通常使用表示位置的元素使用不同的技术, 使用<code>Geohash</code>位置52点整数编码。由于编码和解码过程中所使用的初始最小和最大坐标不同, 编码的编码也不同于标准。此命令返回一个标准的<code>Geohash</code>值<br>返回值: 一个数组, 数组的每个项都是一个<code>Geohash</code> 。 命令返回的<code>Geohash</code>的位置与用户给定的位置元素的位置一一对应。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geohash location position.one position.two position.three position.five</span><br><span class="line">1) "wwfw6pvqn60"</span><br><span class="line">2) "wwfxz0r5760"</span><br><span class="line">3) "wx4ch2by2k0"</span><br><span class="line">4) (nil)</span><br></pre></td></tr></table></figure><p><strong><code>geopos</code></strong></p><blockquote><p>命令: <code>GEOPOS key member [member ...]</code><br>命令描述: 从<code>key</code>里返回所有给定位置元素的位置(经度和纬度);<br>返回值: <code>GEOPOS</code>命令返回一个数组, 数组中的每个项都由两个元素组成: 第一个元素为给定位置元素的经度, 而第二个元素则为给定位置元素的纬度。当给定的位置元素不存在时, 对应的数组项为空值。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geopos location position.one position.five position.three</span><br><span class="line">1) 1) "116.11100167036056519"</span><br><span class="line">   2) "39.11099969335537452"</span><br><span class="line">2) (nil)</span><br><span class="line">3) 1) "116.55499845743179321"</span><br><span class="line">   2) "39.55600040953122942"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p><strong><code>georadius</code></strong></p><blockquote><p>命令: <code>GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count]</code><br>命令描述: 以给定的经纬度为中心, 返回键包含的位置元素当中, 与中心的距离不超过给定最大距离的所有位置元素, 范围可以使用以下其中一个单位:</p><blockquote><p><code>m</code> 表示单位为米;<br><code>km</code> 表示单位为千米;<br><code>mi</code> 表示单位为英里;<br><code>ft</code> 表示单位为英尺;</p></blockquote></blockquote><blockquote><p>在给定以下可选项时, 命令会返回额外的信息:</p><blockquote><p><code>WITHDIST</code>: 在返回位置元素的同时, 将位置元素与中心之间的距离也一并返回。 距离的单位和用户给定的范围单位保持一致。<br><code>WITHCOORD</code>: 将位置元素的经度和维度也一并返回。<br><code>WITHHASH</code>: 以52位有符号整数的形式, 返回位置元素经过原始<code>Geohash</code>编码的有序集合分值。这个选项主要用于底层应用或者调试, 实际中的作用并不大。</p></blockquote></blockquote><blockquote><p>命令默认返回未排序的位置元素。通过以下两个参数, 用户可以指定被返回位置元素的排序方式:</p><blockquote><p><code>ASC</code>: 根据中心的位置, 按照从近到远的方式返回位置元素;<br><code>DESC</code>: 根据中心的位置, 按照从远到近的方式返回位置元素;</p></blockquote></blockquote><blockquote><p>在默认情况下, <code>GEORADIUS</code>命令会返回所有匹配的位置元素;<br>虽然用户可以使用<code>COUNT &lt;count&gt;</code>选项去获取前<code>N</code> 个匹配元素,  但是因为命令在内部可能会需要对所有被匹配的元素进行处理<code>所以在对一个非常大的区域进行搜索时, 即使只使用</code>COUNT<code>选项去获取少量元素,  命令的执行速度也可能会非常慢。 但是从另一方面来说， 使用</code>COUNT<code>选项去减少需要返回的元素数量</code> 对于减少带宽来说仍然是非常有用的。</p></blockquote><blockquote><p>返回值:<br>在没有给定任何<code>WITH</code>选项的情况下, 命令只会返回一个像<code>[&quot;New York&quot;, &quot;Milan&quot;,&quot;Paris&quot;] 这样的线性(linear)列表。在指定了</code>WITHCOORD<code>,</code>WITHDIST<code>,</code>WITHHASH`等选项的情况下, 命令返回一个二层嵌套数组, 内层的每个子数组就表示一个元素。<br>在返回嵌套数组时, 子数组的第一个元素总是位置元素的名字。 至于额外的信息, 则会作为子数组的后续元素, 按照以下顺序被返回:</p><blockquote><p>1.以浮点数格式返回的中心与位置元素之间的距离, 单位与用户指定范围时的单位一致。<br>2.<code>Geohash</code>整数。<br>3.由两个元素组成的坐标, 分别为经度和纬度。</p></blockquote></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; georadius location 116.111 39.111 50 km withcoord withdist withhash</span><br><span class="line">1) 1) "position.one"</span><br><span class="line">   2) "0.0001"</span><br><span class="line">   3) (integer) 4069074382584591</span><br><span class="line">   4) 1) "116.11100167036056519"</span><br><span class="line">      2) "39.11099969335537452"</span><br><span class="line">2) 1) "position.two"</span><br><span class="line">   2) "31.2350"</span><br><span class="line">   3) (integer) 4069124900607885</span><br><span class="line">   4) 1) "116.33299738168716431"</span><br><span class="line">      2) "39.33300071137491472"</span><br><span class="line">127.0.0.1:6379&gt; georadius location 116.111 39.111 50 km withcoord withdist withhash  count 1</span><br><span class="line">1) 1) "position.one"</span><br><span class="line">   2) "0.0001"</span><br><span class="line">   3) (integer) 4069074382584591</span><br><span class="line">   4) 1) "116.11100167036056519"</span><br><span class="line">      2) "39.11099969335537452"</span><br><span class="line">127.0.0.1:6379&gt; georadius location 116.111 39.111 50 km withcoord withdist withhash  count 2 asc</span><br><span class="line">1) 1) "position.one"</span><br><span class="line">   2) "0.0001"</span><br><span class="line">   3) (integer) 4069074382584591</span><br><span class="line">   4) 1) "116.11100167036056519"</span><br><span class="line">      2) "39.11099969335537452"</span><br><span class="line">2) 1) "position.two"</span><br><span class="line">   2) "31.2350"</span><br><span class="line">   3) (integer) 4069124900607885</span><br><span class="line">   4) 1) "116.33299738168716431"</span><br><span class="line">      2) "39.33300071137491472"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p><strong><code>georadiusbymember</code></strong></p><blockquote><p>命令: <code>GEORADIUSBYMEMBER key member radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count]</code><br>命令描述: 这个命令和<code>GEORADIUS</code>命令一样, 都可以找出位于指定范围内的元素, 但是<code>GEORADIUSBYMEMBER</code>的中心点是由给定的位置元素决定的。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 表示对key `location` 以`position.one`为原点, 100km为半径, 帅选出最多5个position 并且对结果进行正向(由近到远)排序</span></span><br><span class="line">127.0.0.1:6379&gt; georadiusbymember location position.one 100 km count 5 asc</span><br><span class="line">1) "position.one"</span><br><span class="line">2) "position.two"</span><br><span class="line">3) "position.three"</span><br><span class="line">127.0.0.1:6379&gt; georadiusbymember location position.one 100 km count 5 asc withcoord withdist withhash</span><br><span class="line">1) 1) "position.one"</span><br><span class="line">   2) "0.0000"</span><br><span class="line">   3) (integer) 4069074382584591</span><br><span class="line">   4) 1) "116.11100167036056519"</span><br><span class="line">      2) "39.11099969335537452"</span><br><span class="line">2) 1) "position.two"</span><br><span class="line">   2) "31.2349"</span><br><span class="line">   3) (integer) 4069124900607885</span><br><span class="line">   4) 1) "116.33299738168716431"</span><br><span class="line">      2) "39.33300071137491472"</span><br><span class="line">3) 1) "position.three"</span><br><span class="line">   2) "62.5206"</span><br><span class="line">   3) (integer) 4069148683788633</span><br><span class="line">   4) 1) "116.55499845743179321"</span><br><span class="line">      2) "39.55600040953122942"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><h5 id="问题及建议"><a href="#问题及建议" class="headerlink" title="问题及建议"></a>问题及建议</h5><p>在一个地图应用中，车的数据、餐馆的数据、人的数据可能会有百万千万条，如果使用<code>redis</code>的<code>Geo</code>数据结构，它们将全部放在一个<code>zset</code> 集合中。在<code>redis</code>的集群环境中，集合可能会从一个节点迁移到另一个节点，如果单个<code>key</code>的数据过大，会对集群的迁移工作造成较大的影响，在集群环境中单个<code>key</code>对应的数据量不宜超过<code>1M</code>，否则会导致集群迁移出现卡顿现象，影响线上服务的正常运行。</p><p>所以，这里建议<code>Geo</code>的数据使用单独的<code>redis</code>实例部署，不使用集群环境。</p><p>如果数据量过亿甚至更大，就需要对<code>Geo</code>数据进行拆分，按国家拆分、按省拆分，按市拆分，在人口特大城市甚至可以按区拆分。这样就可以显著降低单个<code>zset</code>集合的大小。</p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>从地图中元素的二维表示入手，分析引入在<code>redis3.2</code>中提供的<code>Geo</code>地理模块,并对<code>Geo</code>地理模块提供的基础命令原理及使用进行了阐述说明，并进一步通过示例作出了说明；</li><li><code>Geo</code>地理模块对于计算地图中元素位置及查找元素非常方便; </li><li>但值得注意的时，有关使用经验表明当<code>redis</code>集群中单个<code>key</code>数据量比较大如超出<code>1M</code>时，建议按照业务特性进行拆分，分流到多个<code>redis</code>实例中去，以免在进行迁移时影响运营服务;</li></ul><p>此外，可进一步参考</p><hr><p>[1] <a href="https://www.cnblogs.com/zhenbianshu/p/6817569.html" target="_blank" rel="noopener">空间索引 - 各数据库空间索引使用报告</a><br>[2] <a href="https://www.cnblogs.com/zhenbianshu/p/6863405.html" target="_blank" rel="noopener">空间索引 - GeoHash算法及其实现优化</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;redis3.2&lt;/code&gt;版本里面新增的一个功能就是对&lt;code&gt;GEO(地理位置)&lt;/code&gt;的支持。意味着可以用&lt;code&gt;redis&lt;/code&gt;来实现查找&lt;code&gt;附件的人&lt;/code&gt;的等搜索功能了；&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>mysql专题13 性能优化之sql语句优化</title>
    <link href="http://researchlab.github.io/2018/10/06/mysql-13-sql-optimization/"/>
    <id>http://researchlab.github.io/2018/10/06/mysql-13-sql-optimization/</id>
    <published>2018-10-06T10:01:54.000Z</published>
    <updated>2018-11-09T01:39:38.570Z</updated>
    
    <content type="html"><![CDATA[<p>为应用服务提供稳定的数据CURD服务,同时为了进一步提升CURD性能及潜在的问题, 就需要根据实际业务情况及数据体量进行数据库优化修订工作, 关于数据库优化的操作可以从多个方面来总结归纳, 如对SQL语句的优化, 索引的优化, 表结构的优化, 配置的优化等等; 本文从总结实践经验及归纳回顾知识要点的角度来探讨关于SQL语句优化的相关问题;<br><a id="more"></a></p><h2 id="优化目的"><a href="#优化目的" class="headerlink" title="优化目的"></a>优化目的</h2><ul><li>避免出现页面访问错误<ol><li>由于数据库连接timeout产生页面5xx错误;</li><li>由于慢查询造成页面无法加载;</li><li>由于阻塞造成数据无法提交;</li></ol></li><li>增加数据库的稳定性<ol><li>很多数据库问题都是由于低效的查询引起的;</li></ol></li><li>优化用户体验<ol><li>流畅页面的访问速度;</li><li>良好的业务功能体验;</li></ol></li></ul><h2 id="优化方向及成本"><a href="#优化方向及成本" class="headerlink" title="优化方向及成本"></a>优化方向及成本</h2><p>大致可以从如下几个方向进行优化, </p><ul><li>SQL语句优化;</li><li>索引优化;</li><li>数据库表结构优化;</li><li>配置优化(连接数限制/文件数限制等);</li><li>硬件优化(SSD显然能提高IO性能);</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">成本(低) <span class="comment">--- &gt; 高</span></span><br><span class="line">SQL及索引 <span class="comment">---&gt; 数据库表结构 ---&gt; 系统配置 ---&gt; 硬件</span></span><br><span class="line">效果(高) &lt;---  低</span><br></pre></td></tr></table></figure><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>实验数据库采用mysql官方提供的示例数据库 sakila database,</p><ul><li>installation: <a href="https://dev.mysql.com/doc/sakila/en/sakila-installation.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/sakila/en/sakila-installation.html</a></li><li>sakila database zip: <a href="https://dev.mysql.com/doc/index-other.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/index-other.html</a></li></ul><p>导入sakila数据库及数据<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@(none)&gt;source /sqls/sakila-db/sakila-schema.sql;</span><br><span class="line">root@sakila&gt;source /sqls/sakila-db/sakila-data.sql;</span><br><span class="line">root@sakila&gt;select count(*) from film;</span><br><span class="line">+<span class="comment">----------+</span></span><br><span class="line">| count(*) |</span><br><span class="line">+<span class="comment">----------+</span></span><br><span class="line">|     1000 |</span><br><span class="line">+<span class="comment">----------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure></p><ul><li>普通账号没有设置创建schema的权限也不应设置其具有这样的权限, 所以先登录root账号导入sakila数据库及示例数据;</li></ul><p>授权普通账号dev操作sakila数据库的权限<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; grant all privileges on sakila.* to 'dev'@'%' with grant option;</span><br><span class="line">Query OK, 0 rows affected (0.05 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br></pre></td></tr></table></figure></p><ul><li>导入成功后, 需要对普通账号dev授权,dev账号才可以使用sakila数据库, 在mysql8.0+中授权分为创建账号和授权两个过程; </li><li>因为dev账号已创建; 所以这里只需要授权即可;</li><li>建议养成对普通账号每次只针对某个数据库的某些操作进行授权的习惯; 只要需要时才进行进一步授权; </li></ul><p>登录dev普通账号;</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">dev@(none)&gt;use sakila;</span><br><span class="line">Reading table information for completion of table and column names</span><br><span class="line">You can turn off this feature to get a quicker startup <span class="keyword">with</span> -A</span><br><span class="line"></span><br><span class="line"><span class="keyword">Database</span> <span class="keyword">changed</span></span><br><span class="line">dev@sakila&gt;</span><br><span class="line"></span><br><span class="line">dev@sakila&gt;<span class="keyword">select</span> @@<span class="keyword">version</span>;</span><br><span class="line">+<span class="comment">-----------+</span></span><br><span class="line">| @@version |</span><br><span class="line">+<span class="comment">-----------+</span></span><br><span class="line">| 8.0.12    |</span><br><span class="line">+<span class="comment">-----------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><p>如何发现有问题的SQL?<br>在进行SQL语句及索引优化之前, 需要知道哪些查询是需要优化的,是有效率问题的, 在mysql中可以用其提供的慢查询日志把那些有效率的日志记录下来, 然后进行分析优化, </p><h2 id="慢查日志"><a href="#慢查日志" class="headerlink" title="慢查日志"></a>慢查日志</h2><p>使用Mysql慢查日志对有效率的SQL进行监控,</p><p>开启慢查日志</p><ul><li>show variables like ‘slow_query_log’</li><li>set global slow_query_log_file = ‘/var/log/mysql/mysql-slow.log’</li><li>set global log_queries_not_using_indexes = on;</li><li>set global long_query_time =1 #即超过一秒的查询日志记录到慢查日志中;</li></ul><h3 id="查看慢查询开启状态"><a href="#查看慢查询开启状态" class="headerlink" title="查看慢查询开启状态"></a>查看慢查询开启状态</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;show variables like 'slow_query_log';</span><br><span class="line">+<span class="comment">----------------+-------+</span></span><br><span class="line">| Variable_name  | Value |</span><br><span class="line">+<span class="comment">----------------+-------+</span></span><br><span class="line">| slow_query_log | OFF   |</span><br><span class="line">+<span class="comment">----------------+-------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.04</span> sec)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看到slow_query_log 和 log_queries_not_using_indexes 都是未开启状态;</span></span><br><span class="line">dev@sakila&gt;<span class="keyword">show</span> <span class="keyword">variables</span> <span class="keyword">like</span> <span class="string">'%log%'</span>;</span><br><span class="line">+<span class="comment">--------------------------------------------+---------------------------------------------+</span></span><br><span class="line">| Variable_name                              | Value                                       |</span><br><span class="line">+<span class="comment">--------------------------------------------+---------------------------------------------+</span></span><br><span class="line">| activate_all_roles_on_login                | OFF                                         |</span><br><span class="line">| back_log                                   | 151                                         |</span><br><span class="line">| log_error                                  | stderr                                      |</span><br><span class="line">| log_error_services                         | log_filter_internal; log_sink_internal      |</span><br><span class="line">| log_error_verbosity                        | 2                                           |</span><br><span class="line">| log_output                                 | FILE                                        |</span><br><span class="line">| log_queries_not_using_indexes              | OFF                                         |</span><br><span class="line">| slow_query_log_file                        | /var/lib/mysql/2139b750c3f3-slow.log        |</span><br><span class="line">...</span><br><span class="line">+<span class="comment">--------------------------------------------+---------------------------------------------+</span></span><br><span class="line">81 rows in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><ul><li><code>slow_query_log OFF</code> 慢查日志  状态 - 未开启</li><li><code>log_queries_not_using_indexes</code>  将没有创建索引的SQL查询日志记录到慢查日志中 状态 - 未开启 </li></ul><p>查看执行时间超过多少s的SQL查询日志会记录到慢查日志中</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like 'long_query_time';</span><br><span class="line">+<span class="comment">-----------------+-----------+</span></span><br><span class="line">| Variable_name   | Value     |</span><br><span class="line">+<span class="comment">-----------------+-----------+</span></span><br><span class="line">| long_query_time | 10.000000 |</span><br><span class="line">+<span class="comment">-----------------+-----------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><ul><li><code>long_query_time</code>默认是执行时间超过10s的SQL查询将记录到慢查日志中;</li></ul><h3 id="慢查日志位置"><a href="#慢查日志位置" class="headerlink" title="慢查日志位置"></a>慢查日志位置</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like 'slow_query_log_file';</span><br><span class="line">+<span class="comment">---------------------+--------------------------------------+</span></span><br><span class="line">| Variable_name       | Value                                |</span><br><span class="line">+<span class="comment">---------------------+--------------------------------------+</span></span><br><span class="line">| slow_query_log_file |/var/lib/mysql/2139b750c3f3-slow.log  |</span><br><span class="line">+<span class="comment">---------------------+--------------------------------------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><ul><li><code>slow_query_log_file</code> 慢查日志默认位置在<code>/var/lib/mysql/2139b750c3f3-slow.log</code></li></ul><p>为便于学习实验 将设置long_query_time=0s; 即将所有查询日志都记录到慢查日志中, 实际使用中一般设置超过100ms的SQL查询记录到慢查日志中;<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set global long_query_time=0;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">#退出重新登录在查询</span><br><span class="line">mysql&gt; show variables like &apos;long_query_time&apos;;</span><br><span class="line">+-----------------+----------+</span><br><span class="line">| Variable_name   | Value    |</span><br><span class="line">+-----------------+----------+</span><br><span class="line">| long_query_time | 0.000000 |</span><br><span class="line">+-----------------+----------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><ul><li>设置long_query_time参数时，需要重新连接才能生效，不需要重启服务; 否则通过<code>show variables like &#39;long_query_time&#39;</code> 查看不到变化;</li></ul><p>开启将没有创建索引的sql查询日志记录到慢查日志中<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set global log_queries_not_using_indexes=on;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure></p><p>设置慢查日志文件位置 </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set global slow_query_log_file="/var/log/mysql/mysql-slow.log";</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">mysql&gt; show variables like 'slow_query_log_file';</span><br><span class="line">+<span class="comment">---------------------+-------------------------------+</span></span><br><span class="line">| Variable_name       | Value                         |</span><br><span class="line">+<span class="comment">---------------------+-------------------------------+</span></span><br><span class="line">| slow_query_log_file | /var/log/mysql/mysql-slow.log |</span><br><span class="line">+<span class="comment">---------------------+-------------------------------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><ul><li>设置<code>slow_query_log_file</code>时, 目录必须存在, 并且mysql有权读写该目录,</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir /var/log/mysql</span><br><span class="line">chown mysql:mysql /var/log/mysql</span><br></pre></td></tr></table></figure><p>否则报错</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set global slow_query_log_file="/var/log/mysql/mysql-slow.log";</span><br><span class="line">ERROR 1231 (42000): Variable 'slow_query_log_file' can't be <span class="keyword">set</span> <span class="keyword">to</span> the <span class="keyword">value</span> <span class="keyword">of</span> <span class="string">'/var/log/mysql/mysql-slow.log'</span></span><br></pre></td></tr></table></figure><h3 id="开启慢查日志"><a href="#开启慢查日志" class="headerlink" title="开启慢查日志"></a>开启慢查日志</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set global slow_query_log=on;</span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br></pre></td></tr></table></figure><h3 id="查看慢查日志"><a href="#查看慢查日志" class="headerlink" title="查看慢查日志"></a>查看慢查日志</h3><p>进行简单的查询操作查看慢日志文件是否有记录<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;show tables;</span><br><span class="line">dev@sakila&gt;select * from film limit 10;</span><br></pre></td></tr></table></figure></p><h3 id="调整时区"><a href="#调整时区" class="headerlink" title="调整时区"></a>调整时区</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;show variables like '%time_zone%';</span><br><span class="line">+<span class="comment">------------------+--------+</span></span><br><span class="line">| Variable_name    | Value  |</span><br><span class="line">+<span class="comment">------------------+--------+</span></span><br><span class="line">| system_time_zone | UTC    |</span><br><span class="line">| time_zone        | SYSTEM |</span><br><span class="line">+<span class="comment">------------------+--------+</span></span><br><span class="line">2 rows in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">dev@sakila&gt;<span class="keyword">set</span> <span class="keyword">time_zone</span>=<span class="string">'+8:00'</span>;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">dev@sakila&gt;show variables like '%time_zone%';</span><br><span class="line">+<span class="comment">------------------+--------+</span></span><br><span class="line">| Variable_name    | Value  |</span><br><span class="line">+<span class="comment">------------------+--------+</span></span><br><span class="line">| system_time_zone | UTC    |</span><br><span class="line">| time_zone        | +08:00 |</span><br><span class="line">+<span class="comment">------------------+--------+</span></span><br><span class="line">2 rows in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><p>在命令一个终端可以查看到SQL查询日志记录到了慢查日志文件中, </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker exec -it mysql-db tail -f /var/log/mysql/mysql-slow.log</span><br><span class="line"><span class="comment"># Time: 2018-11-03T06:12:56.235450Z</span></span><br><span class="line"><span class="comment"># User@Host: dev[dev] @ localhost []  Id:    28</span></span><br><span class="line"><span class="comment"># Query_time: 0.000182  Lock_time: 0.000000 Rows_sent: 1  Rows_examined: 0</span></span><br><span class="line"><span class="keyword">SET</span> <span class="built_in">timestamp</span>=<span class="number">1541225576</span>;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DATABASE</span>();</span><br><span class="line"><span class="comment"># Time: 2018-11-03T06:12:56.235855Z</span></span><br><span class="line"><span class="comment"># User@Host: dev[dev] @ localhost []  Id:    28</span></span><br><span class="line"><span class="comment"># Query_time: 0.000160  Lock_time: 0.000000 Rows_sent: 1  Rows_examined: 0</span></span><br><span class="line"><span class="keyword">SET</span> <span class="built_in">timestamp</span>=<span class="number">1541225576</span>;</span><br><span class="line"><span class="comment"># administrator command: Init DB;</span></span><br><span class="line"><span class="comment"># Time: 2018-11-03T06:13:34.376262Z</span></span><br><span class="line"><span class="comment"># User@Host: dev[dev] @ localhost []  Id:    28</span></span><br><span class="line"><span class="comment"># Query_time: 0.000779  Lock_time: 0.000337 Rows_sent: 10  Rows_examined: 10</span></span><br><span class="line"><span class="keyword">SET</span> <span class="built_in">timestamp</span>=<span class="number">1541225614</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> film <span class="keyword">limit</span> <span class="number">10</span>;</span><br><span class="line"><span class="comment"># Time: 2018-11-03T06:14:21.627579Z</span></span><br><span class="line"><span class="comment"># User@Host: dev[dev] @ localhost []  Id:    28</span></span><br><span class="line"><span class="comment"># Query_time: 0.000388  Lock_time: 0.000121 Rows_sent: 1  Rows_examined: 0</span></span><br><span class="line"><span class="keyword">SET</span> <span class="built_in">timestamp</span>=<span class="number">1541225661</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> film;</span><br></pre></td></tr></table></figure><h3 id="慢查日志存储格式"><a href="#慢查日志存储格式" class="headerlink" title="慢查日志存储格式"></a>慢查日志存储格式</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Time: 2018-11-03T06:14:21.627579Z</span></span><br><span class="line"><span class="comment"># User@Host: dev[dev] @ localhost []  Id:    28</span></span><br><span class="line"><span class="comment"># Query_time: 0.000388  Lock_time: 0.000121 Rows_sent: 1  Rows_examined: 0</span></span><br><span class="line"><span class="keyword">SET</span> <span class="built_in">timestamp</span>=<span class="number">1541225661</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> film;</span><br></pre></td></tr></table></figure><p>一条慢查日志主要包括五个部分</p><ol><li>查询的执行时间</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Time: 2018-11-03T06:14:21.627579Z</span></span><br></pre></td></tr></table></figure><ol start="2"><li>执行SQL的主机信息</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># User@Host: dev[dev] @ localhost []  Id:    28</span></span><br></pre></td></tr></table></figure><ol start="3"><li>SQL的执行信息</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Query_time: 0.000388  Lock_time: 0.000121 Rows_sent: 1  Rows_examined: 0</span></span><br></pre></td></tr></table></figure><ol start="4"><li>SQL的执行时间</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> <span class="built_in">timestamp</span>=<span class="number">1541225661</span>;</span><br></pre></td></tr></table></figure><ol start="5"><li>SQL的内容</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> film;</span><br></pre></td></tr></table></figure><h2 id="慢查日志分析"><a href="#慢查日志分析" class="headerlink" title="慢查日志分析"></a>慢查日志分析</h2><p>慢查询日志分析工具有很多, 如mysqlsla, pt-query-digest以及官方默认提供的mysqldumpslow等, </p><h3 id="mysqldumpslow"><a href="#mysqldumpslow" class="headerlink" title="mysqldumpslow"></a>mysqldumpslow</h3><p>mysqldumpslow 是一个MySQL官方提供的慢查日志分析工具</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker exec -it mysql-db mysqldumpslow -h</span><br><span class="line">Option h requires an argument</span><br><span class="line">ERROR: bad option</span><br><span class="line"></span><br><span class="line">Usage: mysqldumpslow [ OPTS... ] [ LOGS... ]</span><br><span class="line"></span><br><span class="line">Parse and summarize the MySQL slow query log. Options are</span><br><span class="line"></span><br><span class="line">  <span class="comment">--verbose    verbose</span></span><br><span class="line">  <span class="comment">--debug      debug</span></span><br><span class="line">  <span class="comment">--help       write this text to standard output</span></span><br><span class="line"></span><br><span class="line">  -v           verbose</span><br><span class="line">  -d           debug</span><br><span class="line">  -s ORDER     what to sort by (al, at, ar, c, l, r, t), 'at' is default</span><br><span class="line">                al: average <span class="keyword">lock</span> <span class="built_in">time</span></span><br><span class="line">                ar: average <span class="keyword">rows</span> sent</span><br><span class="line">                <span class="keyword">at</span>: average <span class="keyword">query</span> <span class="built_in">time</span></span><br><span class="line">                 c: <span class="keyword">count</span></span><br><span class="line">                 l: <span class="keyword">lock</span> <span class="built_in">time</span></span><br><span class="line">                 r: <span class="keyword">rows</span> sent</span><br><span class="line">                 t: <span class="keyword">query</span> <span class="built_in">time</span></span><br><span class="line">  -r           <span class="keyword">reverse</span> the <span class="keyword">sort</span> <span class="keyword">order</span> (largest <span class="keyword">last</span> instead <span class="keyword">of</span> <span class="keyword">first</span>)</span><br><span class="line">  -t <span class="keyword">NUM</span>       just <span class="keyword">show</span> the top n queries</span><br><span class="line">  -a           don<span class="string">'t abstract all numbers to N and strings to '</span>S<span class="string">'</span></span><br><span class="line"><span class="string">  -n NUM       abstract numbers with at least n digits within names</span></span><br><span class="line"><span class="string">  -g PATTERN   grep: only consider stmts that include this string</span></span><br><span class="line"><span class="string">  -h HOSTNAME  hostname of db server for *-slow.log filename (can be wildcard),</span></span><br><span class="line"><span class="string">               default is '</span>*<span class="string">', i.e. match all</span></span><br><span class="line"><span class="string">  -i NAME      name of server instance (if using mysql.server startup script)</span></span><br><span class="line"><span class="string">  -l           don'</span>t subtract <span class="keyword">lock</span> <span class="built_in">time</span> <span class="keyword">from</span> total <span class="built_in">time</span></span><br></pre></td></tr></table></figure><ul><li>可以通过<code>s</code>指定排序规则;</li><li>通过<code>t</code>指定最前面的n条查询记录;</li></ul><p>下面通过实例分析一条日志,</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker exec -it mysql-db mysqldumpslow -t 1 /var/log/mysql/mysql-slow.log;</span><br><span class="line"></span><br><span class="line">Reading mysql slow query log from /var/log/mysql/mysql-slow.log</span><br><span class="line">Count: 1  Time=0.02s (0s)  <span class="keyword">Lock</span>=<span class="number">0.00</span>s (<span class="number">0</span>s)  <span class="keyword">Rows</span>=<span class="number">0.0</span> (<span class="number">0</span>), dev[dev]@localhost</span><br><span class="line">  <span class="keyword">CREATE</span> <span class="keyword">TRIGGER</span> <span class="string">`ins_film`</span> <span class="keyword">AFTER</span> <span class="keyword">INSERT</span> <span class="keyword">ON</span> <span class="string">`film`</span> <span class="keyword">FOR</span> <span class="keyword">EACH</span> <span class="keyword">ROW</span> <span class="keyword">BEGIN</span></span><br><span class="line">  <span class="keyword">INSERT</span> <span class="keyword">INTO</span> film_text (film_id, title, description)</span><br><span class="line">  <span class="keyword">VALUES</span> (new.film_id, new.title, new.description);</span><br><span class="line">  <span class="keyword">END</span></span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:left">关键字</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left"><code>Count</code></td><td style="text-align:left">这条SQL执行的次数</td></tr><tr><td style="text-align:left"><code>Time</code></td><td style="text-align:left">执行耗时</td></tr><tr><td style="text-align:left"><code>Lock</code></td><td style="text-align:left">锁定时间</td></tr><tr><td style="text-align:left"><code>Rows</code></td><td style="text-align:left">发送的行数</td></tr></tbody></table><h3 id="pt-query-digest"><a href="#pt-query-digest" class="headerlink" title="pt-query-digest"></a>pt-query-digest</h3><p>pt-query-digest是用于分析mySQL慢查询的一个工具，它可以分析binlog、General log、slowlog，也可以通过SHOWPROCESSLIST或者通过tcpdump抓取的MySQL协议数据来进行分析。可以把分析结果输出到文件中，分析过程是先对查询语句的条件进行参数化，然后对参数化以后的查询进行分组统计，统计出各查询的执行时间、次数、占比等，可以借助分析结果找出问题进行优化。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">输出到文件</span><br><span class="line">pt-query-digest slow.log &gt; slow_log.report</span><br><span class="line"></span><br><span class="line">输出到数据库表</span><br><span class="line">pt-query-digest slow.log -review \</span><br><span class="line">h = 127.0.0.1,D=test,p=root,P=3306,u=root,t=query_review \</span><br><span class="line"><span class="comment">--create-reviewtable \</span></span><br><span class="line"><span class="comment">--review-history t=hostname_slow</span></span><br></pre></td></tr></table></figure><p>常用选项<br>pt-query-digest常用选项, </p><table><thead><tr><th style="text-align:left">选项</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left"><code>--create-review-table</code></td><td style="text-align:left">当使用—review参数，把分析结果输出到表中</td></tr><tr><td style="text-align:left"><code>--create-history-table</code></td><td style="text-align:left">但是用—history参数，把分析结果输出到表中</td></tr><tr><td style="text-align:left"><code>--filter</code></td><td style="text-align:left">对输入的慢查询按指定的字符串进行匹配过滤后，在进行分析</td></tr><tr><td style="text-align:left"><code>--limit</code></td><td style="text-align:left">限制输出结果百分比或数量，默认值是20，即将最慢的20条语句输出</td></tr><tr><td style="text-align:left"><code>--host</code></td><td style="text-align:left">HostName</td></tr><tr><td style="text-align:left"><code>--user</code></td><td style="text-align:left">用户名</td></tr><tr><td style="text-align:left"><code>--password</code></td><td style="text-align:left">密码</td></tr><tr><td style="text-align:left"><code>--history</code></td><td style="text-align:left">将分析结果保存到表中，分析结果比较详细</td></tr><tr><td style="text-align:left"><code>--review</code></td><td style="text-align:left">将分析结果保存到表中</td></tr><tr><td style="text-align:left"><code>--output</code></td><td style="text-align:left">分析结果输出类型</td></tr><tr><td style="text-align:left"><code>--since</code></td><td style="text-align:left">从什么时间开始分析，值为字符串</td></tr><tr><td style="text-align:left"><code>--until</code></td><td style="text-align:left">截止时间，配合since一起分析</td></tr></tbody></table><p>pt-query-digest分析结果主要有以下几部分,</p><ul><li>总体统计结果;</li><li>查询分组统计结果;</li><li>每一种查询的详细统计结果;</li></ul><p>总体统计结果,</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 59.5s user time, 90ms system time, 51.81M rss, 228.12M vsz</span></span><br><span class="line"><span class="comment"># Current date: Sun Aug  3 16:09:31 2014</span></span><br><span class="line"><span class="comment"># Hostname: db1.test.com</span></span><br><span class="line"><span class="comment"># Files: /var/log/mysql/mysql-slow.log</span></span><br><span class="line"><span class="comment"># Overall: 224.01k total, 570 unique, 0.01 QPS, 0.09x concurrency ________</span></span><br><span class="line"><span class="comment"># Time range: 2013-10-09 17:55:04 to 2014-08-03 15:16:38</span></span><br><span class="line"><span class="comment"># Attribute          total     min     max     avg     95%  stddev  median</span></span><br><span class="line"><span class="comment"># ============     ======= ======= ======= ======= ======= ======= =======</span></span><br><span class="line"><span class="comment"># Exec time        2188385s      2s   7229s     10s     13s     67s      5s</span></span><br><span class="line"><span class="comment"># Lock time        100721s       0    365s   450ms      2s      5s   119us</span></span><br><span class="line"><span class="comment"># Rows sent         26.98G       0   3.30M 126.27k 328.61k 371.66k    4.96</span></span><br><span class="line"><span class="comment"># Rows examine     394.85G       0   3.32G   1.80M   3.03M  20.83M 562.03k</span></span><br><span class="line"><span class="comment"># Query size        78.65M       6   5.54k  368.18  685.39  241.61  271.23</span></span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:left">选项</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left"><code>Overall</code></td><td style="text-align:left">总共有多少条查询</td></tr><tr><td style="text-align:left"><code>unique</code></td><td style="text-align:left">唯一查询数量</td></tr><tr><td style="text-align:left"><code>Time range</code></td><td style="text-align:left">查询执行的时间范围</td></tr><tr><td style="text-align:left"><code>total</code></td><td style="text-align:left">总计</td></tr><tr><td style="text-align:left"><code>min</code></td><td style="text-align:left">最小</td></tr><tr><td style="text-align:left"><code>max</code></td><td style="text-align:left">最大</td></tr><tr><td style="text-align:left"><code>avg</code></td><td style="text-align:left">平均</td></tr><tr><td style="text-align:left"><code>95%</code></td><td style="text-align:left">95%的查询时间，重点分析</td></tr><tr><td style="text-align:left"><code>median</code></td><td style="text-align:left">中位数，把所有值从小到大排列，位置位于中间那个数</td></tr></tbody></table><p>分组统计结果,</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Profile</span></span><br><span class="line"><span class="comment"># Rank Query ID           Response time     Calls R/Call    V/M   Item</span></span><br><span class="line"><span class="comment"># ==== ================== ================= ===== ========= ===== ========</span></span><br><span class="line"><span class="comment">#    1 0xA6FE3D6982868655 351140.1266 16.0%   622  564.5340 99... CREATE TABLE dw_user_cache `dw_user_cache`</span></span><br><span class="line"><span class="comment">#    2 0x281C83DE62A11A8B 310896.7675 14.2% 40841    7.6124  6.51 SELECT dw_borrow_tender dw_borrow dw_user dw_credit dw_credit_rank</span></span><br><span class="line"><span class="comment">#    3 0x26BA6BEAE6C74350 279545.6534 12.8%  1305  214.2112 25... SELECT dw_account_log</span></span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:left">选项</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left"><code>Response</code></td><td style="text-align:left">总的响应时间</td></tr><tr><td style="text-align:left"><code>time</code></td><td style="text-align:left">该查询在本次分析中占用的时间比</td></tr><tr><td style="text-align:left"><code>Calls</code></td><td style="text-align:left">执行次数</td></tr><tr><td style="text-align:left"><code>R/Call</code></td><td style="text-align:left">平均每次执行的响应时间</td></tr><tr><td style="text-align:left"><code>Item</code></td><td style="text-align:left">查询对象</td></tr></tbody></table><p>每一种查询的详细统计结果,</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Query 172: 0.00 QPS, 0.00x concurrency, ID 0x61199112D48D8F69 at byte 56964086</span></span><br><span class="line"><span class="comment"># This item is included in the report because it matches --outliers.</span></span><br><span class="line"><span class="comment"># Scores: V/M = 0.85</span></span><br><span class="line"><span class="comment"># Time range: 2013-11-20 17:00:38 to 2014-03-23 09:00:45</span></span><br><span class="line"><span class="comment"># Attribute    pct   total     min     max     avg     95%  stddev  median</span></span><br><span class="line"><span class="comment"># ============ === ======= ======= ======= ======= ======= ======= =======</span></span><br><span class="line"><span class="comment"># Count          0      26</span></span><br><span class="line"><span class="comment"># Exec time      0    172s      5s     17s      7s      8s      2s      6s</span></span><br><span class="line"><span class="comment"># Lock time      0     3ms    63us   180us   100us   119us    22us    93us</span></span><br><span class="line"><span class="comment"># Rows sent      0     208       8       8       8       8       0       8</span></span><br><span class="line"><span class="comment"># Rows examine   0 333.82k   6.95k  20.62k  12.84k  18.47k   4.33k  10.80k</span></span><br><span class="line"><span class="comment"># Query size     0   5.59k     220     220     220     220       0     220</span></span><br><span class="line"><span class="comment"># String:</span></span><br><span class="line"><span class="comment"># Databases    test2</span></span><br><span class="line"><span class="comment"># Hosts</span></span><br><span class="line"><span class="comment"># Users        rx1919 (24/92%), tn1819 (2/7%)</span></span><br><span class="line"><span class="comment"># Query_time distribution</span></span><br><span class="line"><span class="comment">#   1us</span></span><br><span class="line"><span class="comment">#  10us</span></span><br><span class="line"><span class="comment"># 100us</span></span><br><span class="line"><span class="comment">#   1ms</span></span><br><span class="line"><span class="comment">#  10ms</span></span><br><span class="line"><span class="comment"># 100ms</span></span><br><span class="line"><span class="comment">#    1s  ################################################################</span></span><br><span class="line"><span class="comment">#  10s+  #####</span></span><br><span class="line"><span class="comment"># Tables</span></span><br><span class="line"><span class="comment">#    SHOW TABLE STATUS FROM `test2` LIKE 'dw_bbs_topics'G</span></span><br><span class="line"><span class="comment">#    SHOW CREATE TABLE `test2`.`dw_bbs_topics`G</span></span><br><span class="line"><span class="comment">#    SHOW TABLE STATUS FROM `test2` LIKE 'dw_bbs_forums'G</span></span><br><span class="line"><span class="comment">#    SHOW CREATE TABLE `test2`.`dw_bbs_forums`G</span></span><br><span class="line"><span class="comment"># EXPLAIN /*!50100 PARTITIONS*/</span></span><br><span class="line"><span class="keyword">select</span> p1.*,p2.name <span class="keyword">as</span> forum_name <span class="keyword">from</span> <span class="string">`dw_bbs_topics`</span> <span class="keyword">as</span> p1 </span><br><span class="line">                                <span class="keyword">left</span> <span class="keyword">join</span> dw_bbs_forums <span class="keyword">as</span> p2 <span class="keyword">on</span> p2.id = p1.fid</span><br><span class="line">                                <span class="keyword">where</span> isrecycle&lt;&gt;<span class="number">1</span> <span class="keyword">and</span> isrecycle&lt;&gt;<span class="number">1</span> <span class="keyword">and</span> p1.status = <span class="number">1</span> <span class="keyword">and</span> p1.isgood = <span class="number">1</span>    <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">rand</span>()   <span class="keyword">limit</span> <span class="number">8</span>G</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:left">选项</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left"><code>ID</code></td><td style="text-align:left">查询的ID号，和上图的Query ID对应</td></tr><tr><td style="text-align:left"><code>Databases</code></td><td style="text-align:left">数据库名</td></tr><tr><td style="text-align:left"><code>Users</code></td><td style="text-align:left">各个用户执行的次数（占比）</td></tr><tr><td style="text-align:left"><code>Query_time distribution</code></td><td style="text-align:left">查询时间分布, 长短体现区间占比，本例中1s-10s之间查询数量是10s以上的两倍</td></tr><tr><td style="text-align:left"><code>Tables</code></td><td style="text-align:left">查询涉及到的表</td></tr><tr><td style="text-align:left"><code>EXPLAIN</code></td><td style="text-align:left">示例</td></tr></tbody></table><h3 id="用法举例"><a href="#用法举例" class="headerlink" title="用法举例"></a>用法举例</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">(1)直接分析慢查询文件:</span><br><span class="line">pt-query-digest  slow.log &gt; slow_report.log</span><br><span class="line"></span><br><span class="line">(2)分析最近12小时内的查询：</span><br><span class="line">pt-query-digest  <span class="comment">--since=12h  slow.log &gt; slow_report2.log</span></span><br><span class="line"></span><br><span class="line">(3)分析指定时间范围内的查询：</span><br><span class="line">pt-query-digest slow.log <span class="comment">--since '2014-04-17 09:30:00' --until '2014-04-17 10:00:00'&gt; &gt; slow_report3.log</span></span><br><span class="line"></span><br><span class="line">(4)分析指含有<span class="keyword">select</span>语句的慢查询</span><br><span class="line">pt-<span class="keyword">query</span>-digest<span class="comment">--filter '$event-&gt;&#123;fingerprint&#125; =~ m/^select/i' slow.log&gt; slow_report4.log</span></span><br><span class="line"></span><br><span class="line">(<span class="number">5</span>) 针对某个用户的慢查询</span><br><span class="line">pt-<span class="keyword">query</span>-digest<span class="comment">--filter '($event-&gt;&#123;user&#125; || "") =~ m/^root/i' slow.log&gt; slow_report5.log</span></span><br><span class="line"></span><br><span class="line">(<span class="number">6</span>) 查询所有所有的全表扫描或<span class="keyword">full</span> <span class="keyword">join</span>的慢查询</span><br><span class="line">pt-<span class="keyword">query</span>-digest<span class="comment">--filter '(($event-&gt;&#123;Full_scan&#125; || "") eq "yes") ||(($event-&gt;&#123;Full_join&#125; || "") eq "yes")' slow.log&gt; slow_report6.log</span></span><br><span class="line"></span><br><span class="line">(<span class="number">7</span>)把查询保存到query_review表</span><br><span class="line">pt-<span class="keyword">query</span>-digest  <span class="comment">--user=root –password=abc123 --review  h=localhost,D=test,t=query_review--create-review-table  slow.log</span></span><br><span class="line"></span><br><span class="line">(<span class="number">8</span>)把查询保存到query_history表</span><br><span class="line">pt-<span class="keyword">query</span>-digest  <span class="comment">--user=root –password=abc123 --review  h=localhost,D=test,t=query_ history--create-review-table  slow.log_20140401</span></span><br><span class="line">pt-<span class="keyword">query</span>-digest  <span class="comment">--user=root –password=abc123--review  h=localhost,D=test,t=query_history--create-review-table  slow.log_20140402</span></span><br><span class="line"></span><br><span class="line">(<span class="number">9</span>)通过tcpdump抓取mysql的tcp协议数据，然后再分析</span><br><span class="line">tcpdump -s <span class="number">65535</span> -x -nn -q -tttt -i <span class="keyword">any</span> -c <span class="number">1000</span> port <span class="number">3306</span> &gt; mysql.tcp.txt</span><br><span class="line">pt-<span class="keyword">query</span>-digest <span class="comment">--type tcpdump mysql.tcp.txt&gt; slow_report9.log</span></span><br><span class="line"></span><br><span class="line">(<span class="number">10</span>)分析<span class="keyword">binlog</span></span><br><span class="line">mysqlbinlog mysql-<span class="keyword">bin</span><span class="number">.000093</span> &gt; mysql-bin000093.sql</span><br><span class="line">pt-<span class="keyword">query</span>-digest  <span class="comment">--type=binlog  mysql-bin000093.sql &gt; slow_report10.log</span></span><br><span class="line"></span><br><span class="line">(<span class="number">11</span>)分析<span class="keyword">general</span> <span class="keyword">log</span></span><br><span class="line">pt-<span class="keyword">query</span>-digest  <span class="comment">--type=genlog  localhost.log &gt; slow_report11.log</span></span><br></pre></td></tr></table></figure><h2 id="通过慢查日志发现问题SQL"><a href="#通过慢查日志发现问题SQL" class="headerlink" title="通过慢查日志发现问题SQL"></a>通过慢查日志发现问题SQL</h2><p>如何通过慢查日志发现有问题的SQL？ 主要通过以下几个方面来判断, </p><ol><li><p>查询次数多且每次查询占用时间长的SQL<br>通常为pt-query-digest分析的前几个查询</p></li><li><p>IO大的SQL<br>注意pt-query-digest分析中的Rows examine项 (Rows examine 指一条查询SQL中扫描的行数), 扫描行数越多, 说明其IO消耗也会越大;</p></li><li><p>未命中索引的SQL<br>注意pt-query-digest分析中Rows examine 和Rows Send的对比,  Rows examine(扫描的行数) 要比Rows Send(发送的行数)数据大得多, 说明此次查询基本靠扫描查询出来的;</p></li></ol><h2 id="通过explain查询和分析SQL的执行计划"><a href="#通过explain查询和分析SQL的执行计划" class="headerlink" title="通过explain查询和分析SQL的执行计划"></a>通过explain查询和分析SQL的执行计划</h2><p>如何分析SQL查询</p><ol><li>使用explain查询SQL的执行计划</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;explain select customer_id, first_name, last_name from customer \G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">           id: 1</span><br><span class="line">  select_type: SIMPLE</span><br><span class="line">        table: customer</span><br><span class="line">   partitions: NULL</span><br><span class="line">         type: ALL</span><br><span class="line">possible_keys: NULL</span><br><span class="line">          key: NULL</span><br><span class="line">      key_len: NULL</span><br><span class="line">          ref: NULL</span><br><span class="line">         rows: 599</span><br><span class="line">     filtered: 100.00</span><br><span class="line">        Extra: NULL</span><br><span class="line">1 row in <span class="keyword">set</span>, <span class="number">1</span> <span class="keyword">warning</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:left">列名</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left"><code>select_type</code></td><td style="text-align:left">查询的类型</td></tr><tr><td style="text-align:left"><code>table</code></td><td style="text-align:left">显示这一行的数据是关于哪张表的</td></tr><tr><td style="text-align:left"><code>type</code></td><td style="text-align:left">这是重要的列, 显示连接使用了哪种类型, 从最好到最差的连接类型为const, eq_reg, ref,range, index 和 ALL</td></tr><tr><td style="text-align:left"><code>possible_keys</code></td><td style="text-align:left">显示可能应用在这张表中的索引。 如果为空, 没有可能的索引</td></tr><tr><td style="text-align:left"><code>key</code></td><td style="text-align:left">实际使用的索引。如果为NULL, 则没有使用索引</td></tr><tr><td style="text-align:left"><code>key_len</code></td><td style="text-align:left">使用索引的长度。在不损失精确性的情况下, 长度越短越好</td></tr><tr><td style="text-align:left"><code>ref</code></td><td style="text-align:left">显示索引的哪一列被使用了, 如果可能的话, 是一个常数</td></tr><tr><td style="text-align:left"><code>rows</code></td><td style="text-align:left">MySQL认为必须检查的用来返回请求数据的行数</td></tr><tr><td style="text-align:left"><code>filtered</code></td><td style="text-align:left">扫描函数占数据表的比例</td></tr><tr><td style="text-align:left"><code>extra</code></td><td style="text-align:left">是否需要额外的条件及操作来完成当前查询, 返回为NULL表示不需要, 如值为Using filesort或者Using temporary时 说明需要进行优化了</td></tr></tbody></table><p>select_type 查询类型说明,</p><table><thead><tr><th style="text-align:left">选择查询类型</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left"><code>SIMPLE</code></td><td style="text-align:left">简单查询(不适用union和子查询的)</td></tr><tr><td style="text-align:left"><code>PRIMARY</code></td><td style="text-align:left">最外层的查询</td></tr><tr><td style="text-align:left"><code>UNION</code></td><td style="text-align:left">UNION中的第二个或者后面的SELECT语句</td></tr><tr><td style="text-align:left"><code>DEPENDENT</code></td><td style="text-align:left">UNION中的第二个或者后面的SELECT语句,依赖于外部查询</td></tr><tr><td style="text-align:left"><code>UNION</code></td><td style="text-align:left">UNION结果</td></tr><tr><td style="text-align:left"><code>SUBQUERY</code></td><td style="text-align:left">子查询中的第一个SELECT语句</td></tr><tr><td style="text-align:left"><code>DEPENDENT</code></td><td style="text-align:left">子查询中的第一个SELECT语句，依赖于外部查询</td></tr><tr><td style="text-align:left"><code>DERIVED</code></td><td style="text-align:left">派生表的SELECT(FROM子句的子查询)</td></tr><tr><td style="text-align:left"><code>MATERIALIZED</code></td><td style="text-align:left">Materialized subquery</td></tr><tr><td style="text-align:left"><code>UNCACHEABLE</code></td><td style="text-align:left">对于该结果不能被缓存，必须重新评估外部查询的每一行子查询</td></tr><tr><td style="text-align:left"><code>UNCACHEABLE</code></td><td style="text-align:left">UNION中的第二个或者后面的SELECT语句属于不可缓存子查询 (see UNCACHEABLE SUBQUERY)</td></tr></tbody></table><p>type 连接类型说明, </p><table><thead><tr><th style="text-align:left">连接类型</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left"><code>const</code></td><td style="text-align:left">指常数查找, 一般指对主键或唯一索引进行查找;</td></tr><tr><td style="text-align:left"><code>eq_reg</code></td><td style="text-align:left">指在一定范围内查找,一般是基于唯一索引/主键的范围查找;</td></tr><tr><td style="text-align:left"><code>ref</code></td><td style="text-align:left">常见于连接查询中, 基于某一个索引查找;</td></tr><tr><td style="text-align:left"><code>range</code></td><td style="text-align:left">基于索引的范围查找;</td></tr><tr><td style="text-align:left"><code>index</code></td><td style="text-align:left">对索引进行扫描查找;</td></tr><tr><td style="text-align:left"><code>ALL</code></td><td style="text-align:left">进行表扫描查找;</td></tr></tbody></table><p>extra返回值说明,</p><table><thead><tr><th style="text-align:left">返回值</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left"><code>Using filesort</code></td><td style="text-align:left">Mysql需要进行额外的步骤来发现如何对返回的行排序。它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行</td></tr><tr><td style="text-align:left"><code>Using temporary</code></td><td style="text-align:left">Mysql需要创建一个临时表来存储结果, 这通常发生在对不同的列集进行ORDER BY上, 而不是GROUP BY 上</td></tr></tbody></table><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;explain select customer_id, first_name, last_name</span><br><span class="line">    -&gt; from customer</span><br><span class="line">    -&gt; where customer_id &gt; 50</span><br><span class="line">    -&gt; group by customer_id, first_name, last_name</span><br><span class="line">    -&gt; having count(customer_id) &gt; 1</span><br><span class="line">    -&gt; order by customer_id, first_name \G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">           id: 1</span><br><span class="line">  select_type: SIMPLE</span><br><span class="line">        table: customer</span><br><span class="line">   partitions: NULL</span><br><span class="line">         type: range</span><br><span class="line">possible_keys: PRIMARY</span><br><span class="line">          key: PRIMARY</span><br><span class="line">      key_len: 2</span><br><span class="line">          ref: NULL</span><br><span class="line">         rows: 549</span><br><span class="line">     filtered: 100.00</span><br><span class="line">        Extra: Using where; Using temporary; Using filesort</span><br><span class="line">1 row in <span class="keyword">set</span>, <span class="number">1</span> <span class="keyword">warning</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><blockquote><p>Mysql每次读取是以页为单位的, 而一页中存储的索引越多, 其查询效率就越高, 所以索引长度越小越好;</p></blockquote><h2 id="Max-函数优化"><a href="#Max-函数优化" class="headerlink" title="Max()函数优化"></a>Max()函数优化</h2><p>Max()函数经常会被用于查找出最大的或最后的某个时间或数值操作;</p><p>Max()函数示例, 查询最后支付时间,</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;explain select max(payment_date) from payment \G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">           id: 1</span><br><span class="line">  select_type: SIMPLE</span><br><span class="line">        table: payment</span><br><span class="line">   partitions: NULL</span><br><span class="line">         type: ALL</span><br><span class="line">possible_keys: NULL</span><br><span class="line">          key: NULL</span><br><span class="line">      key_len: NULL</span><br><span class="line">          ref: NULL</span><br><span class="line">         rows: 16086</span><br><span class="line">     filtered: 100.00</span><br><span class="line">        Extra: NULL</span><br><span class="line">1 row in <span class="keyword">set</span>, <span class="number">1</span> <span class="keyword">warning</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><ul><li>type值为ALL 表示进行表扫描; </li><li>rows值为16086 表示扫描了16086行数据;</li><li>filtered值为100 表示进行了完整全表扫描;</li></ul><p>显然当payment数据量很大时就会消耗更多的IO, 从而会拖慢服务器的性能;</p><p>通常情况下 是对这个字段建立索引, </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;create index idx_paydate on payment(payment_date);</span><br><span class="line">Query OK, 0 rows affected (0.11 sec)</span><br><span class="line">Records: 0  Duplicates: 0  Warnings: 0</span><br><span class="line"></span><br><span class="line">dev@sakila&gt;explain select max(payment_date) from payment \G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">           id: 1</span><br><span class="line">  select_type: SIMPLE</span><br><span class="line">        table: NULL</span><br><span class="line">   partitions: NULL</span><br><span class="line">         type: NULL</span><br><span class="line">possible_keys: NULL</span><br><span class="line">          key: NULL</span><br><span class="line">      key_len: NULL</span><br><span class="line">          ref: NULL</span><br><span class="line">         rows: NULL</span><br><span class="line">     filtered: NULL</span><br><span class="line">        Extra: <span class="keyword">Select</span> <span class="keyword">tables</span> optimized away</span><br><span class="line"><span class="number">1</span> <span class="keyword">row</span> <span class="keyword">in</span> <span class="keyword">set</span>, <span class="number">1</span> <span class="keyword">warning</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><p>通过建立索引后, 可以看到查询类型不在是All, 同时Extra 表示为 Select tables optimized away, 表示不需进行表的操作就可以完成查询, 因为索引是按顺序排序的, 通过索引就可以知道payment_date最后一个数据值, 因此并不需要进行表的操作, 大大优化了执行效率, 同时尽可能大的减少IO操作, 这种情况下不过payment_date的数据结构是什么样的, 不管它的数据量有多大, 它的执行效率基本是恒定的;</p><p>所以像Max()函数这类的操作优化的思路之一就是为字段建立索引来进行优化;</p><h2 id="Count-函数优化"><a href="#Count-函数优化" class="headerlink" title="Count()函数优化"></a>Count()函数优化</h2><p>问题: 在一条SQL中同时查出2006年和2007年电影的数量</p><p>方式一</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(release_year=<span class="string">'2006'</span> <span class="keyword">OR</span> release_year=<span class="string">'2007'</span>) <span class="keyword">FROM</span> film;</span><br></pre></td></tr></table></figure><p>方式二</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*) <span class="keyword">FROM</span> film <span class="keyword">WHERE</span> release_year=<span class="string">'2006'</span> <span class="keyword">AND</span> release_year=<span class="string">'2007'</span>;</span><br></pre></td></tr></table></figure><p>方式一无法区分2006和2007的电影数量;<br>方式二release_year值不存在同时为2006和2007的情况;</p><p>显然方式一二都无法满足需求, 合理的方式是, </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;select</span><br><span class="line">    -&gt; count(release_year='2006' OR NULL) AS '2006年电影数量',</span><br><span class="line">    -&gt; count(release_year='2007' OR NULL) AS '2007年电影数量'</span><br><span class="line">    -&gt; from film \G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">2006年电影数量: 1000</span><br><span class="line">2007年电影数量: 0</span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br></pre></td></tr></table></figure><p>问题一: count()函数参数里面是用星号(*)号好还是用列名好? </p><p>说明 count()函数参数用星号和列名分别查询的结果 有时候是不一样的, 需要注意,</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;create table tbtest(id int, name char(20));</span><br><span class="line">Query OK, 0 rows affected (0.09 sec)</span><br><span class="line"></span><br><span class="line">dev@sakila&gt;insert tbtest values(1, 'Tom'), (2,NULL);</span><br><span class="line">Query OK, 2 rows affected (0.08 sec)</span><br><span class="line">Records: 2  Duplicates: 0  Warnings: 0</span><br><span class="line"></span><br><span class="line">dev@sakila&gt;select count(*), count(id), count(name) from tbtest;</span><br><span class="line">+<span class="comment">----------+-----------+-------------+</span></span><br><span class="line">| count(*) | count(id) | count(name) |</span><br><span class="line">+<span class="comment">----------+-----------+-------------+</span></span><br><span class="line">|        2 |         2 |           1 |</span><br><span class="line">+<span class="comment">----------+-----------+-------------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><p>上述示例说明count(*)是指存在的具体数据行数, 而count(列名)是指这列值不为NULL的行数; </p><p>同时要注意 count(release_year=’2007’ OR NULL) 后面的<code>OR NULL</code> 这个表示当前面的查询不存在时返回NULL,<br>如果直接写成count(relase_year=’2007’) 那当不存在’2007’的条件值时 返回的结果是count(*)的值;</p><p>下面通过示例进一步分析, </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;create table tb19(name char(20), age tinyint unsigned);</span><br><span class="line">Query OK, 0 rows affected (0.07 sec)</span><br><span class="line"></span><br><span class="line">dev@sakila&gt;insert tb19 values('Tom',19), ('Mike',20),</span><br><span class="line">    -&gt; ('jack',NULL), ('jason',19), ('oliva',19), ('reminer',20);</span><br><span class="line">Query OK, 5 rows affected (0.07 sec)</span><br><span class="line">Records: 5  Duplicates: 0  Warnings: 0</span><br><span class="line"></span><br><span class="line">dev@sakila&gt;select</span><br><span class="line">    -&gt; count(*),</span><br><span class="line">    -&gt; count(age=19),</span><br><span class="line">    -&gt; count(age=19 OR NULL),</span><br><span class="line">    -&gt; count(age=21),</span><br><span class="line">    -&gt; count(age=21 OR NULL),</span><br><span class="line">    -&gt; count(name),</span><br><span class="line">    -&gt; count(age)</span><br><span class="line">    -&gt; from tb19 \G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">             count(*): 6</span><br><span class="line">        count(age=19): 5</span><br><span class="line">count(age=19 OR NULL): 3</span><br><span class="line">        count(age=21): 5</span><br><span class="line">count(age=21 OR NULL): 0</span><br><span class="line">          count(name): 6</span><br><span class="line">           count(age): 5</span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><ul><li>count(*) 返回数据表中当前的数据行数;</li><li>count(age =19) 相当于count(age), 即不管count(age= N) 都相当于count(age)的返回值,count(age)计算这列不为NULL的记录之和; </li><li>count(age =19 OR NULL) 表示只有age=19条件时才参与结果统计, age=NULL或其它值均不参与结果统计;</li><li>count(age=21)  与count(age) 值相同;</li><li>count(列名) 即统计该列值不为NULL的记录总数;</li></ul><h2 id="子查询优化"><a href="#子查询优化" class="headerlink" title="子查询优化"></a>子查询优化</h2><p>通常情况下, 需要把子查询优化为join查询, 但是在优化时要注意关联键是否有一对多的关系, 需要注意重复数据;</p><h3 id="1对多关系带来的重复数据问题"><a href="#1对多关系带来的重复数据问题" class="headerlink" title="1对多关系带来的重复数据问题"></a>1对多关系带来的重复数据问题</h3><p>关于数据重复问题示例, </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;create table t(id int);</span><br><span class="line">Query OK, 0 rows affected (0.07 sec)</span><br><span class="line"></span><br><span class="line">dev@sakila&gt;create table t1(tid int);</span><br><span class="line">Query OK, 0 rows affected (0.07 sec)</span><br><span class="line"></span><br><span class="line">dev@sakila&gt;insert t values(1);</span><br><span class="line">Query OK, 1 row affected (0.04 sec)</span><br><span class="line"></span><br><span class="line">dev@sakila&gt;insert t1 values(1), (1);</span><br><span class="line">Query OK, 2 row affected (0.07 sec)</span><br></pre></td></tr></table></figure><p>查询t表id, 要求t表id是t1表中的tid的值范围;</p><p>子查询</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;select * from t where t.id in (select t1.tid from t1);</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| id   |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">|    1 |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><p>修改为连接查询, </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;select t.id id from t inner join t1 on t.id = t1.tid;</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| id   |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">|    1 |</span><br><span class="line">|    1 |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">2 rows in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><p>因为t.id 与t1.tid存在1对多的关系, 所以用连接查询出现了重复数据问题, 那此时就需要通过distinct来处理重复问题;</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;select distinct t.id id from t inner join t1 on t.id = t1.tid;</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">| id   |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">|    1 |</span><br><span class="line">+<span class="comment">------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><h3 id="实例分析"><a href="#实例分析" class="headerlink" title="实例分析"></a>实例分析</h3><p>问题: 查询sandra出演的所有影片</p><p>子查询,</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;select title, release_year, length</span><br><span class="line">    -&gt; from film</span><br><span class="line">    -&gt; where film_id in (</span><br><span class="line">    -&gt; select film_id from film_actor where actor_id in (</span><br><span class="line">    -&gt; select actor_id from actor where first_name = 'sandra'));</span><br></pre></td></tr></table></figure><p>修改为连接查询,</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;explain select title, release_year, length</span><br><span class="line">    -&gt; from film</span><br><span class="line">    -&gt; join film_actor fa on film.film_id = fa.film_id</span><br><span class="line">    -&gt; join actor a on fa.actor_id = a.actor_id where a.first_name = 'sandra';</span><br></pre></td></tr></table></figure><p>子查询与连接查询执行计划对比,</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;explain select title, release_year, length</span><br><span class="line">    -&gt; from film</span><br><span class="line">    -&gt; where film_id in (</span><br><span class="line">    -&gt; select film_id from film_actor where actor_id in (</span><br><span class="line">    -&gt; select actor_id from actor where first_name = 'sandra'));</span><br><span class="line">+<span class="comment">----+--------------+-------------+------------+--------+------------------------+---------+---------+-----------------------+------+----------+-------------+</span></span><br><span class="line">| id | select_type  | table       | partitions | type   | possible_keys          | key     | key_len | ref                   | rows | filtered | Extra       |</span><br><span class="line">+<span class="comment">----+--------------+-------------+------------+--------+------------------------+---------+---------+-----------------------+------+----------+-------------+</span></span><br><span class="line">|  1 | SIMPLE       | &lt;subquery2&gt; | NULL       | ALL    | NULL                   | NULL    | NULL    | NULL                  | NULL |   100.00 | NULL        |</span><br><span class="line">|  1 | SIMPLE       | film        | NULL       | eq_ref | PRIMARY                | PRIMARY | 2       | &lt;subquery2&gt;.film_id   |    1 |   100.00 | NULL        |</span><br><span class="line">|  2 | MATERIALIZED | actor       | NULL       | ALL    | PRIMARY                | NULL    | NULL    | NULL                  |  200 |    10.00 | Using where |</span><br><span class="line">|  2 | MATERIALIZED | film_actor  | NULL       | ref    | PRIMARY,idx_fk_film_id | PRIMARY | 2       | sakila.actor.actor_id |   27 |   100.00 | Using index |</span><br><span class="line">+<span class="comment">----+--------------+-------------+------------+--------+------------------------+---------+---------+-----------------------+------+----------+-------------+</span></span><br><span class="line">4 rows in <span class="keyword">set</span>, <span class="number">1</span> <span class="keyword">warning</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">dev@sakila&gt;<span class="keyword">explain</span> <span class="keyword">select</span> title, release_year, <span class="keyword">length</span></span><br><span class="line">    -&gt; <span class="keyword">from</span> film</span><br><span class="line">    -&gt; <span class="keyword">join</span> film_actor fa <span class="keyword">on</span> film.film_id = fa.film_id</span><br><span class="line">    -&gt; <span class="keyword">join</span> actor a <span class="keyword">on</span> fa.actor_id = a.actor_id <span class="keyword">where</span> a.first_name = <span class="string">'sandra'</span>;</span><br><span class="line">+<span class="comment">----+-------------+-------+------------+--------+------------------------+---------+---------+-------------------+------+----------+-------------+</span></span><br><span class="line">| id | select_type | table | partitions | type   | possible_keys          | key     | key_len | ref               | rows | filtered | Extra       |</span><br><span class="line">+<span class="comment">----+-------------+-------+------------+--------+------------------------+---------+---------+-------------------+------+----------+-------------+</span></span><br><span class="line">|  1 | SIMPLE      | a     | NULL       | ALL    | PRIMARY                | NULL    | NULL    | NULL              |  200 |    10.00 | Using where |</span><br><span class="line">|  1 | SIMPLE      | fa    | NULL       | ref    | PRIMARY,idx_fk_film_id | PRIMARY | 2       | sakila.a.actor_id |   27 |   100.00 | Using index |</span><br><span class="line">|  1 | SIMPLE      | film  | NULL       | eq_ref | PRIMARY                | PRIMARY | 2       | sakila.fa.film_id |    1 |   100.00 | NULL        |</span><br><span class="line">+<span class="comment">----+-------------+-------+------------+--------+------------------------+---------+---------+-------------------+------+----------+-------------+</span></span><br><span class="line">3 rows in <span class="keyword">set</span>, <span class="number">1</span> <span class="keyword">warning</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><ul><li>同对比中可以优化后的连接查询比子查询要少进行一次子查询引发的全表扫描查询操作, 如果数据量很大的时候, 优化效果将灰常明显;</li></ul><h2 id="group-by优化"><a href="#group-by优化" class="headerlink" title="group by优化"></a>group by优化</h2><p>对关联中的某一列进行group by 时, 尽量选用来自同一张表的列进行group by 操作;</p><p>问题: 查询每个演员所参演的影片的数量</p><p>查询语句, </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> actor.first_name, actor.last_name, <span class="keyword">count</span>(*) <span class="keyword">from</span> sakila.film_actor </span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span> sakila.actor <span class="keyword">using</span>(actor_id) <span class="keyword">group</span> <span class="keyword">by</span> film_actor.actor_id;</span><br></pre></td></tr></table></figure><p>执行计划,</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;explain select actor.first_name, actor.last_name, count(*)</span><br><span class="line">    -&gt; from film_actor</span><br><span class="line">    -&gt; join actor using(actor_id)</span><br><span class="line">    -&gt; group by film_actor.actor_id;</span><br><span class="line">+<span class="comment">----+-------------+------------+------------+------+------------------------+---------+---------+-----------------------+------+----------+-----------------+</span></span><br><span class="line">| id | select_type | table      | partitions | type | possible_keys          | key     | key_len | ref                   | rows | filtered | Extra           |</span><br><span class="line">+<span class="comment">----+-------------+------------+------------+------+------------------------+---------+---------+-----------------------+------+----------+-----------------+</span></span><br><span class="line">|  1 | SIMPLE      | actor      | NULL       | ALL  | PRIMARY                | NULL    | NULL    | NULL                  |  200 |   100.00 | Using temporary |</span><br><span class="line">|  1 | SIMPLE      | film_actor | NULL       | ref  | PRIMARY,idx_fk_film_id | PRIMARY | 2       | sakila.actor.actor_id |   27 |   100.00 | Using index     |</span><br><span class="line">+<span class="comment">----+-------------+------------+------------+------+------------------------+---------+---------+-----------------------+------+----------+-----------------+</span></span><br><span class="line">2 rows in <span class="keyword">set</span>, <span class="number">1</span> <span class="keyword">warning</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><p>可以看到执行计划中将用到临时表来支持查询操作, 那么最好对这个查询语句进行改写, 尽量避免使用临时表来进行操作, </p><p>改写后的查询语句,</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> actor.first_name, actor.last_name, c.cnt</span><br><span class="line"><span class="keyword">from</span> actor </span><br><span class="line"><span class="keyword">join</span> (<span class="keyword">select</span> actor_id, <span class="keyword">count</span>(*) <span class="keyword">as</span> cnt <span class="keyword">from</span> film_actor <span class="keyword">group</span> <span class="keyword">by</span> actor_id) <span class="keyword">as</span> c <span class="keyword">using</span>(actor_id);</span><br></pre></td></tr></table></figure><ul><li>using(id) 等价于 on actor.actor_id = c.actor_id的意思;</li></ul><p>对比执行计划</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;explain select actor.first_name, actor.last_name, c.cnt</span><br><span class="line">    -&gt; from actor</span><br><span class="line">    -&gt; inner join (</span><br><span class="line">    -&gt; select actor_id, count(*) as cnt from film_actor group by actor_id</span><br><span class="line">    -&gt; ) as c using(actor_id);</span><br><span class="line">+<span class="comment">----+-------------+------------+------------+-------+------------------------+-------------+---------+-----------------------+------+----------+-------------+</span></span><br><span class="line">| id | select_type | table      | partitions | type  | possible_keys          | key         | key_len | ref                   | rows | filtered | Extra       |</span><br><span class="line">+<span class="comment">----+-------------+------------+------------+-------+------------------------+-------------+---------+-----------------------+------+----------+-------------+</span></span><br><span class="line">|  1 | PRIMARY     | actor      | NULL       | ALL   | PRIMARY                | NULL        | NULL    | NULL                  |  200 |   100.00 | NULL        |</span><br><span class="line">|  1 | PRIMARY     | &lt;derived2&gt; | NULL       | ref   | &lt;auto_key0&gt;            | &lt;auto_key0&gt; | 2       | sakila.actor.actor_id |   27 |   100.00 | NULL        |</span><br><span class="line">|  2 | DERIVED     | film_actor | NULL       | index | PRIMARY,idx_fk_film_id | PRIMARY     | 4       | NULL                  | 5462 |   100.00 | Using index |</span><br><span class="line">+<span class="comment">----+-------------+------------+------------+-------+------------------------+-------------+---------+-----------------------+------+----------+-------------+</span></span><br><span class="line">3 rows in <span class="keyword">set</span>, <span class="number">1</span> <span class="keyword">warning</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><ul><li>可见优化后 就不需要使用临时表来辅助查询操作了; </li><li>在上述语句中是先通过子查询查询到演员及其参演电影数量然后通过连接查询连接演员的基本信息, 这就是说 子查询可以通过修改为连接查询来进一步优化, 那有时候有可能在连接查询中应用子查询来提高查询效率, 具体优化时应根据实际情况进行灵活应用;</li></ul><h2 id="limit查询优化"><a href="#limit查询优化" class="headerlink" title="limit查询优化"></a>limit查询优化</h2><p>limit常用于分页处理, 时常会伴随order by 从句使用, 因此大多时候会使用filesorts, 这样会造成大量IO问题;</p><p>问题: 获取影片信息,</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> film_id, description <span class="keyword">from</span> film <span class="keyword">order</span> <span class="keyword">by</span> title <span class="keyword">limit</span> <span class="number">50</span>, <span class="number">5</span>;</span><br></pre></td></tr></table></figure><p>优化1,</p><p>使用有索引的列或主键进行Order by 操作;</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;explain select film_id, description from film order by title limit 50, 5 \G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">           id: 1</span><br><span class="line">  select_type: SIMPLE</span><br><span class="line">        table: film</span><br><span class="line">   partitions: NULL</span><br><span class="line">         type: ALL</span><br><span class="line">possible_keys: NULL</span><br><span class="line">          key: NULL</span><br><span class="line">      key_len: NULL</span><br><span class="line">          ref: NULL</span><br><span class="line">         rows: 1000</span><br><span class="line">     filtered: 100.00</span><br><span class="line">        Extra: Using filesort</span><br><span class="line">1 row in <span class="keyword">set</span>, <span class="number">1</span> <span class="keyword">warning</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">dev@sakila&gt;<span class="keyword">explain</span> <span class="keyword">select</span> film_id, description <span class="keyword">from</span> film <span class="keyword">order</span> <span class="keyword">by</span> film_id <span class="keyword">limit</span> <span class="number">50</span>, <span class="number">5</span> \G</span><br><span class="line">*************************** <span class="number">1.</span> <span class="keyword">row</span> ***************************</span><br><span class="line">           <span class="keyword">id</span>: <span class="number">1</span></span><br><span class="line">  select_type: SIMPLE</span><br><span class="line">        <span class="keyword">table</span>: film</span><br><span class="line">   <span class="keyword">partitions</span>: <span class="literal">NULL</span></span><br><span class="line">         <span class="keyword">type</span>: <span class="keyword">index</span></span><br><span class="line">possible_keys: <span class="literal">NULL</span></span><br><span class="line">          <span class="keyword">key</span>: PRIMARY</span><br><span class="line">      key_len: <span class="number">2</span></span><br><span class="line">          <span class="keyword">ref</span>: <span class="literal">NULL</span></span><br><span class="line">         <span class="keyword">rows</span>: <span class="number">55</span></span><br><span class="line">     filtered: <span class="number">100.00</span></span><br><span class="line">        Extra: <span class="literal">NULL</span></span><br><span class="line"><span class="number">1</span> <span class="keyword">row</span> <span class="keyword">in</span> <span class="keyword">set</span>, <span class="number">1</span> <span class="keyword">warning</span> (<span class="number">0.00</span> sec)</span><br><span class="line"><span class="keyword">select</span> film_id, description <span class="keyword">from</span> film <span class="keyword">order</span> <span class="keyword">by</span> film_id <span class="keyword">limit</span> <span class="number">50</span>, <span class="number">5</span>;</span><br></pre></td></tr></table></figure><ul><li>优化前需要用到filesort排序, 将order by 字段修改为索引的列或主键后, 就不需要额外的filesort排序, 从而可以减少很多IO操作;</li></ul><p>上述优化存在一个问题， 当表中数据量很大时, 要扫描的行数也随之增大, 那就需要进一步优化,</p><p>优化2,</p><p>记录上次返回的主键, 在下次查询时使用主键过滤, 从而可以避免数据量大时扫描过多的记录;</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">dev@sakila&gt;explain select film_id, description from film where film_id &gt; 55 and film_id &lt;= 60 order by film_id limit 1, 5 \G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">           id: 1</span><br><span class="line">  select_type: SIMPLE</span><br><span class="line">        table: film</span><br><span class="line">   partitions: NULL</span><br><span class="line">         type: range</span><br><span class="line">possible_keys: PRIMARY</span><br><span class="line">          key: PRIMARY</span><br><span class="line">      key_len: 2</span><br><span class="line">          ref: NULL</span><br><span class="line">         rows: 5</span><br><span class="line">     filtered: 100.00</span><br><span class="line">        Extra: Using where</span><br><span class="line">1 row in <span class="keyword">set</span>, <span class="number">1</span> <span class="keyword">warning</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><p>上述优化后, 可以看到要扫描的行数就是要查询的行数量, 从而可以避免数据量很大时要查询靠后的数据引发扫描多行的问题;</p><p>当然上述优化有一个限制, 就是要求主键是连续的， 如果主键在中间是不连续的那按照上述优化, 有可能where子查询返回的条数不够要查询的条数;</p><p>上述两个优化的思想就是优化过多的扫描带来的IO消耗;</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>简要概述了优化的目的及方向;</li><li>对慢查日志知识进行回顾并通过实例实践深入了解学习慢查日志分析来发现存在效率的SQL;</li><li>对max()函数场景进行优化, 实例分析max()函数场景优化前后的执行计划;</li><li>对count()函数场景进行优化, 并实例分析count()函数优化的执行计划;</li><li>回顾子查询相关知识并实例分析子查询优化过程;</li><li>对group by及limit查询进行实例分析优化过程, 总结出其适用的场景及使用时应注意的限制级问题;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;为应用服务提供稳定的数据CURD服务,同时为了进一步提升CURD性能及潜在的问题, 就需要根据实际业务情况及数据体量进行数据库优化修订工作, 关于数据库优化的操作可以从多个方面来总结归纳, 如对SQL语句的优化, 索引的优化, 表结构的优化, 配置的优化等等; 本文从总结实践经验及归纳回顾知识要点的角度来探讨关于SQL语句优化的相关问题;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="mysql专题" scheme="http://researchlab.github.io/categories/mysql%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="mysql" scheme="http://researchlab.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>mysql专题12 数据库表物理设计系列问题</title>
    <link href="http://researchlab.github.io/2018/10/05/mysql-12-database-physical-design/"/>
    <id>http://researchlab.github.io/2018/10/05/mysql-12-database-physical-design/</id>
    <published>2018-10-05T18:59:22.000Z</published>
    <updated>2018-11-09T01:39:38.570Z</updated>
    
    <content type="html"><![CDATA[<p>数据库需求分析及逻辑设计仅仅是将数据及数据实体之间的关系理清楚了, 最终目的是建立合适的数据库表结构; 在数据库设计环节中的物理设计的重要工作就是建立数据库表结构;<br><a id="more"></a></p><h2 id="物理设计"><a href="#物理设计" class="headerlink" title="物理设计"></a>物理设计</h2><ul><li>选择合适的数据库管理系统(Mysql、Oracle, PgSQL等);</li><li>定义数据库, 表及字段的命名规范;</li><li>根据所选的DBMS系统选择合适的字段类型;</li><li>反范式化设计(实际过程中可能会设计冗余数据来换效率, 即用空间换时间)</li></ul><p>选择合适的数据库也是至关重要的， 一般而言可以从成本, 功能，场景等方面进行考虑</p><ul><li><p>成本<br>商业数据库(Oracle, SQLServer)需要支持商业成本; 而开源数据库(MySQL, PgSQL) 只要符合社区协议则可免费使用;</p></li><li><p>功能<br>如果需要经常进行比较大的事务操作 则使用Oracle更合适, 因为Oracle相比其他数据库,其事务执行开销成本要低;</p></li><li><p>场景<br>互联网项目一般会选择开源数据库(MySQl, PgSQL), 而企业级项目一般倾向于商业数据库(Oracle, SQLServer)</p></li></ul><h2 id="表及字段的命令规则"><a href="#表及字段的命令规则" class="headerlink" title="表及字段的命令规则"></a>表及字段的命令规则</h2><p>所有对象命名应该遵循以下原则:</p><ol><li><p>可读性原则<br>使用大写和小写来格式化的库对象名字以获得良好的可读性;例如使用CustAddress而不是custaddress来提高可读性;</p></li><li><p>表意性原则<br>对象的名字应该能描述它所标识的对象; 例如对于表, 表的名称应该能体现表中存储的数据内容; 对于存储过程, 存储过程名称应该能够体现存储过程的功能;</p></li><li><p>长名原则<br>尽可能少使用或者不使用缩写; 因为缩写有可能存在歧义;</p></li></ol><h2 id="字段类型选择原则"><a href="#字段类型选择原则" class="headerlink" title="字段类型选择原则"></a>字段类型选择原则</h2><p>列的数据类型一方面影响数据存储空间的开销, 另一方面也会影响数据查询性能; 当一个列可以选择多种数据类型时, 应该优先考虑数字类型, 其次是日期或二进制类型, 最后是字符类型;  对于相同级别的数据类型, 应该优先选择占用空间小的数据类型;</p><p>示例</p><p>birthday 字段可选择如下四种类型,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Int: 257529600 # 时间戳</span><br><span class="line">Datetime: 1978-03-01 #时间类型</span><br><span class="line">varchar(20): '1978-03-01' 变长字符类型</span><br><span class="line">char(10) '1978-03-01' 固定长度字符类型</span><br></pre></td></tr></table></figure></p><p>显然优先选择顺序依次是 时间戳类型 &gt; 时间类型 &gt;  固定字符类型 &gt; 变长字符类型;</p><p>因为birthday 类型长度比较固定, 且char(10) 比varchar(10)占用空间小; </p><table><thead><tr><th style="text-align:left">列类型</th><th style="text-align:left">存储空间(单位:字节)</th></tr></thead><tbody><tr><td style="text-align:left"><code>TINYINT</code></td><td style="text-align:left">1</td></tr><tr><td style="text-align:left"><code>SMALLINT</code></td><td style="text-align:left">2</td></tr><tr><td style="text-align:left"><code>MEDIUMINT</code></td><td style="text-align:left">3</td></tr><tr><td style="text-align:left"><code>INT</code></td><td style="text-align:left">4</td></tr><tr><td style="text-align:left"><code>BIGINT</code></td><td style="text-align:left">8</td></tr><tr><td style="text-align:left"><code>DATE</code></td><td style="text-align:left">3</td></tr><tr><td style="text-align:left"><code>DATETIME</code></td><td style="text-align:left">8</td></tr><tr><td style="text-align:left"><code>TIMESTAMP</code></td><td style="text-align:left">4</td></tr><tr><td style="text-align:left"><code>CHAR(M)</code></td><td style="text-align:left">1&lt;=M&lt;=255</td></tr><tr><td style="text-align:left"><code>VARCHAR(M)</code></td><td style="text-align:left">L+1, (其中 L&lt;=M, 1&lt;=M&lt;=255)</td></tr></tbody></table><p>字段类型选择原则主要考虑了如下两方面, </p><p>在对数据进行比较(查询条件,JOIN条件及排序)操作时,</p><p><strong>同样的数据, 字符处理往往比数字处理慢;</strong> (字符串需要参考字典进行排序)</p><p>在数据库中, 数据处理以页为单位, <strong>列的长度越小, 利于性能提升;</strong> (InnoDB下默认页长度为16k)</p><h2 id="数据库如何具体选择字段类型"><a href="#数据库如何具体选择字段类型" class="headerlink" title="数据库如何具体选择字段类型"></a>数据库如何具体选择字段类型</h2><h3 id="char与varchar的选择"><a href="#char与varchar的选择" class="headerlink" title="char与varchar的选择"></a>char与varchar的选择</h3><p>选择原则,</p><ol><li><p>如果列中要存储的数据长度差不多是一致的, 则应该考虑用char; 否则应该考虑用varchar;</p></li><li><p>如果列中的最大数据长度小于50Byte, 则一般也考虑用char (如果这个列很少用, 则基于节省空间和减少IO的考虑, 还是可以选择用varchar)</p></li><li><p>一般不宜定义大于50Byte的char类型列;</p></li></ol><h3 id="decimal与float的选择"><a href="#decimal与float的选择" class="headerlink" title="decimal与float的选择"></a>decimal与float的选择</h3><p>选择原则,</p><ol><li><p>decimal 用于存储精确数据, 而float 只能用于存储非精确数据; 故精确数据只能选择用decimal类型;</p></li><li><p>由于float的存储空间开销一般比decimal小(精确到7位小数只需要4个字节, 而精确到15位小数需要8个字节) 故非精确数据优先选择float类型;</p></li></ol><h3 id="时间类型"><a href="#时间类型" class="headerlink" title="时间类型"></a>时间类型</h3><p>选择原则, </p><ol><li>使用int类存储时间字段的优缺点,<br>优点: 字段长度比datetime小;<br>缺点: 使用不方便, 要进行函数转换;<br>限制: 只能存储到2038-1-19 11:14.07 即2<sup>32</sup>为2147483648</li></ol><p>2.需要存储的时间粒度<br>年月日 时分秒周</p><h3 id="如何选择主键"><a href="#如何选择主键" class="headerlink" title="如何选择主键"></a>如何选择主键</h3><ol><li><p>区分业务主键和数据库主键<br>业务主键用于标识业务数据, 进行表与表之间的关联;<br>数据库主键为了优化数据存储(InnoDB会生成6个字节的隐含主键)</p></li><li><p>根据数据库的类型, 考虑主键是否要顺序增长<br>有些数据库是按主键的顺序逻辑存储的(如InnoDB);</p></li><li><p>主键的字段类型所占空间要尽可能的小<br>对于使用聚集索引方式存储的表, 每个索引后都会附加主键信息;<br>数据库是按页查询的, 所以一页中存在的数据也多约便于查询;</p></li></ol><h2 id="数据库设计注意事项"><a href="#数据库设计注意事项" class="headerlink" title="数据库设计注意事项"></a>数据库设计注意事项</h2><h3 id="避免使用外键约束"><a href="#避免使用外键约束" class="headerlink" title="避免使用外键约束"></a>避免使用外键约束</h3><ol><li><p>降低数据导入的效率; (高并发时 建议不使用外键约束)</p></li><li><p>增加维护成本;</p></li><li><p>虽然不建议使用外键约束, 但是相关联的列上一定要建立索引;</p></li></ol><h3 id="避免使用触发器"><a href="#避免使用触发器" class="headerlink" title="避免使用触发器"></a>避免使用触发器</h3><ol><li><p>降低数据导入的效率; (有些存储引擎对触发器使用的总数是有限的)</p></li><li><p>可能会出现意想不到的数据异常; (当逻辑变更后, 新逻辑的修订可能会忽略同步更新触发器设定而带来数据异常问题);</p></li><li><p>使业务逻辑变得复杂;</p></li></ol><h3 id="预留字段"><a href="#预留字段" class="headerlink" title="预留字段"></a>预留字段</h3><ol><li><p>无法准确的知道预留字段的类型;</p></li><li><p>无法准确的知道预留字段中所存储的内容;</p></li><li><p>后期维护预留字段所要的成本, 同增加一个字段所需要的成本是相同的; </p></li><li><p><strong>严禁</strong> 使用预留字段; </p></li></ol><h2 id="反范式化表设计"><a href="#反范式化表设计" class="headerlink" title="反范式化表设计"></a>反范式化表设计</h2><h3 id="知识回顾"><a href="#知识回顾" class="headerlink" title="知识回顾"></a>知识回顾</h3><p>反范式化是针对范式化而言, 有时为了性能和读取效率的考虑而适当的对第三范式的要求进行违反, 而充许存在少量的数据冗余, 换句话来说反范式化就是使用空间来换取时间; </p><h3 id="实例说明"><a href="#实例说明" class="headerlink" title="实例说明"></a>实例说明</h3><p>符合范式化设计的表 </p><table><thead><tr><th style="text-align:left">表名</th><th style="text-align:left">表字段</th></tr></thead><tbody><tr><td style="text-align:left">用户表</td><td style="text-align:left">用户ID, 姓名, 电话, 地址, 邮编</td></tr><tr><td style="text-align:left">订单表</td><td style="text-align:left">订单ID, 用户ID, 下单时间, 支付类型, 订单状态</td></tr><tr><td style="text-align:left">订单商品表</td><td style="text-align:left">订单ID, 商品ID, 商品数量, 商品价格</td></tr><tr><td style="text-align:left">商品表</td><td style="text-align:left">商品ID, 名称, 描述, 过期时间</td></tr></tbody></table><p>问题一,</p><p>查询订单信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT b.用户名, b.电话, b.地址, a.订单ID, SUM(c.商品价格*c.商品数量) as 订单价格</span><br><span class="line">FROM `订单表` a</span><br><span class="line">JOIN `用户表` b ON a.用户ID = b.用户ID</span><br><span class="line">JOIN `订单商品表` c ON c.订单ID = b.订单ID</span><br><span class="line">GROUP BY b,用户名, b.电话, b.地址, a.订单ID</span><br></pre></td></tr></table></figure><p>查询订单详情信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT b.用户名, b.电话, b.地址, a.订单ID, SUM(c.商品价格*c.商品数量) as 订单价格, d.名称 as 商品名称, c.商品价格</span><br><span class="line">FROM `订单表` a</span><br><span class="line">JOIN `用户表` b ON a.用户ID = b.用户ID</span><br><span class="line">JOIN `订单商品表` c ON c.订单ID = b.订单ID</span><br><span class="line">JOIN `商品表` d on d.商品ID = c.商品ID</span><br></pre></td></tr></table></figure><p>反范式化的冗余设计</p><table><thead><tr><th style="text-align:left">表名</th><th style="text-align:left">表字段</th><th style="text-align:left">冗余字段</th></tr></thead><tbody><tr><td style="text-align:left">用户表</td><td style="text-align:left">用户ID, 姓名, 电话, 地址, 邮编</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">订单表</td><td style="text-align:left">订单ID, 用户ID, 下单时间, 支付类型, 订单状态</td><td style="text-align:left"><code>订单价格, 姓名, 地址, 电话</code></td></tr><tr><td style="text-align:left">订单商品表</td><td style="text-align:left">订单ID, 商品ID, 商品数量, 商品价格</td><td style="text-align:left"><code>商品名称, 过期时间</code></td></tr><tr><td style="text-align:left">商品表</td><td style="text-align:left">商品ID, 名称, 描述, 过期时间</td></tr></tbody></table><p>查询订单信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT a.姓名, a.电话, a.地址, a.订单ID, a.订单价格</span><br><span class="line">FROM `订单表` a</span><br></pre></td></tr></table></figure><p>查询订单详情信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT b.用户名, b.电话, b.地址, a.订单ID, SUM(c.商品价格*c.商品数量) as 订单价格, c.商品名称, c.商品价格</span><br><span class="line">FROM `订单表` a</span><br><span class="line">JOIN `用户表` b ON a.用户ID = b.用户ID</span><br><span class="line">JOIN `订单商品表` c ON c.订单ID = b.订单ID</span><br></pre></td></tr></table></figure><p>一般情况下 读写比率为3:1, 少量的写冗余可以换取大量的读取效率;</p><p>为什么要进行反范式化设计</p><ol><li><p>减少表的关联数量; (减少表关联数量 意味着减少了数据库对磁盘的IO操作)</p></li><li><p>增加数据的读取效率;</p></li><li><p>反范式化一定要适度;</p></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>物理设计过程中需要注意数据库/表/字段命名规范; 字段类型选择原则等问题;</li><li>如果设计字符长度小于50Byte, 与varchar相比, 建议优先选择char字符类型;</li><li>decimal 用于精确数据场景, 而float用于非精确数据场景, 考虑的点在于非精确float只需要占用4字节, 而精确的decimal字段需要用到8字节;</li><li>时间类型选择, 读占比更多时,且对格式化有要求的 优先建议使用时间类型, 如果仅做判断或对时间格式没有太多要求时 建议使用int存储，但是要注意int只能存储的最大年限时间, 如果对时间有特殊的格式化要求时可以考虑字符串类型, 当格式化长度相对固定,且小于50Byte时, 优先选择char字符类型;</li><li>注意区分数据库主键与业务主键, 数据库主键主要服务与数据库自身检索查询用, 而业务主键主要用于关联业务数据表使用;</li><li>尽量避免使用外键约束, 因为导入外键约束耗时长, 此外会增加维护成本, 虽然不建议使用约束,但相应的列上也应建立合适的索引, 便于快速检索数据;</li><li>避免使用触发器, 一因为一些存储引擎如InnoDB对触发器的使用数量是有限的; 而新需求更新时可能忘记同步更新触发器而导致数据异常问题; 同时过多的使用触发器会使得业务逻辑变得复杂;</li><li>严禁使用预留字段;</li><li>为了性能及读取效率, 在数据库表物理设计时可以适当进行一些反范式化设计, 其本质为增加数据冗余, 通过空间换时间, 因为大多数场景下读占比会较高于写, 所以少量的写冗余能换来较高的读取效率是值得的; </li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;数据库需求分析及逻辑设计仅仅是将数据及数据实体之间的关系理清楚了, 最终目的是建立合适的数据库表结构; 在数据库设计环节中的物理设计的重要工作就是建立数据库表结构;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="mysql专题" scheme="http://researchlab.github.io/categories/mysql%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="mysql" scheme="http://researchlab.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>redis专题08 redis分布式限流之redis-cell</title>
    <link href="http://researchlab.github.io/2018/10/05/redis-08-redis-cell/"/>
    <id>http://researchlab.github.io/2018/10/05/redis-08-redis-cell/</id>
    <published>2018-10-05T17:05:32.000Z</published>
    <updated>2018-11-09T01:39:38.574Z</updated>
    
    <content type="html"><![CDATA[<p><code>redis4.0</code>以后开始支持扩展模块，<code>redis-cell</code>是一个用<code>rust</code>语言编写的基于<code>令牌桶算法</code>的的限流模块，提供原子性的限流功能，并允许突发流量，可以很方便的应用于分布式环境中。<br><a id="more"></a></p><h5 id="令牌桶限流算法原理"><a href="#令牌桶限流算法原理" class="headerlink" title="令牌桶限流算法原理"></a>令牌桶限流算法原理</h5><p>令牌桶算法的原理是定义一个按一定速率产生<code>token</code>的桶，每次去桶中申请<code>token</code>，若桶中没有足够的<code>token</code>则申请失败，否则成功。在请求不多的情况下，桶中的<code>token</code>基本会饱和，此时若流量激增，并不会马上拒绝请求，所以这种算法允许一定的流量激增。</p><p>1.定义一个令牌桶<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">令牌桶其拥有几个关键属性为，</span><br><span class="line">桶容量</span><br><span class="line">令牌产生速率</span><br><span class="line">当前桶中令牌数</span><br><span class="line">最近一次取（生成）令牌时间</span><br></pre></td></tr></table></figure></p><p>2.从桶中申请令牌，这一步中有两个关键动作</p><blockquote><p>根据上一次生成令牌时间到现在的时间，及生成速率计算出当前令牌桶中的令牌数<br>判断令牌桶中是否有足够的令牌，并返回结果</p></blockquote><p>这几个步骤可以采用<code>redis</code>提供的原生命令去实现，但是高并发的时候数据会不一致，所以<code>redis-cell</code>将这个过程原子化，完美解决了分布式环境下数据的一致性问题。</p><p><code>redis-cell</code>模块只提供了一个命令<code>cl.throttle</code></p><p>示例<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt;cl.throttle test 100 500 20 1</span><br></pre></td></tr></table></figure></p><p>参数依次说明</p><ul><li><p><code>test</code> 表示<code>redis key</code></p></li><li><p><code>100</code> 官方叫·max_burst·，其值为令牌桶的容量<code>-1</code>， 首次执行时令牌桶会默认填满</p></li><li><p><code>500</code> 与下一个参数一起，表示在指定时间窗口内允许访问的次数</p></li><li><p><code>20</code> 指定的时间窗口，单位：秒</p></li><li><p><code>1</code>  表示本次要申请的令牌数，不写则默认为<code>1</code></p></li></ul><blockquote><p>以上命令表示从一个初始值为100的令牌桶中取1个令牌，该令牌桶的速率限制为500次/20秒。</p></blockquote><p>结果示例<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; CL.THROTTLE test 100 500 20 1</span><br><span class="line">1) (integer) 0</span><br><span class="line">2) (integer) 101</span><br><span class="line">3) (integer) 98</span><br><span class="line">4) (integer) -1</span><br><span class="line">5) (integer) 0</span><br></pre></td></tr></table></figure></p><ul><li><code>1)</code> 是否成功，0：成功，1：拒绝</li><li><code>2)</code> 令牌桶的容量，大小为初始值+1</li><li><code>3)</code> 当前令牌桶中可用的令牌</li><li><code>4)</code> 若请求被拒绝，这个值表示多久后才令牌桶中会重新添加令牌，单位：秒，可以作为重试时间</li><li><code>5)</code> 表示多久后令牌桶中的令牌会存满</li></ul><blockquote><p>由于<code>redis-Cell</code>是基于Rust语言写的插件，因此在安装插件前要先安装rust, 具体可参看官方README <a href="https://github.com/brandur/redis-cell" target="_blank" rel="noopener">github</a></p></blockquote><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>从限制用户行为频率场景出发，引入<code>redis-cell</code>分布式限流解决方案，阐述了其算法原理及步骤，并给出实例说明;</li><li>频率限制的实现有多种方式，例如<code>Nginx</code>和<code>Haproxy</code>都有限制模块、通过Redis来实现也是常见的方式之一;</li><li>除了引入<code>redis-cell</code>分布式限流模块， 也可以将上述令牌通的实现思路通过<code>Lua</code>脚本实现，然后嵌入到<code>redis</code>中执行， 实际上在<code>redis</code>还不支持<code>redis-cell</code>模块时， 实际使用场景中大多采用<code>redis+lua</code>方式来实现限流策略;</li><li>将<code>redis-cell</code>限流应用于微服务接口访问频次上也灰常方便;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;redis4.0&lt;/code&gt;以后开始支持扩展模块，&lt;code&gt;redis-cell&lt;/code&gt;是一个用&lt;code&gt;rust&lt;/code&gt;语言编写的基于&lt;code&gt;令牌桶算法&lt;/code&gt;的的限流模块，提供原子性的限流功能，并允许突发流量，可以很方便的应用于分布式环境中。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题07 redis应用之限流策略</title>
    <link href="http://researchlab.github.io/2018/10/04/redis-07-limit-rate/"/>
    <id>http://researchlab.github.io/2018/10/04/redis-07-limit-rate/</id>
    <published>2018-10-04T17:01:59.000Z</published>
    <updated>2018-11-09T01:39:38.574Z</updated>
    
    <content type="html"><![CDATA[<p>限流算法在分布式领域是一个经常被提起的话题，当系统的处理能力有限时，如何阻止计划外的请求继续对系统施压，这是一个需要重视的问题。除了控制流量，限流还有一个应用目的是用于控制用户行为，避免垃圾请求。比如在<code>UGC</code>社区, <code>用户的发帖</code>, <code>回复</code>, <code>点赞</code>等行为都要严格受控，一般要严格限定某行为在规定时间内允许的次数，超过了次数那就是非法行为。<br><a id="more"></a></p><h5 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h5><p>系统要限定用户的某个行为在指定的时间里只能允许发生<code>N</code>次，如何使用<code>redis</code>的数据结构来实现这个限流的功能？</p><h5 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h5><p>这个限流需求中存在一个滑动时间窗口，想想<code>zset</code>数据结构的<code>score</code>值，是不是可以通过<code>score</code>来圈出这个时间窗口来。而且我们只需要保留这个时间窗口，窗口之外的数据都可以砍掉。用一个<code>zset</code>结构记录用户的行为历史，每一个行为都会作为<code>zset</code>中的一个<code>key</code>保存下来。同一个用户同一种行为用一个<code>zset</code>记录。为节省内存，我们只需要保留时间窗口内的行为记录，同时如果用户是冷用户，滑动时间窗口内的行为是空记录，那么这个<code>zset</code>就可以从内存中移除，不再占用空间。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ZADD key score member [[score member] [score member] ...]</span><br><span class="line"></span><br><span class="line">key: 'hist:userid:actionkey</span><br><span class="line"></span><br><span class="line">score: 'time.Millisecond'</span><br><span class="line"></span><br><span class="line">member: 'time.Millisecond'</span><br></pre></td></tr></table></figure><blockquote><p>每个用户的每个行为单独作为一个<code>key</code>;<br>指定时间时间内，刚好可以利用<code>zset</code>集合中的<code>rangebyscore</code>命令， 通过把时间设置为<code>score</code>值来动态维持一个有效的指定时间内的时间窗口;<br><code>zset</code>中插入的<code>key</code>值的<code>member</code>如果相同， 则只会更新这个相同<code>member</code>的<code>score</code>值，所以需要保证<code>member</code>在同一个行为多次发生时都不同即可， 所以可以简单设置为时间值，但在实际中应保证每次<code>member</code>是绝对不同的;</p></blockquote><p>golang代码如下<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line"><span class="string">"log"</span></span><br><span class="line"><span class="string">"time"</span></span><br><span class="line"></span><br><span class="line"><span class="string">"github.com/go-redis/redis"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">addr = <span class="string">"127.0.0.1:6378"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"></span><br><span class="line">client := redis.NewClient(&amp;redis.Options&#123;</span><br><span class="line">Addr:     addr,</span><br><span class="line">Password: <span class="string">""</span>, <span class="comment">//no password set</span></span><br><span class="line">DB:       <span class="number">0</span>,  <span class="comment">// use default DB</span></span><br><span class="line">&#125;)</span><br><span class="line"><span class="keyword">defer</span> client.Close()</span><br><span class="line">pong, err := client.Ping().Result()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">panic</span>(err)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> pong == <span class="string">"PONG"</span> &#123;</span><br><span class="line">log.Println(<span class="string">"redis service is ready."</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">1</span>; i &lt;= <span class="number">10</span>; i++ &#123;</span><br><span class="line">fmt.Println(<span class="string">"nums:"</span>, i, <span class="string">" result:"</span>, isActionAllowd(client, <span class="string">"test"</span>, <span class="string">"reply"</span>, <span class="number">60</span>*time.Second, <span class="number">5</span>))</span><br><span class="line">time.Sleep(time.Millisecond) #为了实验效果，这里适当sleep一下，在实际环境中应保证每次member是不同的</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">isActionAllowd</span><span class="params">(client *redis.Client, userID, actionKey <span class="keyword">string</span>, period time.Duration, maxCount <span class="keyword">int64</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">key := fmt.Sprintf(<span class="string">"hist:%s:%s"</span>, userID, actionKey)</span><br><span class="line">mperiod := period.Nanoseconds() / <span class="number">1e6</span>       <span class="comment">//转毫秒</span></span><br><span class="line">now := <span class="keyword">int64</span>(time.Now().Nanosecond() / <span class="number">1e6</span>) <span class="comment">// 毫秒时间戳</span></span><br><span class="line">    <span class="comment">// 注意这里 不能使用 now = time.Now().Seconds()*1000  因为这样精度就丢失了，导致一秒内的所有now值都一样;</span></span><br><span class="line"></span><br><span class="line">pipe := client.Pipeline()</span><br><span class="line">pipe.ZAdd(key, redis.Z&#123;</span><br><span class="line">Score:  <span class="keyword">float64</span>(now),</span><br><span class="line">Member: now,</span><br><span class="line">&#125;) <span class="comment">//记录行为， value 和score 都使用毫秒时间戳;</span></span><br><span class="line"><span class="comment">//移除时间窗口之前的行为记录, 剩下的都是时间窗口内的</span></span><br><span class="line">pipe.ZRemRangeByScore(key, <span class="string">"0"</span>, fmt.Sprintf(<span class="string">"%v"</span>, now-mperiod))</span><br><span class="line"><span class="comment">// 获取窗口内的行为数量</span></span><br><span class="line">pipe.ZCard(key)</span><br><span class="line"><span class="comment">// 设置zset 过期时间, 避免冷用户持续占用内存</span></span><br><span class="line"><span class="comment">// 过期时间应该等于时间窗口的长度, 再多宽限1s</span></span><br><span class="line">pipe.Expire(key, time.Duration(period+<span class="number">1</span>))</span><br><span class="line"><span class="comment">//执行</span></span><br><span class="line">res, err := pipe.Exec()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Println(err)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line">cmd, ok := res[<span class="number">2</span>].(*redis.IntCmd)</span><br><span class="line"><span class="keyword">if</span> ok &#123;</span><br><span class="line"><span class="keyword">return</span> cmd.Val() &lt;= maxCount</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>output<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">2018/10/23 11:50:01 redis service is ready.</span><br><span class="line">nums: 1  result: true</span><br><span class="line">nums: 2  result: true</span><br><span class="line">nums: 3  result: true</span><br><span class="line">nums: 4  result: true</span><br><span class="line">nums: 5  result: true</span><br><span class="line">nums: 6  result: false</span><br><span class="line">nums: 7  result: false</span><br><span class="line">nums: 8  result: false</span><br><span class="line">nums: 9  result: false</span><br><span class="line">nums: 10  result: false</span><br></pre></td></tr></table></figure></p><blockquote><p>执行结果可知，通过统计滑动窗口内的行为数量与阈值<code>maxCount</code>进行比较就可以得出当前的行为是否允许, 从而起到限流策略;</p></blockquote><blockquote><p>因为这几个连续的 Redis 操作都是针对同一个<code>key</code>的，使用<code>pipeline</code>可以显著提升<code>redis</code>存取效率。</p></blockquote><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>通过限制规定时间内用户行为次数的场景，引入<code>redis</code>在限流策略中的应用，并给出实例分析及代码验证说明;</li><li>但这种方案也有缺点，因为它要记录时间窗口内所有的行为记录，如果这个量很大，比如限定<code>60s</code>内操作不得超过<code>100w</code>次这样的参数，它是不适合做这样的限流的，因为会消耗大量的存储空间。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;限流算法在分布式领域是一个经常被提起的话题，当系统的处理能力有限时，如何阻止计划外的请求继续对系统施压，这是一个需要重视的问题。除了控制流量，限流还有一个应用目的是用于控制用户行为，避免垃圾请求。比如在&lt;code&gt;UGC&lt;/code&gt;社区, &lt;code&gt;用户的发帖&lt;/code&gt;, &lt;code&gt;回复&lt;/code&gt;, &lt;code&gt;点赞&lt;/code&gt;等行为都要严格受控，一般要严格限定某行为在规定时间内允许的次数，超过了次数那就是非法行为。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>mysql专题11 数据库逻辑设计</title>
    <link href="http://researchlab.github.io/2018/10/04/mysql-11-database-logic-design/"/>
    <id>http://researchlab.github.io/2018/10/04/mysql-11-database-logic-design/</id>
    <published>2018-10-04T13:59:42.000Z</published>
    <updated>2018-11-09T01:39:38.570Z</updated>
    
    <content type="html"><![CDATA[<p>设计出符合业务需求的数据存储模型至关重要, 合理的数据库表设计不仅能有效的应对业务数据的存储, 还能高效的对已存储的数据进行访问操作; 本文将以数据库设计范式等知识背景来进一步探讨数据库逻辑设计相关问题;<br><a id="more"></a></p><h2 id="数据库设计"><a href="#数据库设计" class="headerlink" title="数据库设计"></a>数据库设计</h2><p>优良设计的参考基准</p><ul><li>减少数据冗余;</li><li>避免数据维护异常;</li><li>节省存储空间;</li><li>高效的访问;</li></ul><p>数据库设计过程主要经过以下几个阶段, </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">需求分析--&gt; 逻辑设计--&gt; 物理设计--&gt;维护优化</span><br></pre></td></tr></table></figure><h3 id="需求分析阶段"><a href="#需求分析阶段" class="headerlink" title="需求分析阶段"></a>需求分析阶段</h3><p>分析数据库需求的作用点,</p><ul><li>数据是什么;</li><li>数据由哪些属性;</li><li>数据和属性各自的特点;</li><li>了解数据的生命周期;</li><li>非核心数据的归档和清理策略定制;</li><li>了解实体与实体之间的关系(1:1, 1:N, M:N);</li><li>哪些属性或属性的组合可以唯一标识一个实体;</li></ul><h3 id="逻辑设计阶段"><a href="#逻辑设计阶段" class="headerlink" title="逻辑设计阶段"></a>逻辑设计阶段</h3><ul><li>将需求转化为数据库的逻辑模型;</li><li>通过ER图的形式对逻辑模型进行展示;</li><li>逻辑设计与所选用的具体DBMS系统无关;</li></ul><h3 id="物理设计阶段"><a href="#物理设计阶段" class="headerlink" title="物理设计阶段"></a>物理设计阶段</h3><ul><li>根据数据库自身的特点把逻辑设计转换为物理设计; </li></ul><h3 id="维护优化阶段"><a href="#维护优化阶段" class="headerlink" title="维护优化阶段"></a>维护优化阶段</h3><ul><li>新的需求进行建表;</li><li>索引优化;</li><li>大表拆分;</li></ul><h2 id="实例分析"><a href="#实例分析" class="headerlink" title="实例分析"></a>实例分析</h2><blockquote><p>以一个小型电商为例, 电商网站包含如下几个核心模块: 用户模块, 商品模块, 订单模块, 购物车模块, 供用商模块;</p></blockquote><h3 id="用户模块"><a href="#用户模块" class="headerlink" title="用户模块"></a>用户模块</h3><table><thead><tr><th style="text-align:left"></th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:left"><code>功能</code></td><td style="text-align:left">用于记录注册用户信息</td></tr><tr><td style="text-align:left"><code>包括属性</code></td><td style="text-align:left">用户名, 密码, 电话, 邮箱, 身份证号, 地址, 姓名, 昵称 …</td></tr><tr><td style="text-align:left"><code>可选唯一标识属性</code></td><td style="text-align:left">用户名, 身份证, 电话</td></tr><tr><td style="text-align:left"><code>存储特点</code></td><td style="text-align:left">随系统上线时间逐渐增加, 需要永久存储, 考虑分库分表问题</td></tr></tbody></table><h3 id="商品模块"><a href="#商品模块" class="headerlink" title="商品模块"></a>商品模块</h3><table><thead><tr><th style="text-align:left"></th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:left"><code>功能</code></td><td style="text-align:left">用于记录网站中所销售的商品信息</td></tr><tr><td style="text-align:left"><code>包括属性</code></td><td style="text-align:left">商品编码, 商品名称, 商品描述, 商品品类, 供应商名称, 重量, 有效期, 价格 …</td></tr><tr><td style="text-align:left"><code>可选唯一标识属性</code></td><td style="text-align:left">(商品名称, 供应商名称), (商品编码)</td></tr><tr><td style="text-align:left"><code>存储特点</code></td><td style="text-align:left">对于下线商品可以归档存储</td></tr></tbody></table><h3 id="订单模块"><a href="#订单模块" class="headerlink" title="订单模块"></a>订单模块</h3><table><thead><tr><th style="text-align:left"></th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:left"><code>功能</code></td><td style="text-align:left">用于用户订购商品的信息</td></tr><tr><td style="text-align:left"><code>包括属性</code></td><td style="text-align:left">订单号, 用户姓名, 用户电话, 收货地址, 商品编号, 商品名称, 数量, 价格, 订单状态, 支付状态, 订单类型 …</td></tr><tr><td style="text-align:left"><code>可选唯一标识属性</code></td><td style="text-align:left">(订单号)</td></tr><tr><td style="text-align:left"><code>存储特点</code></td><td style="text-align:left">永久存储(分表, 分库存储)</td></tr></tbody></table><h3 id="购物车模块"><a href="#购物车模块" class="headerlink" title="购物车模块"></a>购物车模块</h3><table><thead><tr><th style="text-align:left"></th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:left"><code>功能</code></td><td style="text-align:left">用于保存用户购物时选购的商品</td></tr><tr><td style="text-align:left"><code>包括属性</code></td><td style="text-align:left">用户名, 商品编号, 商品名称, 商品价格, 商品描述, 商品分类, 加入时间, 商品数量 …</td></tr><tr><td style="text-align:left"><code>可选唯一标识属性</code></td><td style="text-align:left">(用户名, 商品编号, 加入时间), (购物车编号)</td></tr><tr><td style="text-align:left"><code>存储特点</code></td><td style="text-align:left">不用永久存储( 设置归档, 清理规则)</td></tr></tbody></table><h3 id="供应商模块"><a href="#供应商模块" class="headerlink" title="供应商模块"></a>供应商模块</h3><table><thead><tr><th style="text-align:left"></th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:left"><code>功能</code></td><td style="text-align:left">用于保存所销售商品的供应商信息</td></tr><tr><td style="text-align:left"><code>包括属性</code></td><td style="text-align:left">供应商编号, 供应商名称, 联系人, 电话, 营业执照号, 地址, 法人 …</td></tr><tr><td style="text-align:left"><code>可选唯一标识属性</code></td><td style="text-align:left">(供应商编号), (营业执照号)</td></tr><tr><td style="text-align:left"><code>存储特点</code></td><td style="text-align:left">永久存储</td></tr></tbody></table><h3 id="模块间关系图"><a href="#模块间关系图" class="headerlink" title="模块间关系图"></a>模块间关系图</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  订单 &lt;---(多对多)---&gt; 商品 &lt; ---(多对多)---&gt; 供应商</span><br><span class="line">   ^                     ^</span><br><span class="line">   |                     |</span><br><span class="line">(1对多)               (多对多)</span><br><span class="line">   |                     |</span><br><span class="line">   v                     v</span><br><span class="line">  用户 &lt;---(1对多)----&gt; 购物车</span><br></pre></td></tr></table></figure><blockquote><p>需求分析需要理清楚实体属性字段及存储特点;<br>需求分析需要理清楚实体间的关系; </p></blockquote><h2 id="逻辑设计ER图"><a href="#逻辑设计ER图" class="headerlink" title="逻辑设计ER图"></a>逻辑设计ER图</h2><h3 id="知识回顾"><a href="#知识回顾" class="headerlink" title="知识回顾"></a>知识回顾</h3><table><thead><tr><th style="text-align:left"></th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:left"><code>关系</code></td><td style="text-align:left">一个关系对应通常所说的一张表</td></tr><tr><td style="text-align:left"><code>元组</code></td><td style="text-align:left">表中的一行即为一个元组</td></tr><tr><td style="text-align:left"><code>属性</code></td><td style="text-align:left">表中的一列即为一个属性; 每个属性都有一个名称, 称为属性名</td></tr><tr><td style="text-align:left"><code>候选码</code></td><td style="text-align:left">表中的某个属性组, 它可以唯一确定一个元组</td></tr><tr><td style="text-align:left"><code>主码</code></td><td style="text-align:left">一个关系有多个候选码, 选定其中一个为主码</td></tr><tr><td style="text-align:left"><code>域</code></td><td style="text-align:left">属性的取值范围</td></tr><tr><td style="text-align:left"><code>分量</code></td><td style="text-align:left">元组中的一个属性值</td></tr></tbody></table><p>ER图例说明</p><table><thead><tr><th style="text-align:left"></th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:left"><code>矩形</code></td><td style="text-align:left">表示实体集, 矩形内写实体集的名字</td></tr><tr><td style="text-align:left"><code>菱形</code></td><td style="text-align:left">表示联系集</td></tr><tr><td style="text-align:left"><code>椭圆</code></td><td style="text-align:left">表示实体的属性</td></tr><tr><td style="text-align:left"><code>线段</code></td><td style="text-align:left">将属性连接到实体集, 或将实体集连接到联系集</td></tr></tbody></table><h3 id="ER图分析"><a href="#ER图分析" class="headerlink" title="ER图分析"></a>ER图分析</h3><p>下面是将前面的电商网站实例分析部分用ER图展示, </p><p><img src="/2018/10/04/mysql-11-database-logic-design/shoping-goods.png" alt=""></p><ul><li>图中仅表示出order(订单), goods(商品), supplier(供应商), user(用户), 购物车(cart) 五个实体, 同时也只大致列出了实体中的一些属性字段值,(因仅做分析学习没有详细列出实体的属性, 实体属性页应根据业务实际情况进行详细分析最终确定, 故而也没有通用的实体属性集);</li><li>图中清晰刻画了实体间的关系</li></ul><table><thead><tr><th style="text-align:left">实体集</th><th style="text-align:left">关系</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left"><code>user与order</code></td><td style="text-align:left"><code>1 对 0...many</code></td><td style="text-align:left">用户可以拥有0个或多个订单, 而一个订单只能且必须属于某一个人</td></tr><tr><td style="text-align:left"><code>user与cart</code></td><td style="text-align:left"><code>1 对 1...many</code></td><td style="text-align:left">用户至少拥有一个购物车, 一个购物车只能属于某一个用户</td></tr><tr><td style="text-align:left"><code>order与goods</code></td><td style="text-align:left"><code>0...many 对 1...many</code></td><td style="text-align:left">一个订单至少有一个商品, 而商品可以不属于也可以属于多个订单</td></tr><tr><td style="text-align:left"><code>goods与cart</code></td><td style="text-align:left"><code>0...many 对 0...many</code></td><td style="text-align:left">一个商品可以属于0个或多个购物车中, 一个购物车也可以放置0个或多个商品</td></tr><tr><td style="text-align:left"><code>goods与supplier</code></td><td style="text-align:left"><code>1...many 对1...many</code></td><td style="text-align:left">一个商品至少有一个供用商, 而供应商至少应提供一个商品(否则的话就不能算供应商了)</td></tr></tbody></table><h2 id="逻辑设计规范"><a href="#逻辑设计规范" class="headerlink" title="逻辑设计规范"></a>逻辑设计规范</h2><p>通过上述ER图分析, 可以帮助用户理清各个实体的属性数据和其特征及实体之间的关系, 那如何将这些实体属性设计成数据表呢? 是通过一张表表示还是要通过多张表来设计? 哪些应该设计在一张表中, 哪些实体属性字段又应该设计在分开的数据表中呢?  为尽量合理设置数据表, 就需要进一步了解数据库表的设计规范, </p><p>数据库设计范式的主要作用是是的符合设计范式的数据库表在存储操作过程可以做到简洁高效,减少冗余数据, 同时最大限度的避免一些插入更新删除的异常情况发生; </p><p>常见的数据库设计范式, </p><ul><li>第一范式</li><li>第二范式</li><li>第三范式</li><li>第四范式(不常见)</li><li>第五范式(不常见)</li><li>BC范式</li></ul><p>数据操作异常 </p><table><thead><tr><th style="text-align:left"></th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:left"><code>插入异常</code></td><td style="text-align:left">如果某实体A随着另一个实体B的存在而存在, 即缺少某个实体B时无法表示这个实体A, 那么这个表就存在插入异常</td></tr><tr><td style="text-align:left"><code>更新异常</code></td><td style="text-align:left">如果更改表所对应的某个实体实例的单独属性时, 需要将多行更新, 那么就说这个表存在更新异常</td></tr><tr><td style="text-align:left"><code>删除异常</code></td><td style="text-align:left">如果删除表的某一行来反映某实体实例, 失效时导致另一个不同实体实例信息丢失, 那么这个表中就存在删除异常</td></tr></tbody></table><p>数据冗余是指相同的数据在多个地方存在, 或者说表中的某个列可以由其它列计算得到, 这样就说表中存在着数据冗余;</p><h2 id="第一范式-1NF"><a href="#第一范式-1NF" class="headerlink" title="第一范式(1NF)"></a>第一范式(1NF)</h2><h3 id="知识回顾-1"><a href="#知识回顾-1" class="headerlink" title="知识回顾"></a>知识回顾</h3><p><strong>第一范式: 数据库表中的所有字段都是单一属性, 不可再分的;</strong></p><p>单一属性是由基本的数据类型所构成的, 如整数, 浮点数, 字符串等;</p><p>也就是说 第一范式 要求数据库中的表都是二维表( 即由行和列组成的表)</p><h3 id="实例分析-1"><a href="#实例分析-1" class="headerlink" title="实例分析"></a>实例分析</h3><p>下面两张表都符合第一范式,</p><p>表一</p><table><thead><tr><th style="text-align:left">用户ID</th><th style="text-align:left">用户名</th><th style="text-align:left">密码</th><th style="text-align:left">姓名</th><th style="text-align:left">电话</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left">zhang3</td><td style="text-align:left">***</td><td style="text-align:left">张三</td><td style="text-align:left">010100200</td></tr></tbody></table><p>表二</p><table><thead><tr><th style="text-align:left">用户ID</th><th style="text-align:left">用户名</th><th style="text-align:left">密码</th><th style="text-align:left">用户信息</th></tr></thead><tbody><tr><td style="text-align:left"></td><td style="text-align:left"></td><td style="text-align:left"></td><td style="text-align:left"><strong>姓名</strong></td><td style="text-align:left"><strong>电话</strong></td></tr><tr><td style="text-align:left">1</td><td style="text-align:left">zhang3</td><td style="text-align:left">***</td><td style="text-align:left">张三</td><td style="text-align:left">010100200</td></tr></tbody></table><p>在现在大多数数据库中设计的表都是符合第一范式要求的， 但是都不会去设计出上述第二张表那样的结构;</p><h2 id="第二范式-2NF"><a href="#第二范式-2NF" class="headerlink" title="第二范式(2NF)"></a>第二范式(2NF)</h2><h3 id="知识回顾-2"><a href="#知识回顾-2" class="headerlink" title="知识回顾"></a>知识回顾</h3><p><strong>第二范式: 数据库的表中不存在非关键字段对任一候选关键字段的部分函数依赖;</strong></p><p>部分函数依赖是指存在着组合关键字中的某一关键字决定非关键字的情况</p><p>换句话说: 所有单关键字段的表都符合第二范式 </p><h3 id="实例分析-2"><a href="#实例分析-2" class="headerlink" title="实例分析"></a>实例分析</h3><p>表</p><table><thead><tr><th style="text-align:left">商品名称</th><th style="text-align:left">供应商名称</th><th style="text-align:left">价格</th><th style="text-align:left">描述</th><th style="text-align:left">重量</th><th style="text-align:left">供应商电话</th><th style="text-align:left">有效期</th><th style="text-align:left">分类</th></tr></thead><tbody><tr><td style="text-align:left">可乐</td><td style="text-align:left">饮料一厂</td><td style="text-align:left">2.00</td><td style="text-align:left"></td><td style="text-align:left">250ml</td><td style="text-align:left">88888</td><td style="text-align:left">2018.1</td><td style="text-align:left">饮料</td></tr><tr><td style="text-align:left">可乐</td><td style="text-align:left">饮料二厂</td><td style="text-align:left">2.00</td><td style="text-align:left"></td><td style="text-align:left">250ml</td><td style="text-align:left">66666</td><td style="text-align:left">2018.1</td><td style="text-align:left">饮料</td></tr></tbody></table><p>显然商品和供应商之间是多对多的关系; </p><p>所以上表中只有使用商品名称+供应商名称才可以唯一标识出一件商品;</p><p>也就是说商品名称和供应商名称是一组组合关键字, 所以上表中字段如下, </p><table><thead><tr><th style="text-align:left">组合关键字</th><th style="text-align:left">候选关键字段</th><th style="text-align:left">非关键字段</th></tr></thead><tbody><tr><td style="text-align:left">商品名称+供应商名称</td><td style="text-align:left">商品名称</td><td style="text-align:left">价格</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">供应商名称</td><td style="text-align:left">描述</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"></td><td style="text-align:left">重量</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"></td><td style="text-align:left">供应商电话</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"></td><td style="text-align:left">有效期</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"></td><td style="text-align:left">分类</td></tr></tbody></table><p>上表中存在如下的部分函数依赖关系,</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">如通过商品名称找到其价格,描述,重量等信息;</span><br><span class="line">(商品名称) --&gt; (价格, 描述, 重量, 商品有效期)</span><br><span class="line"></span><br><span class="line">通过供应商名称找到其联系信息等;</span><br><span class="line">(供应商名称) --&gt; (供应商电话)</span><br></pre></td></tr></table></figure><p>即上表中存在 非关键字段对候选关键字的部分函数依赖关系, 所以不符合第二范式要求的, 那这种不符合第二范式要求的表可能会存在哪些问题呢? </p><ol><li><p>插入异常<br>如果饮料一厂没有提供饮料, 则在上表中就找不到饮料一厂的相关信息, 只有插入了饮料一厂提供的饮料才能找到饮料一厂的相关信息, 这种就称之为插入异常;</p></li><li><p>删除异常<br>如果把上表中所有饮料一厂提供的饮料信息删除, 那在上表中就找不到饮料一厂的相关信息了;</p></li><li><p>更新异常<br>假如饮料一厂提供了很多种饮料如可乐, 雪碧等, 此时要更新饮料一厂的供用商电话, 那所有饮料一厂的数据行都要更新; 一般只要存在插入异常或删除异常就存在更新异常;</p></li><li><p>数据冗余<br>上表中可以看到供应商信息会随着饮料品种的增多而大量冗余;</p></li></ol><p>可以通过将上表进行信息拆分来来解决上述问题, </p><p>可以将商品信息及供应商信息拆分成两张表, 此外为建立商品与供应商关系 还应在新建一张关系表, </p><p>goods </p><table><thead><tr><th style="text-align:left">商品ID</th><th style="text-align:left">商品名称</th><th style="text-align:left">价格</th><th style="text-align:left">描述</th><th style="text-align:left">重量</th><th style="text-align:left">有效期</th><th style="text-align:left">分类</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left">可乐</td><td style="text-align:left">2.00</td><td style="text-align:left"></td><td style="text-align:left">250ml</td><td style="text-align:left">2018.1</td><td style="text-align:left">饮料</td></tr></tbody></table><p>supplier</p><table><thead><tr><th style="text-align:left">供应商ID</th><th style="text-align:left">供应商名称</th><th style="text-align:left">供应商电话</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left">饮料一厂</td><td style="text-align:left">88888</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left">饮料二厂</td><td style="text-align:left">66666</td></tr></tbody></table><p>r_supplier_goods</p><table><thead><tr><th style="text-align:left">供应商ID</th><th style="text-align:left">商品ID</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left">1</td></tr></tbody></table><p>拆分成三张表后, 每张表都是单关键字表了，符合第二范式要求;</p><h2 id="第三范式-3NF"><a href="#第三范式-3NF" class="headerlink" title="第三范式(3NF)"></a>第三范式(3NF)</h2><h3 id="知识回顾-3"><a href="#知识回顾-3" class="headerlink" title="知识回顾"></a>知识回顾</h3><p><strong>第三范式: 在第二范式的基础之上定义的, 如果数据表中不存在非关键字对任意候选关键字段的传递函数依赖则符合第三范式;</strong></p><h3 id="实例分析-3"><a href="#实例分析-3" class="headerlink" title="实例分析"></a>实例分析</h3><p>表</p><table><thead><tr><th style="text-align:left">商品名称</th><th style="text-align:left">价格</th><th style="text-align:left">商品描述</th><th style="text-align:left">重量</th><th style="text-align:left">有效期</th><th style="text-align:left">分类</th><th style="text-align:left">分类描述</th></tr></thead><tbody><tr><td style="text-align:left">可乐</td><td style="text-align:left">3.00</td><td style="text-align:left"></td><td style="text-align:left">250ml</td><td style="text-align:left">2020.10</td><td style="text-align:left">酒水饮料</td><td style="text-align:left">碳酸饮料</td></tr><tr><td style="text-align:left">苹果</td><td style="text-align:left">8.00</td><td style="text-align:left"></td><td style="text-align:left">500g</td><td style="text-align:left"></td><td style="text-align:left">生鲜食品</td><td style="text-align:left">水果</td></tr></tbody></table><p>存在以下传递函数依赖关系,</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(商品名称)--&gt;(分类)--&gt;(分类描述)</span><br></pre></td></tr></table></figure><p>也就是说存在非关键字段”分类描述”对关键字段”商品名称”的传递函数依赖;</p><p>所以上述表不符合第三范式要求, 那么不存在第三范式要求的表可能会存在什么问题呢? </p><p>显然, (分类,分类描述) 对于每一个商品都会进行记录, 所以存在着数据冗余, 同时也还存在数据的插入, 更新及删除异常;</p><p>可以通过对信息拆分成多张表来解决上述问题;</p><p>goods </p><table><thead><tr><th style="text-align:left">商品名称</th><th style="text-align:left">价格</th><th style="text-align:left">商品描述</th><th style="text-align:left">重量</th><th style="text-align:left">有效期</th></tr></thead><tbody><tr><td style="text-align:left">可乐</td><td style="text-align:left">3.00</td><td style="text-align:left"></td><td style="text-align:left">250ml</td><td style="text-align:left">2020.10</td></tr><tr><td style="text-align:left">苹果</td><td style="text-align:left">8.00</td><td style="text-align:left"></td><td style="text-align:left">500g</td></tr></tbody></table><p>category </p><table><thead><tr><th style="text-align:left">分类</th><th style="text-align:left">分类描述</th></tr></thead><tbody><tr><td style="text-align:left">酒水饮料</td><td style="text-align:left">碳酸饮料</td></tr><tr><td style="text-align:left">生鲜食品</td><td style="text-align:left">水果</td></tr></tbody></table><p>r_goods_category</p><table><thead><tr><th style="text-align:left">分类ID</th><th style="text-align:left">商品ID</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left">1</td></tr></tbody></table><p>拆分后三张表就不存在传递函数依赖了， 符合第三范式要求;</p><h2 id="BC范式-BCNF"><a href="#BC范式-BCNF" class="headerlink" title="BC范式(BCNF)"></a>BC范式(BCNF)</h2><h3 id="知识回顾-4"><a href="#知识回顾-4" class="headerlink" title="知识回顾"></a>知识回顾</h3><p><strong>BC范式: 在第三范式的基础之上, 数据库表中如果不存在任何字段对任一候选键字段的传递函数依赖则符合BC范式;</strong></p><p>也就是说如果是复合关键字, 则复合关键字之间也不能存在函数依赖关系;</p><h3 id="实例分析-4"><a href="#实例分析-4" class="headerlink" title="实例分析"></a>实例分析</h3><p>表</p><table><thead><tr><th style="text-align:left">供应商</th><th style="text-align:left">商品ID</th><th style="text-align:left">供应商联系人</th><th style="text-align:left">商品数量</th></tr></thead><tbody><tr><td style="text-align:left">饮料一厂</td><td style="text-align:left">1</td><td style="text-align:left">张三</td><td style="text-align:left">10</td></tr><tr><td style="text-align:left">饮料一厂</td><td style="text-align:left">2</td><td style="text-align:left">李四</td><td style="text-align:left">20</td></tr><tr><td style="text-align:left">饮料二厂</td><td style="text-align:left">1</td><td style="text-align:left">王五</td><td style="text-align:left">10</td></tr></tbody></table><p>假设: 供应商联系人只能受雇于一家供应商,每家供应商可以供应多个商品, 则存在如下决定关系, </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(供应商, 商品ID) --&gt; (联系人, 商品数量)</span><br><span class="line"></span><br><span class="line">(联系人, 商品ID) --&gt; (供应商, 商品数量)</span><br></pre></td></tr></table></figure><p>存在下列关系因此不符合BCNF要求, </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(供应商） --&gt; (供应商联系人)</span><br><span class="line">(供应商联系人) --&gt; (供应商)</span><br></pre></td></tr></table></figure><p>并且存在数据操作异常及数据冗余</p><p>如果饮料二厂还没有提供任何饮料，则此时就看不到饮料二厂的相关信息;  (插入异常)<br>删除饮料二厂提供的所有商品, 饮料二厂信息丢失 (删除异常)<br>更新饮料二厂信息, 所有饮料二厂饮料信息需要更新 (更新异常)<br>饮料二厂提供多种饮料 饮料二厂信息数据冗余 </p><p>通过拆分成两张表来解决上述问题, </p><p>goods_supplier</p><table><thead><tr><th style="text-align:left">供应商</th><th style="text-align:left">商品ID</th><th style="text-align:left">商品数量</th></tr></thead><tbody><tr><td style="text-align:left">饮料一厂</td><td style="text-align:left">1</td><td style="text-align:left">10</td></tr><tr><td style="text-align:left">饮料一厂</td><td style="text-align:left">2</td><td style="text-align:left">20</td></tr><tr><td style="text-align:left">饮料二厂</td><td style="text-align:left">1</td><td style="text-align:left">30</td></tr></tbody></table><p>supplier</p><table><thead><tr><th style="text-align:left">供应商</th><th style="text-align:left">供应商联系人</th></tr></thead><tbody><tr><td style="text-align:left">饮料一厂</td><td style="text-align:left">张三</td></tr><tr><td style="text-align:left">饮料一厂</td><td style="text-align:left">李四</td></tr><tr><td style="text-align:left">饮料二厂</td><td style="text-align:left">王五</td></tr></tbody></table><p>可以看到拆分后的两张表就满足了BC范式的要求了;</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>数据库表设计大致经历需求分析,逻辑ER图设计, 物理设计, 维护优化等几个阶段;</li><li>通过一个电商网站实例分析了数据库需求分析过程;</li><li>回顾了ER图知识, 实例分析ER图回顾逻辑设计阶段的相关知识点;</li><li>逻辑设计有第一二三四五范式及BC范式;</li><li>回顾第一二三及BC范式相关知识,通过实例分析;</li><li>第一范式要求数据库表设计符合二维表;</li><li>第二范式要求数据库表中不存在非关键字的对任一候选关键字段的部分函数依赖;</li><li>第三范式要求在第二范式基础上不存在非关键字段对任一候选关键字的传递函数依赖;</li><li>BC范式则要求在第三范式基础上不存在任一字段对任一候选关键字段的传递函数依赖;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;设计出符合业务需求的数据存储模型至关重要, 合理的数据库表设计不仅能有效的应对业务数据的存储, 还能高效的对已存储的数据进行访问操作; 本文将以数据库设计范式等知识背景来进一步探讨数据库逻辑设计相关问题;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="mysql专题" scheme="http://researchlab.github.io/categories/mysql%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="mysql" scheme="http://researchlab.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>redis专题06 布隆过滤器</title>
    <link href="http://researchlab.github.io/2018/10/03/redis-06-bloom-filter/"/>
    <id>http://researchlab.github.io/2018/10/03/redis-06-bloom-filter/</id>
    <published>2018-10-03T16:57:48.000Z</published>
    <updated>2018-11-09T01:39:38.574Z</updated>
    
    <content type="html"><![CDATA[<p>灰常方便用<code>redis</code>的<code>HyperLogLog</code>来<strong>进行数值估数</strong>, <u><strong>可以解决很多精确度不高的统计需求。</strong></u></p><p>但是如果想知道某一个值是不是已经在<code>HyperLogLog</code>结构里面了，它就无能为力了，它只提供了<code>pfadd</code>, <code>pfcount</code>和<code>pfmerge</code>等方法，没有提供<code>pfcontains</code>这样类似的方法。<br><a id="more"></a></p><p>讲个使用场景，比如我们在使用新闻客户端看新闻时，它会给我们不停地推荐新的内容，它每次推荐时要去重，去掉那些已经看过的内容。问题来了，新闻客户端推荐系统如何实现推送去重的？</p><p>你会想到服务器记录了用户看过的所有历史记录，当推荐系统推荐新闻时会从每个用户的历史记录里进行筛选，过滤掉那些已经存在的记录。问题是当用户量很大，每个用户看过的新闻又很多的情况下，这种方式，推荐系统的去重工作在性能上跟的上么？</p><p>实际上，如果历史记录存储在关系数据库里，去重就需要频繁地对数据库进行<code>exists</code>查询，当系统并发量很高时，数据库是很难扛住压力的。</p><p>你可能又想到了缓存，但是如此多的历史记录全部缓存起来，那得浪费多大存储空间啊？而且这个存储空间是随着时间线性增长，你撑得住一个月，你能撑得住几年么？但是不缓存的话，性能又跟不上，这该怎么办？</p><p>这时，<font color="red"><strong><code>布隆过滤器(Bloom Filter)</code>闪亮登场了，它就是专门用来解决这种去重问题的。它在起到去重的同时，在空间上还能节省 90%`以上，只是稍微有那么点不精确，也就是有一定的误判概率。</strong></font></p><blockquote><p>数据量小时， 可以用<code>redis</code>提供的集合<code>set</code>去重;</p></blockquote><blockquote><p>当数据量很大，且没有很严格的精度要求时， 就可以用<code>redis</code>提供的布隆过滤器来去重，而且还能极大的节省空间, 所以在存储空间上相比<code>set</code>集合优势十分明显;</p></blockquote><h5 id="布隆过滤器是什么"><a href="#布隆过滤器是什么" class="headerlink" title="布隆过滤器是什么?"></a>布隆过滤器是什么?</h5><p>布隆过滤器可以理解为一个不怎么精确的<code>set</code>结构，当你使用它的<code>contains</code>方法判断某个对象是否存在时，它可能会误判。但是布隆过滤器也不是特别不精确，只要参数设置的合理，它的精确度可以控制的相对足够精确，只会有小小的误判概率。</p><blockquote><p>当布隆过滤器说某个值存在时，这个值可能不存在；<br>当它说不存在时，那就肯定不存在。打个比方，当它说不认识你时，肯定就不认识；当它说见过你时，可能根本就没见过面，不过因为你的脸跟它认识的人中某脸比较相似 (某些熟脸的系数组合)，所以误判以前见过你。</p></blockquote><p>套在上面的使用场景中，布隆过滤器能准确过滤掉那些已经看过的内容，那些没有看过的新内容，它也会过滤掉极小一部分 (误判)，但是绝大多数新内容它都能准确识别。这样就可以完全保证推荐给用户的内容都是无重复的。</p><h5 id="redis中布隆过滤器基本使用"><a href="#redis中布隆过滤器基本使用" class="headerlink" title="redis中布隆过滤器基本使用"></a>redis中布隆过滤器基本使用</h5><h6 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h6><p><code>redis</code>官方提供的布隆过滤器到了<code>redis4.0</code>提供了插件功能之后才正式登场。布隆过滤器作为一个插件加载到<code>Redis Server</code>中，给<code>Redis</code>提供了强大的布隆去重功能。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">➜  02 docker exec -it myredis redis-cli --version</span><br><span class="line">redis-cli 4.0.11</span><br><span class="line">➜  02 docker pull redislabs/rebloom</span><br><span class="line">➜  02 docker run -itd --name redisbloom -p6378:6379 redislabs/rebloom</span><br><span class="line">➜  02 docker exec -it redisbloom redis-cli</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p><p>布隆过滤器有二个基本指令，<code>bf.add</code>添加元素，<code>bf.exists</code>查询元素是否存在，它的用法和<code>set</code>集合的<code>sadd</code>和 <code>sismember</code>差不多。注意<code>bf.add</code>只能一次添加一个元素，如果想要一次添加多个，就需要用到<code>bf.madd</code>指令。同样如果需要一次查询多个元素是否存在，就需要用到<code>bf.mexists</code>指令。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; bf.add visitor user1</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加的元素如果原来不存在 则返回1， 否则返回0</span></span><br><span class="line">127.0.0.1:6379&gt; bf.add visitor user1</span><br><span class="line">(integer) 0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> bf.madd 返回值为数组</span></span><br><span class="line">127.0.0.1:6379&gt; bf.madd visitor user2 user3</span><br><span class="line">1) (integer) 1</span><br><span class="line">2) (integer) 1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> bf.exists 如果存在返回1， 否则返回0;</span></span><br><span class="line">127.0.0.1:6379&gt; bf.exists visitor user1</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">bf.mexists 返回一个数组， 1表示存在， 0表示不存在;</span></span><br><span class="line">127.0.0.1:6379&gt; bf.mexists visitor user1 user2 user3</span><br><span class="line">1) (integer) 1</span><br><span class="line">2) (integer) 1</span><br><span class="line">3) (integer) 1</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p><p><code>布隆过滤器</code>判断元素是否存在时，存在一定的误差， 可以通过调节<code>布隆过滤器</code>参数来降低误差值， 在没有设置误差参数值时，<code>redis</code>会启用布隆过滤器的默认参数，它在第一次<code>add</code>的时候自动创建。用户可以在<code>add</code>之前使用<code>bf.reserve</code>指令显式自定义布隆过滤器参数值。如果对应的<code>key</code>已经存在，<code>bf.reserve</code>会报错。<code>bf.reserve</code>有三个参数，分别是<code>key</code>, <code>error_rate</code>和<code>initial_size</code>。错误率越低，需要的空间越大。<code>initial_size</code>参数表示预计放入的元素数量，当实际数量超出这个数值时，误判率会上升。所以需要提前设置一个较大的数值避免超出导致误判率升高。</p><blockquote><p>默认的<code>error_rate</code>是<code>0.01</code>，默认的<code>initial_size</code>是<code>100</code>。</p></blockquote><blockquote><p>布隆过滤器的<code>initial_size</code>估计的过大，会浪费存储空间，估计的过小，就会影响准确率，用户在使用之前一定要尽可能地精确估计好元素数量，还需要加上一定的冗余空间以避免实际元素可能会意外高出估计值很多。</p></blockquote><blockquote><p>布隆过滤器的<code>error_rate</code>越小，需要的存储空间就越大，对于不需要过于精确的场合，<code>error_rate</code>设置稍大一点也无伤大雅。比如在新闻去重上而言，误判率高一点只会让小部分文章不能让合适的人看到，文章的整体阅读量不会因为这点误判率就带来巨大的改变。</p></blockquote><h5 id="布隆过滤器实现原理"><a href="#布隆过滤器实现原理" class="headerlink" title="布隆过滤器实现原理"></a>布隆过滤器实现原理</h5><p>每个<code>布隆过滤器</code>对应到<code>redis</code>的数据结构里面就是一个大型的<code>位数组</code>和几个不一样的<code>无偏hash函数</code>。</p><blockquote><p><code>无偏</code>就是能够把元素的<code>hash</code>值算得比较均匀。</p></blockquote><p>向<code>布隆过滤器</code>中添加<code>key</code>时，会使用多个<code>hash</code>函数对<code>key</code>进行<code>hash</code>算得一个<code>整数索引值</code>然后对位数组长度进行取模运算得到一个位置，每个<code>hash</code>函数都会算得一个不同的位置。再把位数组的这几个位置都置为<code>1</code>就完成了<code>add</code>操作。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">       key1     key2</span><br><span class="line">       /  |    /  \</span><br><span class="line">      /   |   /    \</span><br><span class="line">     /    |  /      \</span><br><span class="line">0 0 1 0 0 1  1 0 0 0 1 0 0 0</span><br></pre></td></tr></table></figure><p>向<code>布隆过滤器</code>询问<code>key</code>是否存在时，跟<code>add</code>一样，也会把<code>hash</code>的几个位置都算出来，看看位数组中这几个位置是否都为<code>1</code>，只要有一个位为<code>0</code>，那么说明布隆过滤器中这个<code>key</code>不存在。如果都是<code>1</code>，这并不能说明这个<code>key</code>就一定存在，只是极有可能存在，因为这些位被置为<code>1</code>可能是因为其它的<code>key</code>存在所致。如果这个位数组比较稀疏，判断正确的概率就会很大，如果这个位数组比较拥挤，判断正确的概率就会降低。</p><p>使用时不要让实际元素远大于初始化大小，当实际元素开始超出初始化大小时，应该对<code>布隆过滤器</code>进行重建，重新分配一个<code>size</code>更大的过滤器，再将所有的历史元素批量<code>add</code>进去 (这就要求我们在其它的存储器中记录所有的历史元素)。因为<code>error_rate</code>不会因为数量超出就急剧增加，这就给我们重建过滤器提供了较为宽松的时间。</p><h5 id="占用空间估计"><a href="#占用空间估计" class="headerlink" title="占用空间估计"></a>占用空间估计</h5><p><code>布隆过滤器</code>有两个参数，第一个是预计元素的数量<code>n</code>，第二个是错误率<code>f</code>。公式根据这两个输入得到两个输出，第一个输出是<code>位数组</code>的长度<code>l</code>，也就是需要的存储空间大小<code>(bit)</code>，第二个输出是<code>hash</code>函数的最佳数量<code>k</code>。<code>hash</code>函数的数量也会直接影响到错误率，最佳的数量会有最低的错误率。<code>布隆过滤器</code>的空间占用有一个简单的计算公式，<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">k=0.7*(l/n)  # 约等于</span><br><span class="line">f=0.6185^(l/n)  # ^ 表示次方计算，也就是 math.pow</span><br></pre></td></tr></table></figure></p><p>从公式中可以看出</p><p>位数组相对越长<code>(l/n)</code>，错误率<code>f</code>越低，这个和直观上理解是一致的<br>位数组相对越长<code>(l/n)</code>，hash<code>函数需要的最佳数量也越多，影响计算效率当一个元素平均需要</code>1<code>个字节</code>(8bit)<code>的指纹空间时</code>(l/n=8)<code>，错误率大约为</code>2%`</p><blockquote><p>错误率为<code>10%</code>，一个元素需要的平均指纹空间为<code>4.792</code>个<code>bit</code>，大约为<code>5bit</code><br>错误率为<code>1%</code>，一个元素需要的平均指纹空间为<code>9.585</code>个<code>bit</code>，大约为<code>10bit</code><br>错误率为<code>0.1%</code>，一个元素需要的平均指纹空间为<code>14.377</code>个 bit，大约为<code>15bit</code></p></blockquote><p>你也许会想，如果一个元素需要占据<code>15</code>个<code>bit</code>，那相对<code>set</code>集合的空间优势是不是就没有那么明显了？</p><blockquote><p><u><strong>这里需要明确的是，<code>set</code>中会存储每个元素的内容，而<code>布隆过滤器</code>仅仅存储元素的指纹。元素的内容大小就是字符串的长度，它一般会有多个字节，甚至是几十个上百个字节，每个元素本身还需要一个指针被<code>set</code>集合来引用，这个指针又会占去<code>4</code>个字节或<code>8</code>个字节，取决于系统是 32bit 还是 64bit。而指纹空间只有接近<code>2</code>个字节，所以布隆过滤器的空间优势还是非常明显的。</strong></u></p></blockquote><p>当实际元素超出预计元素时，错误率会有多大变化，它会急剧上升么，还是平缓地上升，这就需要另外一个公式，引入参数<code>t</code>表示实际元素和预计元素的倍数<code>t</code><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f=(1-0.5^t)^k  # 极限近似，k 是 hash 函数的最佳数量</span><br></pre></td></tr></table></figure></p><p>当<code>t</code>增大时，错误率，<code>f</code>也会跟着增大，分别选择错误率为<code>10%,1%,0.1%</code>的<code>k</code>值，实验得知</p><blockquote><p>错误率为<code>10%</code>时，倍数比为<code>2</code>时，错误率就会升至接近<code>40%</code>，这个就比较危险了<br>错误率为<code>1%</code>时，倍数比为<code>2</code>时，错误率升至<code>15%</code>，也挺可怕的<br>错误率为<code>0.1%</code>，倍数比为<code>2</code>时，错误率升至<code>5%</code>，也比较悬了</p></blockquote><h5 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h5><blockquote><p>在爬虫系统中，我们需要对<code>URL</code>进行去重，已经爬过的网页就可以不用爬了。但是<code>URL</code>太多了，几千万几个亿，如果用一个集合装下这些<code>URL</code>地址那是非常浪费空间的。这时候就可以考虑使用布隆过滤器。它可以大幅降低去重存储消耗，只不过也会使得爬虫系统错过少量的页面。</p></blockquote><blockquote><p>布隆过滤器在<code>NoSQL</code>数据库领域使用非常广泛，我们平时用到的<code>HBase</code>、<code>Cassandra</code>还有<code>LevelDB</code>、<code>RocksDB</code>内部都有布隆过滤器结构，布隆过滤器可以显著降低数据库的<code>IO</code>请求数量。当用户来查询某个<code>row</code>时，可以先通过内存中的布隆过滤器过滤掉大量不存在的<code>row</code>请求，然后再去磁盘进行查询。</p></blockquote><blockquote><p>邮箱系统的垃圾邮件过滤功能也普遍用到了布隆过滤器，因为用了这个过滤器，所以平时也会遇到某些正常的邮件被放进了垃圾邮件目录中，这个就是误判所致，概率很低。</p></blockquote><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li><code>布隆过滤</code>（Bloom Filter）是由布隆（Burton Howard Bloom）在1970年提出的。<u>它实际上是由一个很长的二进制向量和一系列随机映射函数组成，布隆过滤器可以用于检索一个元素是否在一个集合中</u>。本文引入了其基本原理，并给出实例分析;</li><li>它的优点是<code>空间效率和查询时间</code>都远远超过一般的算法，布隆过滤器存储空间和插入/查询时间都是常数。另外, Hash 函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势。</li><li><p>缺点是有一定的误识别率（假正例False positives，即Bloom Filter报告某一元素存在于某集合中，但是实际上该元素并不在集合中）和删除困难，但是没有识别错误的情形（即假反例False negatives，如果某个元素确实没有在该集合中，那么Bloom Filter 是不会报告该元素存在于集合中的，所以不会漏报）。</p></li><li><p>目前我们知道布隆过滤器可以支持<code>add</code>和<code>isExist</code>操作，那么<code>delete</code>操作可以么，很难实现， 如位数组中的<code>bit</code>位 被两个值共同覆盖的话，一旦你删除其中一个值而将其置位<code>0</code>，那么下次判断另一个值是否存在的话，会直接返回<code>false</code>，而实际上你并没有删除它。如何解决这个问题，答案是<code>计数删除</code>。但是计数删除需要存储一个数值，而不是原先的<code>bit</code>位，会增大占用的内存大小。这样的话，增加一个值就是将对应索引槽上存储的值加一，删除则是减一，判断是否存在则是看值是否大于0。</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;灰常方便用&lt;code&gt;redis&lt;/code&gt;的&lt;code&gt;HyperLogLog&lt;/code&gt;来&lt;strong&gt;进行数值估数&lt;/strong&gt;, &lt;u&gt;&lt;strong&gt;可以解决很多精确度不高的统计需求。&lt;/strong&gt;&lt;/u&gt;&lt;/p&gt;
&lt;p&gt;但是如果想知道某一个值是不是已经在&lt;code&gt;HyperLogLog&lt;/code&gt;结构里面了，它就无能为力了，它只提供了&lt;code&gt;pfadd&lt;/code&gt;, &lt;code&gt;pfcount&lt;/code&gt;和&lt;code&gt;pfmerge&lt;/code&gt;等方法，没有提供&lt;code&gt;pfcontains&lt;/code&gt;这样类似的方法。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>mysql专题10 存储过程及存储引擎</title>
    <link href="http://researchlab.github.io/2018/10/03/mysql-10-storage-procedure-and-engine-summary/"/>
    <id>http://researchlab.github.io/2018/10/03/mysql-10-storage-procedure-and-engine-summary/</id>
    <published>2018-10-03T08:52:02.000Z</published>
    <updated>2018-11-09T01:39:38.570Z</updated>
    
    <content type="html"><![CDATA[<p><code>MySQL 5.0</code>开始支持存储过程，这样大大提高数据库的处理速度，同时也可以提高数据库编程的灵活性。SQL语句需要先编译然后执行，而存储过程（Stored Procedure）是一组为了完成特定功能的SQL语句集，经编译后存储在数据库中，用户通过指定存储过程的名字并给定参数（如果该存储过程带有参数）来调用执行它。<br><a id="more"></a></p><p>为何要使用存储过程? </p><p>经常需要对数据进行SQL CURD操作, 那么一条SQL语句从输入MySQL执行开始到得到结果为止需要经历哪些过程呢?</p><p>一条SQL语句在Mysql中执行经过,</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SQL命令--&gt; MySQL引擎--(分析)--&gt;如果语法、词法正确--(翻译)--&gt; 可识别命令--(执行)--&gt;执行结果--(返回)--&gt; 客户端</span><br></pre></td></tr></table></figure><p>存储过程是SQL语句和控制语句的预编译集合, 以一个名词存储并作为一个单元处理; 存储过程只在第一次执行时需要进行语法分析和编译处理, 之后再次执行存储过程就直接执行, 而不再需要进行语法分析及编译等过程, 从而可以提高Mysql的执行效率; </p><h1 id="存储过程概念"><a href="#存储过程概念" class="headerlink" title="存储过程概念"></a>存储过程概念</h1><p>存储过程是可编程的函数，在数据库中创建并保存，可以由SQL语句和控制结构组成。当想要在不同的应用程序或平台上执行相同的函数，或者封装特定功能时，存储过程是非常有用的。数据库中的存储过程可以看做是对编程中面向对象方法的模拟，它允许控制数据的访问方式。</p><p>存储过程的优点:</p><ul><li><p>增强SQL语言的功能和灵活性: 存储过程可以用控制语句编写，有很强的灵活性，可以完成复杂的判断和较复杂的运算。</p></li><li><p>标准组件式编程: 存储过程被创建后，可以在程序中被多次调用，而不必重新编写该存储过程的SQL语句。而且数据库专业人员可以随时对存储过程进行修改，对应用程序源代码毫无影响。</p></li><li><p>较快的执行速度: 如果某一操作包含大量的Transaction-SQL代码或分别被多次执行，那么存储过程要比批处理的执行速度快很多。因为存储过程是预编译的。在首次运行一个存储过程时查询，优化器对其进行分析优化，并且给出最终被存储在系统表中的执行计划。而批处理的Transaction-SQL语句在每次运行时都要进行编译和优化，速度相对要慢一些。</p></li><li><p>减少网络流量: 针对同一个数据库对象的操作（如查询、修改），如果这一操作所涉及的Transaction-SQL语句被组织进存储过程，那么当在客户计算机上调用该存储过程时，网络中传送的只是该调用语句，从而大大减少网络流量并降低了网络负载。</p></li><li><p>作为一种安全机制来充分利用: 通过对执行某一存储过程的权限进行限制，能够实现对相应的数据的访问权限的限制，避免了非授权用户对数据的访问，保证了数据的安全。</p></li></ul><h1 id="存储过程语法结构"><a href="#存储过程语法结构" class="headerlink" title="存储过程语法结构"></a>存储过程语法结构</h1><p>Mysql存储过程语法结构解析 </p><p>创建存储过程语法结构</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">CREATE </span><br><span class="line">[DEFINER = &#123;user |CURRENT_USER&#125;]</span><br><span class="line">PROCEDURE sp_name ([proc_parameter[,...]])</span><br><span class="line">[characteristic ...] routine_body</span><br><span class="line"></span><br><span class="line">proc_parameter:</span><br><span class="line">[IN | OUT | INOUT ] param_name type </span><br><span class="line"></span><br><span class="line">COMMENT 'string'</span><br><span class="line"></span><br><span class="line">| &#123;CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA &#125;</span><br><span class="line">| SQL SECURITY &#123;DEFINER | INVOKER&#125;</span><br></pre></td></tr></table></figure><ul><li>DEFINER 指创建者的名字, 默认是当前登录用户; </li><li>sp_name 即存储过程名称; </li><li>IN 表示该参数的值必须在调用存储过程时指定;</li><li>OUT 表示该参数的值可以被存储过程改变, 并且可以返回;</li><li>INOUT 表示该参数的调用时指定, 并且可以被改变和返回;</li><li>COMMENT 注释</li><li>CONTAINS SQL: 包含SQL语句, 但不包含读或写数据的语句;</li><li>NO SQL: 不包含SQL语句;</li><li>READS SQL DATA: 包含读数据的语句;</li><li>MODIFIES SQL DATA: 包含写数据的语句;</li><li>SQL SECURITY { DEFINER }INVOKER} 指明谁有权限来执行;</li></ul><p>存储过程过程体规则</p><ul><li>过程体由合法的SQL语句构成;</li><li>过程体可以是任意SQL语句;</li><li>过程体如果为复合结构则使用BEGIN…END语句;</li><li>复合结构可以包含声明, 循环,控制结构;</li></ul><blockquote><p>存储过程主要用于数据的CURD包含多表连接等操作;<br>不要通过存储过程去创建数据库/表等操作;</p></blockquote><p>调用存储过程</p><ul><li>CALL sp_name ([(parameter[,…]])</li><li>CALL sp_name[()]</li></ul><h1 id="无参数存储过程"><a href="#无参数存储过程" class="headerlink" title="无参数存储过程"></a>无参数存储过程</h1><p>创建不带参数存储过程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">dev@testdb&gt;CREATE PROC SELECT VERSION();</span></span><br><span class="line">Query OK, 0 rows affected (0.10 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">CALL sp1;</span></span><br><span class="line">+-----------+</span><br><span class="line">| VERSION() |</span><br><span class="line">+-----------+</span><br><span class="line">| 8.0.12    |</span><br><span class="line">+-----------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">CALL sp1();</span></span><br><span class="line">+-----------+</span><br><span class="line">| VERSION() |</span><br><span class="line">+-----------+</span><br><span class="line">| 8.0.12    |</span><br><span class="line">+-----------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure><h1 id="有参数存储过程"><a href="#有参数存储过程" class="headerlink" title="有参数存储过程"></a>有参数存储过程</h1><p>创建带有IN类型参数的存储过程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">CREATE PROCEDURE removeGoodsByID(IN id SMALLINT UNSIGNED)</span></span><br><span class="line">    -&gt; BEGIN</span><br><span class="line">    -&gt; DELETE FROM tdb_goods WHERE goods_id = id;</span><br><span class="line">    -&gt; END</span><br><span class="line">    -&gt; //</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">DELIMITER ;</span></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">CALL removeGoodsByID(5);</span></span><br><span class="line">Query OK, 1 row affected (0.02 sec)</span><br></pre></td></tr></table></figure><blockquote><p>注意 存储过程入参的参数名字不能与 待删除表的待判定的字段名称一样, 否则将执行全部删除, </p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">DELIMITER //</span></span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">CREATE PROCEDURE remGoodsByID(IN goods_id SMALLINT UNSIGNED)</span></span><br><span class="line">    -&gt; BEGIN</span><br><span class="line">    -&gt; DELETE FROM tb13 WHERE goods_id = goods_id;</span><br><span class="line">    -&gt; END</span><br><span class="line">    -&gt; //</span><br><span class="line">Query OK, 0 rows affected (0.07 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">DELIMITER ;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">select * from tb13;</span></span><br><span class="line">+----------+---------------------------------+---------+------------+-------------+---------+------------+</span><br><span class="line">| goods_id | goods_name                      | cate_id | brand_name | goods_price | is_show | is_saleoff |</span><br><span class="line">+----------+---------------------------------+---------+------------+-------------+---------+------------+</span><br><span class="line">|        1 | R510VC 15.6英寸笔记本           |       1 | 华硕       |    3399.000 |       1 |          0 |</span><br><span class="line">|        2 | Y400N 14.0英寸笔记本电脑        |       1 | 联想       |    4899.000 |       1 |          0 |</span><br><span class="line">|        3 | Macbook pro 15.0英寸笔记本      |       5 | Apple      |  120000.000 |       1 |          0 |</span><br><span class="line">|        4 | R510VC 15.6英寸笔记本           |       1 | 华硕       |    3399.000 |       1 |          0 |</span><br><span class="line">|        5 | Y400N 12.0英寸笔记本电脑        |       1 | 联想       |    2899.000 |       1 |          0 |</span><br><span class="line">|        6 | Macbook pro 15.0英寸笔记本      |       5 | Apple      |  120000.000 |       1 |          0 |</span><br><span class="line">+----------+---------------------------------+---------+------------+-------------+---------+------------+</span><br><span class="line">6 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">CALL remGoodsByID(5);</span></span><br><span class="line">Query OK, 6 rows affected (0.06 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">select * from tb13;</span></span><br><span class="line">Empty set (0.00 sec)</span><br></pre></td></tr></table></figure><h1 id="修改存储过程"><a href="#修改存储过程" class="headerlink" title="修改存储过程"></a>修改存储过程</h1><p>语法结构<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ALTER PROCEDURE sp_name [ characteristic ...]</span><br><span class="line"></span><br><span class="line">COMMENT 'string'</span><br><span class="line"></span><br><span class="line">| &#123; CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA &#125;</span><br><span class="line">| SQL SECURITY &#123; DEFINER | INVOKER &#125;</span><br></pre></td></tr></table></figure></p><ul><li>存储存储过程时 仅能修改注释, 内容的类型等, 并不能修改过程体;</li><li>若要修改过程体，只能先将存储过程删除，然后再重建;</li></ul><h1 id="删除存储过程"><a href="#删除存储过程" class="headerlink" title="删除存储过程"></a>删除存储过程</h1><p>语法结构</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DROP PROCEDURE [ IF EXISTS ] sp_name</span><br></pre></td></tr></table></figure><p>用法举例</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">drop procedure <span class="keyword">if</span> exists sp1;</span></span><br><span class="line">Query OK, 0 rows affected (0.06 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">删除不存在的存储过程仅warning 无error</span></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">DROP PROCEDURE IF EXISTS sp3;</span></span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure><h1 id="创建带IN和OUT类型参数的存储过程"><a href="#创建带IN和OUT类型参数的存储过程" class="headerlink" title="创建带IN和OUT类型参数的存储过程"></a>创建带IN和OUT类型参数的存储过程</h1><p>实例 删除指定的数据行, 返回剩下的数据行数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">DELIMITER //</span></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">CREATE PROCEDURE removeGoodsAndReturnGoodsNums(IN p_goods_id INT UNSIGNED, OUT goodsNums INT UNSIGNED)</span></span><br><span class="line">    -&gt; BEGIN</span><br><span class="line">    -&gt; DELETE FROM tdb_goods WHERE goods_id = p_goods_id;</span><br><span class="line">    -&gt; SELECT count(goods_id) FROM tdb_goods INTO goodsNums;</span><br><span class="line">    -&gt; END</span><br><span class="line">    -&gt; //</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">DELIMITER ;</span></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">SELECT COUNT(goods_id) FROM tdb_goods;</span></span><br><span class="line">+-----------------+</span><br><span class="line">| COUNT(goods_id) |</span><br><span class="line">+-----------------+</span><br><span class="line">|              20 |</span><br><span class="line">+-----------------+</span><br><span class="line">1 row in set (0.01 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">CALL removeGoodsAndReturnGoodsNums(1, @nums);</span></span><br><span class="line">Query OK, 1 row affected (0.03 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">SELECT @nums;</span></span><br><span class="line">+-------+</span><br><span class="line">| @nums |</span><br><span class="line">+-------+</span><br><span class="line">|    19 |</span><br><span class="line">+-------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><ul><li>DECLARE 声明的变量为局部变量, 并且为BEGIN … END 第一行 只在BEGIN…END内有效</li><li>@nums @声明的变量 只在当前客户端有效; 通过SET设置的也是一样， 所以@变量称之为用户变量只在当前客户端有效;</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">SET @i = 7;</span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">SELECT @i;</span></span><br><span class="line">+------+</span><br><span class="line">| @i   |</span><br><span class="line">+------+</span><br><span class="line">|    7 |</span><br><span class="line">+------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><h1 id="带有多个OUT类型参数的存储过程"><a href="#带有多个OUT类型参数的存储过程" class="headerlink" title="带有多个OUT类型参数的存储过程"></a>带有多个OUT类型参数的存储过程</h1><p>返回删除的用户数，返回剩余的用户数</p><p>数据准备</p><blockquote><p> 建表脚本及数据生成可参考<a href="https://github.com/researchlab/docker-envs/tree/master/mysql/sqls" target="_blank" rel="noopener">tb18_ddl.sql tb18_dml.sql</a></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash"><span class="built_in">source</span> /sqls/tb18_ddl.sql;</span></span><br><span class="line">Query OK, 0 rows affected (0.07 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash"><span class="built_in">source</span> /sqls/tb18_dml.sql;</span></span><br><span class="line">...</span><br><span class="line">Query OK, 1 row affected (0.01 sec)</span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">select * from tb18;</span></span><br><span class="line">+----+----------+----------------------------------+------+------+</span><br><span class="line">| id | username | password                         | age  | SEX  |</span><br><span class="line">+----+----------+----------------------------------+------+------+</span><br><span class="line">|  1 | A        | 507f513353702b50c145d5b7d138095c |   20 |    1 |</span><br><span class="line">|  2 | B        | 5ecb75b1-de4c-11e8-9bb8-0242ac15 |   33 |    0 |</span><br><span class="line">|  3 | C        | 5ecbba14-de4c-11e8-9bb8-0242ac15 |   38 |    1 |</span><br><span class="line">|  4 | D        | 5ecc4ee0-de4c-11e8-9bb8-0242ac15 |   64 |    1 |</span><br><span class="line">|  5 | E        | 5ecce3ae-de4c-11e8-9bb8-0242ac15 |   29 |    0 |</span><br><span class="line">|  6 | F        | 5ecd835c-de4c-11e8-9bb8-0242ac15 |   86 |    1 |</span><br><span class="line">|  7 | G        | 5ece181e-de4c-11e8-9bb8-0242ac15 |   51 |    1 |</span><br><span class="line">|  8 | H        | 5ece6966-de4c-11e8-9bb8-0242ac15 |   65 |    1 |</span><br><span class="line">|  9 | I        | 5ecebfba-de4c-11e8-9bb8-0242ac15 |   62 |    0 |</span><br><span class="line">| 10 | J        | 5ecf22af-de4c-11e8-9bb8-0242ac15 |  102 |    0 |</span><br><span class="line">| 11 | K        | 5ecfaab5-de4c-11e8-9bb8-0242ac15 |   59 |    0 |</span><br><span class="line">| 12 | L        | 5ed08bd3-de4c-11e8-9bb8-0242ac15 |   74 |    1 |</span><br><span class="line">| 13 | M        | 5ed12952-de4c-11e8-9bb8-0242ac15 |   27 |    1 |</span><br><span class="line">| 14 | N        | 5ed1c141-de4c-11e8-9bb8-0242ac15 |   92 |    1 |</span><br><span class="line">| 15 | O        | 5ed2b90c-de4c-11e8-9bb8-0242ac15 |   59 |    0 |</span><br><span class="line">| 16 | P        | 5ed3654d-de4c-11e8-9bb8-0242ac15 |   50 |    1 |</span><br><span class="line">| 17 | Q        | 5ed3d018-de4c-11e8-9bb8-0242ac15 |   45 |    0 |</span><br><span class="line">| 18 | R        | 5ed438b6-de4c-11e8-9bb8-0242ac15 |   48 |    0 |</span><br><span class="line">| 19 | S        | 5ed4be04-de4c-11e8-9bb8-0242ac15 |   28 |    1 |</span><br><span class="line">| 20 | T        | 5ed56b4c-de4c-11e8-9bb8-0242ac15 |   94 |    0 |</span><br><span class="line">| 21 | U        | 5ed5ebf7-de4c-11e8-9bb8-0242ac15 |   88 |    0 |</span><br><span class="line">| 22 | V        | 5ed67bd1-de4c-11e8-9bb8-0242ac15 |  105 |    0 |</span><br><span class="line">| 23 | W        | 5ed6c6dc-de4c-11e8-9bb8-0242ac15 |  113 |    1 |</span><br><span class="line">| 24 | X        | 5ed7616b-de4c-11e8-9bb8-0242ac15 |    7 |    1 |</span><br><span class="line">| 25 | Y        | 5ed7ff1b-de4c-11e8-9bb8-0242ac15 |   74 |    0 |</span><br><span class="line">| 26 | Z        | 5ed86256-de4c-11e8-9bb8-0242ac15 |   12 |    1 |</span><br><span class="line">+----+----------+----------------------------------+------+------+</span><br><span class="line">26 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>得到插入或删除更新(CREATE/UPDATE/DELETE) Mysql记录影响的行数<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">SELECT ROW_COUNT();</span></span><br><span class="line">+-------------+</span><br><span class="line">| ROW_COUNT() |</span><br><span class="line">+-------------+</span><br><span class="line">|          -1 |</span><br><span class="line">+-------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><p>创建存储过程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">DELIMITER //</span></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">CREATE PROCEDURE remUserByAgeAndReturnInfos(</span></span><br><span class="line">    -&gt; IN p_age SMALLINT UNSIGNED,</span><br><span class="line">    -&gt; OUT deletedUsers SMALLINT UNSIGNED,</span><br><span class="line">    -&gt; OUT userCounts SMALLINT UNSIGNED)</span><br><span class="line">    -&gt; BEGIN</span><br><span class="line">    -&gt; DELETE FROM tb18 WHERE age = p_age;</span><br><span class="line">    -&gt; SELECT ROW_COUNT() INTO deletedUsers;</span><br><span class="line">    -&gt; SELECT COUNT(id) FROM tb18 INTO userCounts;</span><br><span class="line">    -&gt; END</span><br><span class="line">    -&gt; //</span><br><span class="line">Query OK, 0 rows affected (0.04 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">DELIMITER ;</span></span><br></pre></td></tr></table></figure><p>查询数据状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">select age from tb18 group by age having count(age) &gt; 1;</span></span><br><span class="line">+------+</span><br><span class="line">| age  |</span><br><span class="line">+------+</span><br><span class="line">|    6 |</span><br><span class="line">|  120 |</span><br><span class="line">|   54 |</span><br><span class="line">+------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">select count(*) from tb18;</span></span><br><span class="line">+----------+</span><br><span class="line">| count(*) |</span><br><span class="line">+----------+</span><br><span class="line">|       26 |</span><br><span class="line">+----------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>调用存储过程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">CALL remUserByAgeAndReturnInfos(54, @deletedUsers, @userCounts);</span></span><br><span class="line">Query OK, 1 row affected (0.02 sec)</span><br></pre></td></tr></table></figure><p>查询执行结果</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">SELECT @deletedUsers as deletedUsers;</span></span><br><span class="line">+--------------+</span><br><span class="line">| deletedUsers |</span><br><span class="line">+--------------+</span><br><span class="line">|            2 |</span><br><span class="line">+--------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">SELECT @userCounts;</span></span><br><span class="line">+-------------+</span><br><span class="line">| @userCounts |</span><br><span class="line">+-------------+</span><br><span class="line">|          24 |</span><br><span class="line">+-------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">或者</span></span><br><span class="line"><span class="meta">dev@testdb&gt;</span><span class="bash">SELECT @deletedUsers as deletedUsers, @userCounts;</span></span><br><span class="line">+--------------+-------------+</span><br><span class="line">| deletedUsers | @userCounts |</span><br><span class="line">+--------------+-------------+</span><br><span class="line">|            2 |          24 |</span><br><span class="line">+--------------+-------------+</span><br><span class="line">1 row in set (0.01 sec)</span><br></pre></td></tr></table></figure><ul><li>上述存储过程不是事务数据一致性的, 但存储过程中执行语句错误; 则前面执行过的sql语句依然生效不回滚, 而执行错误的后继sql语句将不再执行;</li></ul><h1 id="存储过程与自定义函数的区别"><a href="#存储过程与自定义函数的区别" class="headerlink" title="存储过程与自定义函数的区别"></a>存储过程与自定义函数的区别</h1><ul><li>存储过程实现的功能要复杂一些; 而函数的针对性更强;</li><li>存储过程可以返回多个值; 函数只能有一个返回值;</li><li>存储过程一般独立的来执行; 而函数可以作为其它SQL语句的组成部分来出现;</li><li>存储过程的修改只能修改注释及内容类型等 不能修改存储体, 要修改存储体只能删除然后重建;</li></ul><h1 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h1><p>Mysql可以将数据以不同的技术存储在文件(内存)中, 这种技术就称为存储引擎;<br>每一种存储引擎使用不同的存储机制, 索引技巧, 锁定水平, 最终提供广泛且不同的功能; </p><p>Mysql目前支持的存储引擎主要有,</p><ul><li>MyISAM</li><li>InnoDB</li><li>Memory </li><li>CSV</li><li>Archive</li></ul><p>并发控制<br>当多个连接同时对记录进行修改时保证数据的一致性和完整性; </p><p>为保证数据的一致性和完整性，目前主要通过锁来处理, 主要有两种锁 </p><ul><li><p>共享锁(读锁)<br>在同一时间段内, 多个用户可以读取同一个资源, 读取过程中数据不会发生变化;</p></li><li><p>排它锁(写锁)<br>在任何时候只能有一个用户写入资源, 当进行写锁时, 会阻塞其它的读锁或者写锁操作;</p></li></ul><p>锁的颗粒大小 及锁定数据的单元大小的度量;</p><p>mysql主要有两种锁策略, </p><ul><li><p>表锁, 是一种开销最小的锁策略; </p></li><li><p>行锁, 是一种开销最大的锁策略;</p></li></ul><p>事务 </p><p>事务是数据库区别于文件系统的重要特征之一;<br>事务用于保证数据库的完整性; </p><p>事务四大特性 </p><ul><li>原子性 (Atomicity)</li><li>一致性(Consistency)</li><li>隔离性(Isolation)</li><li>持久性(Durability)</li></ul><p>外键是保证数据一致性的一种特性;</p><p>索引是对数据表中一列或多列的执行排序的一种结构,如书的目录, 可以快速定位数据的方法, </p><ul><li>普通索引</li><li>唯一索引</li><li>全文索引</li><li>btree索引</li><li>hash索引</li><li>…</li></ul><p>几类存储引擎的主要特征,</p><table><thead><tr><th style="text-align:left"></th><th style="text-align:left">存储限制</th><th style="text-align:left">事务安全</th><th style="text-align:left">支持索引</th><th style="text-align:left">锁颗粒</th><th style="text-align:left">数据压缩</th><th style="text-align:left">支持外键</th><th style="text-align:left">忌用</th></tr></thead><tbody><tr><td style="text-align:left"><code>InnoDB</code></td><td style="text-align:left">64TB</td><td style="text-align:left">支持</td><td style="text-align:left">支持</td><td style="text-align:left">支持MvCC行锁</td><td style="text-align:left">-</td><td style="text-align:left">支持</td><td style="text-align:left">无</td></tr><tr><td style="text-align:left"><code>MyISAM</code></td><td style="text-align:left">256TB</td><td style="text-align:left">-</td><td style="text-align:left">支持</td><td style="text-align:left">表锁</td><td style="text-align:left">支持</td><td style="text-align:left">-</td><td style="text-align:left">读写操作频繁</td></tr><tr><td style="text-align:left"><code>MRG_MYISAM</code></td><td style="text-align:left"></td><td style="text-align:left">不支持</td><td style="text-align:left"></td><td style="text-align:left">支持并发插入表级锁</td><td style="text-align:left"></td><td style="text-align:left"></td><td style="text-align:left">全局查找过多的场景</td></tr><tr><td style="text-align:left"><code>Memory</code></td><td style="text-align:left">有</td><td style="text-align:left">-</td><td style="text-align:left">支持</td><td style="text-align:left">表锁</td><td style="text-align:left">-</td><td style="text-align:left">-</td><td style="text-align:left">-</td></tr><tr><td style="text-align:left"><code>Archive</code></td><td style="text-align:left">无</td><td style="text-align:left">-</td><td style="text-align:left"></td><td style="text-align:left">行锁</td><td style="text-align:left">支持</td><td style="text-align:left">-</td><td style="text-align:left">需要随机读写/更新/删除</td></tr><tr><td style="text-align:left"><code>Ndb cluster</code></td><td style="text-align:left"></td><td style="text-align:left">支持</td><td style="text-align:left"></td><td style="text-align:left">行锁</td><td style="text-align:left"></td><td style="text-align:left"></td><td style="text-align:left">大部分应用</td></tr></tbody></table><p>适用场景</p><ul><li>MyISAM: 适用于事务的处理不多的情况;</li><li>InnoDB: 适用于事务处理比较多, 需要外键支持的情况;</li><li>MRG_MYISAM 适用于分段归档, 数据仓库;</li><li>Archive 适用于日志记录, 支持SELECT/INSERT操作,不支持UPDATE/DELETE操作;</li><li>Ndb cluster 适用于高可用性;</li></ul><p>修改存储引擎</p><p>从Mysql5.5开始默认配置InnoDB存储引擎;</p><ul><li><p>可通过修改配置文件<code>default-storage-engine = InnoDB</code> 值来设置合适的引擎;</p></li><li><p>通过创建表时指定所使用的存储引擎,</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS tbl_name(</span><br><span class="line">...</span><br><span class="line">) ENGINE = engine;</span><br></pre></td></tr></table></figure><ul><li>通过ALTER 命令来修改, </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE tbl_name ENGINE [=] engine_name;</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul><li>简要阐述了存储过程的基本概念及为何要使用存储过程的优点;</li><li>存储过程 实际为SQL语句和控制语句的预编译集合, 以一个名称存储并作为一个单元处理;</li><li>存储过程<ul><li>有三类参数可使用 输入类型, 输出类型,输入&amp;输出类型;</li><li>通过CREATE PROCEDURE sp_name(p,…)…创建存储过程;</li><li>创建存储过程或自定义函数时需要通过delimiter语句修改定界符;</li><li>如果函数体或过程体有多个语句, 需要包含在BEGIN…END语句块中;</li><li>存储过程通过call来调用;</li></ul></li><li>简要分析了存储过程创建/修改/调用/修改的语法结构;</li><li>通过创建无参数存储过程实例初步学习存储过程;</li><li>通过创建带IN参数的存储过程实例分析进一步了解存储过程的使用;</li><li>通过进一步创建带IN和OUT参数及多OUT参数的存储过程深入了解学习存储过程的使用;</li><li>简要对比了存储过程与自定义函数的区别及其各自适合的场景;</li><li>简要介绍了几类存储引擎的特点等;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;MySQL 5.0&lt;/code&gt;开始支持存储过程，这样大大提高数据库的处理速度，同时也可以提高数据库编程的灵活性。SQL语句需要先编译然后执行，而存储过程（Stored Procedure）是一组为了完成特定功能的SQL语句集，经编译后存储在数据库中，用户通过指定存储过程的名字并给定参数（如果该存储过程带有参数）来调用执行它。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="mysql专题" scheme="http://researchlab.github.io/categories/mysql%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="mysql" scheme="http://researchlab.github.io/tags/mysql/"/>
    
  </entry>
  
</feed>
