<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>一线攻城狮</title>
  
  <subtitle>十年磨一剑，一步一步脚踏实地的耕种</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://researchlab.github.io/"/>
  <updated>2018-10-26T12:04:15.898Z</updated>
  <id>http://researchlab.github.io/</id>
  
  <author>
    <name>Lee Hong</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>redis专题17 主从同步系列问题</title>
    <link href="http://researchlab.github.io/2018/10/15/redis-17-replication/"/>
    <id>http://researchlab.github.io/2018/10/15/redis-17-replication/</id>
    <published>2018-10-15T19:03:25.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p>在生产环境中需要用到<code>redis</code>做数据持久化落地数据库时,  一般应搭建专属的<code>redis</code>集群来避免单点故障及单点读写性能问题, 如不是重度<code>redis</code>用户, 数据量压力不是特别大时, 也可以考虑采用<code>redis</code>主从同步架构代替, 本文将试图对<code>redis</code>主从同步原理, 步骤, 配置项, 实践等方面进行学习总结;<br><a id="more"></a></p><h5 id="主从同步目的"><a href="#主从同步目的" class="headerlink" title="主从同步目的"></a>主从同步目的</h5><blockquote><p>一旦主节点宕机, 从节点作为主节点的备份可以随时顶上来;<br>扩展主节点的读能力, 分担主节点读压力;</p></blockquote><h5 id="主从同步原理"><a href="#主从同步原理" class="headerlink" title="主从同步原理"></a>主从同步原理</h5><p><code>redis</code>支持主从复制, <code>redis</code>的主从结构可以采用一主多从或者级联结构, <code>redis</code>主从复制可以根据是否是全量分为全量同步和增量同步,<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">       /  slave-1  /  slave-2-1</span><br><span class="line">Master -  slave-2--   slave-2-2</span><br><span class="line">       \  slave-3  \  slave-2-3</span><br><span class="line">        \ ...      \  ...</span><br><span class="line">          slave-n     slave-2-n</span><br></pre></td></tr></table></figure></p><h6 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h6><p><code>redis</code>全量复制一般发生在<code>slave</code>初始化阶段, 这时<code>slave</code>需要将Master上的所有数据都复制一份, 具体过程如下,</p><ul><li>1.从服务器连接主服务器, 发送<code>sync</code>命令;</li><li>2.主服务器接收到<code>sync</code>命名后, 开始执行<code>bgsave</code>命令生成RDB文件并使用复制积压缓冲区记录此后执行的所有写命令;</li><li>3.主服务器<code>bgsave</code>执行完后, 向所有从服务器发送快照文件, 并在发送期间继续记录被执行的写命令;</li><li>4.从服务器收到快照文件后丢弃所有旧数据, 载入收到的快照;</li><li>5.主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令;</li><li>6.从服务器完成对快照的载入, 开始接收命令请求, 并执行来自主服务器缓冲区的写命令;</li></ul><p>完成上面几个步骤后就完成了从服务器数据初始化的所有操作, 从服务器此时可以接收来自用户的读请求。</p><blockquote><p>若多个从服务器同时发来<code>sync</code>指令, 主服务器也只会执行一次<code>bgsave</code>, 然后把持久化好的RDB文件发给多个下游;</p></blockquote><h6 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a>增量同步</h6><p>在redis2.8之前, redis仅支持<code>sync</code>全量同步操作, <code>sync</code>命令是一个非常耗费资源的操作, 为了解决主从服务器断线重来带来的<code>sync</code>重复复制问题, <code>redis</code>从2.8版本开始, 使用<code>psync</code>命令代替<code>sync</code>命令来执行复制时的同步操作。<br><code>psync</code>命令具有完整重同步<code>(full resynchronization)</code>和增量重同步<code>(partial resynchronization)</code>两种模式, 而增量同步策略大大降低了连接断开的恢复成本。增量同步过程如下,</p><ul><li>1.<code>master</code>端为复制流维护一个内存缓冲区<code>(in-memory backlog)</code>, 记录最近发送的复制流命令;</li><li>2.同时, Master和<code>slave</code>之间都维护一个复制偏移量<code>(replication offset)</code>和当前<code>master</code>服务器<code>ID(Masterrun id)</code>。</li><li>3.当网络断开, <code>slave</code>尝试重连时:<ul><li>a. 如果<code>masterID</code>相同(即仍是断网前的<code>master</code>服务器), 并且从断开时到当前时刻的历史命令依然在<code>master</code>的内存缓冲区中存在, 则Master会将缺失的这段时间的所有命令发送给<code>slave</code>执行, 然后复制工作就可以继续执行了;</li><li>b. 否则, 依然需要全量复制操作;</li></ul></li></ul><blockquote><p>增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令, 从服务器接收并执行收到的写命令。</p></blockquote><p>可见增量重同步功能由以下三个部分构成,</p><ul><li>1.主服务器的复制偏移量<code>(replication offset)</code>和从服务器的复制偏移量;</li><li>2.主服务器的复制积压缓冲区<code>(replication backlog)</code>;</li><li>3.服务器的运行<code>ID(run ID)</code>。</li></ul><p><strong>1.复制偏移量</strong></p><p>执行复制的双方——主服务器和从服务器会分别维护一个复制偏移量,</p><ul><li>主服务器每次向从服务器传播<code>N</code>个字节的数据时, 就将自己的复制偏移量的值加上<code>N</code>;</li><li>从服务器每次收到主服务器传播来的<code>N</code>个字节的数据时, 就将自己的复制偏移量的值加上<code>N</code>;</li></ul><blockquote><p>主从偏移量相同, 则当前主从处于一致状态, 反之则主从状态不一致;</p></blockquote><p>示例分析</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                          --(网络故障断线  )--&gt; slaveA ( offset=10086 )</span><br><span class="line">                        /</span><br><span class="line">                       /</span><br><span class="line">Master ( offset=10119 )-----(成功发送33字节)--&gt; slaveB ( offset=10119 )</span><br><span class="line">                       \</span><br><span class="line">                        \</span><br><span class="line">                          --(成功发送33字节)--&gt; slaveC ( offset=10119 )</span><br></pre></td></tr></table></figure><p>如上示例, 假设从服务器<code>A</code>在断线之后就立即重新连接主服务器成功, 那么接下来, 从服务器将向主服务器发送<code>psync</code>命令, 报告从服务器A当前的复制偏移量为<code>10086</code>, 那么这时, 主服务器应该对从服务器执行完整重同步还是部分重同步呢？如果执行部分重同步的话, 主服务器又如何补偿从服务器<code>A</code>在断线期间丢失的那部分数据呢？以上问题的答案都和复制积压缓冲区有关。</p><p><strong>2.复制积压缓冲区</strong><br>复制积压缓冲区是由主服务器维护的一个固定长度<code>(fixed-size)</code>先进先出<code>(FIFO)</code>队列, 默认大小为<code>1MB</code>。</p><p>和普通先进先出队列随着元素的增加和减少而动态调整长度不同, 固定长度先进先出队列的长度是固定的, 当入队元素的数量大于队列长度时, 最先入队的元素会被弹出, 而新元素会被放入队列。</p><p>当主服务器向从服务器发送命令时, 它不仅会将写命令发送给所有从服务器, 还会将写命令入队到复制积压缓冲区里面, 示意图,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">          --(向从服务器发送命令)--&gt; slaveA</span><br><span class="line">        /</span><br><span class="line">       /</span><br><span class="line">Master -----(向从服务器发送命令)--&gt; slave...</span><br><span class="line">       \</span><br><span class="line">        \</span><br><span class="line">          --(同步将命令写入队列)--&gt; | 复制积压缓冲区队列 |</span><br></pre></td></tr></table></figure><p>因此, 主服务器的复制积压缓冲区里面会保存着一部分最近发送的写命令, 并且复制积压缓冲区会为队列中的每个字节记录相应的复制偏移量, 就像下表所示的那样,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">|偏移量| 10086 | 10087 | 10088 | 10089 |</span><br><span class="line">|字节值|   &apos;*&apos; |   5   | &apos;\r&apos;  | &apos;\n&apos;  |</span><br></pre></td></tr></table></figure><p>当从服务器重新连上主服务器时, 从服务器会通过<code>psync</code>命令将自己的复制偏移量offset发送给主服务器, 主服务器会根据这个复制偏移量来决定对从服务器执行何种同步操作:</p><blockquote><p>如果<code>offset</code>偏移量之后的数据(也即是偏移量<code>offset+1</code>开始的数据)仍然存在于复制积压缓冲区里面, 那么主服务器将对从服务器执行部分重同步操作;</p></blockquote><blockquote><p>相反, 如果<code>offset</code>偏移量之后的数据已经不存在于复制积压缓冲区, 那么主服务器将对从服务器执行完整重同步操作。</p></blockquote><p><strong>根据需要调整复制积压缓冲区的大小</strong></p><p><code>redis</code>为复制积压缓冲区设置的默认大小为<code>1MB</code>, 如果主服务器需要执行大量写命令, 又或者主从服务器断线后重连接所需的时间比较长, 那么这个大小也许并不合适。如果复制积压缓冲区的大小设置得不恰当, 那么<code>psync</code>命令的复制重同步模式就不能正常发挥作用, 因此, 正确估算和设置复制积压缓冲区的大小非常重要。<br>复制积压缓冲区的最小大小可以根据公式<code>second*write_size_per_second</code>来估算:</p><blockquote><p>其中<code>second</code>为从服务器断线后重新连接上主服务器所需的平均时间(以秒计算);</p></blockquote><blockquote><p>而<code>write_size_per_second</code>则是主服务器平均每秒产生的写命令数据量(协议格式的写命令的长度总和);</p></blockquote><p>例如, 如果主服务器平均每秒产生<code>1MB</code>的写数据, 而从服务器断线之后平均要<code>5秒</code>才能重新连接上主服务器, 那么复制积压缓冲区的大小就不能低于<code>5MB</code>。<br>为了安全起见, 可以将复制积压缓冲区的大小设为<code>2*second*write_size_per_second</code>, 这样可以保证绝大部分断线情况都能用部分重同步来处理。<br>可以根据实际需要, 修改配置文件中的<code>repl-backlog-size</code>选项来修改复制积压缓冲区的大小;</p><p><strong>3.服务器运行ID</strong><br>除了复制偏移量和复制积压缓冲区之外, 实现部分重同步还需要用到服务器运行<code>ID(run ID)</code>:</p><blockquote><p>每个<code>redis</code>服务器, 不论主服务器还是从服务, 都会有自己的运行<code>ID</code>;</p></blockquote><blockquote><p>运行<code>ID</code>在服务器启动时自动生成, 由40个随机的十六进制字符组成, 例如<code>53b9b28df8042fdc9ab5e3fcbbbabff1d5dce2b3</code>;</p></blockquote><p>当从服务器对主服务器进行初次复制时, 主服务器会将自己的运行<code>ID</code>传送给从服务器, 而从服务器则会将这个运行<code>ID</code>保存起来(注意哦, 是从服务器保存了主服务器的<code>ID</code>)。</p><p>当从服务器断线并重新连上一个主服务器时, 从服务器将向当前连接的主服务器发送之前保存的运行<code>ID</code>:</p><blockquote><p>如果从服务器保存的运行<code>ID</code>和当前连接的主服务器的运行<code>ID</code>相同, 那么说明从服务器断线之前复制的就是当前连接的这个主服务器, 主服务器可以继续尝试执行部分重同步操作;</p></blockquote><blockquote><p>相反地, 如果从服务器保存的运行<code>ID</code>和当前连接的主服务器的运行<code>ID</code>并不相同, 那么说明从服务器断线之前复制的主服务器并不是当前连接的这个主服务器, 主服务器将对从服务器执行完整重同步操作。</p></blockquote><p><strong>psync命令</strong><br><code>psync</code>命令的调用方法有两种,</p><blockquote><p>如果从服务器以前没有复制过任何主服务器, 或者之前执行过<code>SLAVEOF NO ONE</code>命令, 那么从服务器在开始一次新的复制时将向主服务器发送<code>psync ? -1</code>命令, 主动请求主服务器进行完整重同步(因为这时不可能执行部分重同步);</p></blockquote><blockquote><p>相反地, 如果从服务器已经复制过某个主服务器, 那么从服务器在开始一次新的复制时将向主服务器发送<code>psync &lt;runid&gt; &lt;offset&gt;</code>命令: 其中<code>runid</code>是上一次复制的主服务器的运行<code>ID</code>, 而<code>offset</code>则是从服务器当前的复制偏移量, 接收到这个命令的主服务器会通过这两个参数来判断应该对从服务器执行哪种同步操作。</p></blockquote><h5 id="主从同步策略"><a href="#主从同步策略" class="headerlink" title="主从同步策略"></a>主从同步策略</h5><p><code>redis</code> 的复制是异步进行的, <code>redis3.0</code>开始提供的<code>wait</code>指令可以让异步复制变身同步复制, 确保系统的强一致性,<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; set key value</span><br><span class="line">OK</span><br><span class="line">&gt; wait 1 0</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure></p><p>wait 提供两个参数, 第一个参数是从库的数量<code>N</code>, 第二个参数是时间<code>t</code>, 以毫秒为单位。它表示等待<code>wait</code>指令之前的所有写操作同步到<code>N</code>个从库 (也就是确保<code>N</code>个从库的同步没有滞后), 最多等待时间<code>t</code>。如果时间<code>t=0</code>, 表示无限等待直到<code>N</code>个从库同步完成达成一致。</p><p>假设此时出现了网络分区,<code>wait</code>指令第二个参数时间<code>t=0</code>, 主从同步无法继续进行, <code>wait</code>指令会永远阻塞, <code>redis</code>服务器将丧失可用性。</p><p><strong>主从刚刚连接的时候, 进行全量同步; 全同步结束后, 进行增量同步。当然, 如果有需要, slave在任何时候都可以发起全量同步。redis策略是, 无论如何, 首先会尝试进行增量同步, 如不成功, 要求从机进行全量同步。</strong></p><h5 id="主从同步过程"><a href="#主从同步过程" class="headerlink" title="主从同步过程"></a>主从同步过程</h5><p>从服务器每次启动时, 会立即通过<code>slaveof master-host  master-port</code> 向主服务器发起主从复制同步请求; <code>SLAVEOF</code>命令是一个异步命令, 在完成<code>master-host</code>属性和<code>master-port</code>属性的设置工作之后, 从服务器将向发送<code>SLAVEOF</code>命令的客户端返回<code>OK</code>, 表示复制指令已经被接收, 而实际的复制工作将在<code>OK</code>返回之后才真正开始执行。从服务器开始发起主从复制请求到开始复制主要经历了如下7个步骤,</p><p><strong>步骤1</strong>: 设置主服务器的地址和端口, 通过<code>slaveof</code>指令发起主从复制同步请求,<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:12345&gt; SLAVEOF 127.0.0.1 6379</span><br><span class="line">OK</span><br></pre></td></tr></table></figure></p><p><strong>步骤2</strong>: 建立套接字连接</p><p>在SLAVEOF命令执行之后, 从服务器将根据命令所设置的IP地址和端口, 创建连向主服务器的套接字连接, 如果从服务器创建的套接字能成功连接(connect)到主服务器, 那么从服务器将为这个套接字关联一个专门用于处理复制工作的文件事件处理器, 这个处理器将负责执行后续的复制工作, 比如接收RDB文件, 以及接收主服务器传播来的写命令, 诸如此类。而主服务器在接受(accept)从服务器的套接字连接之后, 将为该套接字创建相应的客户端状态, 并将从服务器看作是一个连接到主服务器的客户端来对待, 这时从服务器将同时具有服务器(server)和客户端(client)两个身份: 从服务器可以向主服务器发送命令请求, 而主服务器则会向从服务器返回命令回复。</p><p><strong>步骤3</strong>: 发送PING命令</p><p>从服务器成为主服务器的客户端之后, 做的第一件事就是向主服务器发送一个PING命令。</p><blockquote><p>通过发送PING命令检查套接字的读写状态;</p></blockquote><blockquote><p>通过PING命令可以检查主服务器能否正常处理命令。</p></blockquote><p>从服务器在发送PING命令之后可能遇到以下三种情况:</p><blockquote><p>主服务器向从服务器返回了一个命令回复, 但从服务器却不能在规定的时限内读取命令回复的内容(timeout), 说明网络连接状态不佳, 从服务器将断开并重新创建连向主服务器的套接字;</p></blockquote><blockquote><p>如果主服务器返回一个错误, 那么表示主服务器暂时没有办法处理从服务器的命令请求, 从服务器也将断开并重新创建连向主服务器的套接字;</p></blockquote><blockquote><p>如果从服务器读取到”PONG”回复, 那么表示主从服务器之间的网络连接状态正常, 那就继续执行下面的复制步骤。</p></blockquote><p><strong>步骤4</strong>: 身份验证</p><p>从服务器在收到主服务器返回的”PONG”回复之后, 下一步要做的就是决定是否进行身份验证:</p><p>如果从服务器设置了masterauth选项, 那么进行身份验证。否则不进行身份认证;<br>在需要进行身份验证的情况下, 从服务器将向主服务器发送一条AUTH命令, 命令的参数为从服务器masterauth选项的值。</p><p>从服务器在身份验证阶段可能遇到的情况有以下几种:</p><blockquote><p>主服务器没有设置requirepass选项, 从服务器没有设置masterauth,那么就继续后面的复制工作;</p></blockquote><blockquote><p>如果从服务器的通过AUTH命令发送的密码和主服务器requirepass选项所设置的密码相同, 那么也继续后面的工作, 否则返回错误invaild password;</p></blockquote><blockquote><p>如果主服务器设置了requireoass选项, 但从服务器没有设置masterauth选项, 那么服务器将返回NOAUTH错误。反过来如果主服务器没有设置requirepass选项, 但是从服务器却设置了materauth选项, 那么主服务器返回no password is set错误;</p></blockquote><p>所有错误到只有一个结果: 中止目前的复制工作, 并从创建套接字开始重新执行复制, 直到身份验证通过, 或者从服务器放弃执行复制为止。</p><p><strong>步骤5</strong>: 发送端口信息</p><p>身份验证步骤之后, 从服务器将执行命令<code>REPLCONF listening-port &lt;port-number&gt;</code>, 向主服务器发送从服务器的监听端口号。</p><p>主服务器在接收到这个命令之后, 会将端口号记录在从服务器所对应的客户端状态的<code>slave_listening_port</code>属性,</p><blockquote><p><code>slave_listening_port</code>属性目前唯一的作用就是在主服务器执行<code>INFO replication</code>命令时打印出从服务器的端口号。</p></blockquote><p><strong>步骤6</strong>: 同步</p><p>在这一步, 从服务器将向主服务器发送<code>psync</code>命令, 执行同步操作, 并将自己的数据库更新至主服务器数据库当前所处的状态。</p><p>需要注意的是在执行同步操作前, 只有从服务器是主服务器的客户端。但是执行同步操作之后, 主服务器也会成为从服务器的客户端,</p><blockquote><p>如果<code>psync</code>命令执行的是完整同步操作, 那么主服务器只有成为了从服务器的客户端才能将保存在缓冲区中的写命令发送给从服务器执行;</p></blockquote><blockquote><p>如果<code>psync</code>命令执行的是部分同步操作, 那么主服务器只有成为了从服务器的客户端才能将保存在复制积压缓冲区中的写命令发送给从服务器执行;</p></blockquote><p><strong>步骤7</strong>: 命令传播</p><p>当完成了同步之后, 主从服务器就会进入命令传播阶段, 这时主服务器只要一直将自己执行的写命令发送给从服务器, 而从服务器只要一直接收并执行主服务器发来的写命令, 就可以保证主从服务器一直保持一致了。</p><p><strong>心跳检测</strong><br>在命令传播阶段, 从服务器默认会以每秒一次的频率, 向主服务器发送命令: <code>REPLCONF ACK &lt;replication_offset&gt;</code></p><p>其中<code>replication_offset</code>是从服务器当前的复制偏移量。</p><p>发送<code>REPLCONF ACK</code>命令对于主从服务器有三个作用:</p><blockquote><p>检测主从服务器的网络连接状态;</p></blockquote><blockquote><p>辅助实现min-slaves选项;</p></blockquote><blockquote><p>检测命令丢失。</p></blockquote><p>检测主从服务器的网络连接状态</p><p>如果主服务器超过一秒钟没有收到从服务器发来的<code>REPLCONF ACK</code>命令, 那么主服务器就知道主从服务器之间的连接出现问题了。</p><p>通过向主服务器发送<code>INFO replication</code>命令, 在列出的从服务器列表的<code>lag</code>一栏中, 我们可以看到相应从服务器最后一次向主服务器发送<code>REPLCONF ACK</code>命令距离现在过了多少秒;</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">10.1.195.19:8001&gt; info replication</span><br><span class="line"><span class="meta">#</span><span class="bash"> Replication</span></span><br><span class="line">role:master</span><br><span class="line">connected_slaves:1</span><br><span class="line">slave0:ip=172.28.0.1,port=6379,state=online,offset=0,lag=1</span><br><span class="line">master_replid:10c63aebd8f09c749d1b26eccb52856b6d894292</span><br><span class="line">master_replid2:0000000000000000000000000000000000000000</span><br><span class="line">master_repl_offset:0</span><br><span class="line">second_repl_offset:-1</span><br><span class="line">repl_backlog_active:1</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:1</span><br><span class="line">repl_backlog_histlen:0</span><br><span class="line">10.1.195.19:8001&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">刚刚发送过 REPLCONF ACK命令</span></span><br><span class="line">slave1:ip=171.28.0.1,port=6379,state=online,offset=197,lag=15</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">15秒之前发送过REPLCONF ACK命令</span></span><br><span class="line"></span><br><span class="line">master_repl_offset:211</span><br><span class="line">repl_backlog_active:1</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:2</span><br><span class="line">repl_backlog_histlen:210</span><br></pre></td></tr></table></figure><p>在一般情况下, <code>lag</code>的值应该在0秒或者1秒之间跳动, 如果超过1秒的话, 那么说明主从服务器之间的连接出现了故障。</p><p><strong>辅助实现min-slaves配置选项</strong></p><p><code>redis</code>的<code>min-slaves-to-write</code>和<code>min-slaves-max-lag</code>两个选项可以防止主服务器在不安全的情况下执行写命令。</p><p>举个例子, 如果我们向主服务器提供以下设置:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">min-slaves-to-write 3</span><br><span class="line">min-slaves-max-lag 10</span><br></pre></td></tr></table></figure></p><p>那么在从服务器的数量少于3个, 或者三个从服务器的延迟<code>(lag)</code>值都大于或等于10秒时, 主服务器将拒绝执行写命令, 这里的延迟值就是上面提到的<code>INFO replication</code>命令的<code>(lag)</code>值。</p><p><strong>检测命令丢失</strong></p><p>我们从命令: <code>REPLCONF ACK &lt;replication_offset&gt;</code>就可以知道, 每发送一次这个命令从服务器都会向主服务器报告一次自己的复制偏移量。那此时尽管主服务器发送给从服务器的<code>SET key value</code>丢失了。也无所谓, 主服务器马上就知道了。</p><h5 id="同步实践"><a href="#同步实践" class="headerlink" title="同步实践"></a>同步实践</h5><p><strong>0.环境准备</strong><br>通过构建如下主从级联架构来进一步实践<code>redis</code>主从复制同步机制,<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">master---&gt; slave01 --&gt; slave02</span><br></pre></td></tr></table></figure></p><p>即<code>master</code>为主服务器, <code>slave01</code>为<code>master</code>从服务器, 同时也是<code>slave02</code>主服务器,  由于要构建多个<code>redis container</code>环境, 为方便起见通过<code>docker-compose</code>来实践,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">version: '3'</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  master-redis:</span><br><span class="line">    image: redis</span><br><span class="line">    container_name: master</span><br><span class="line">    ports:</span><br><span class="line">      - "8001:6379"</span><br><span class="line">    volumes:</span><br><span class="line">      - ~/workbench/docker/docker-compose/redis/conf/redis.conf:/etc/redis/redis.conf</span><br><span class="line">    entrypoint: ["redis-server", "/etc/redis/redis.conf"]</span><br><span class="line"></span><br><span class="line">  slave-redis-01:</span><br><span class="line">    image: redis</span><br><span class="line">    container_name: slave01</span><br><span class="line">    ports:</span><br><span class="line">      - "8002:6379"</span><br><span class="line">    volumes:</span><br><span class="line">      - ~/workbench/docker/docker-compose/redis/conf/redis.conf:/etc/redis/redis.conf</span><br><span class="line">    entrypoint: ["redis-server", "/etc/redis/redis.conf"]</span><br><span class="line"></span><br><span class="line">  slave-redis-02:</span><br><span class="line">    image: redis</span><br><span class="line">    container_name: slave02</span><br><span class="line">    ports:</span><br><span class="line">      - "8003:6379"</span><br><span class="line">    volumes:</span><br><span class="line">      - ~/workbench/docker/docker-compose/redis/conf/redis.conf:/etc/redis/redis.conf</span><br><span class="line">    entrypoint: ["redis-server", "/etc/redis/redis.conf"]</span><br></pre></td></tr></table></figure></p><p>将<code>redis.conf</code>配置做如下修改,</p><ul><li>将<code>bind 127.0.0.1</code> 修改为<code>bind 0.0.0.0</code>;</li><li>将<code>daemonize yes</code> 修改为<code>daemonize no</code>, 让<code>redis</code>运行在前台;</li><li>将<code>protected-mode yes</code>修改为<code>protected-mode no</code>, 在<code>protected-mode yes</code>模式下需要设置密码才能远程访问, 否则<code>redis</code>只接受本地访问;</li></ul><p><strong>1.发送<code>slaveof</code>指令,请求主从同步</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">➜  redis docker-compose up -d</span><br><span class="line">Creating network "redis_default" with the default driver</span><br><span class="line">Creating master  ... done</span><br><span class="line">Creating slave02 ... done</span><br><span class="line">Creating slave01 ... done</span><br><span class="line">➜  redis docker-compose ps</span><br><span class="line"> Name                Command               State           Ports</span><br><span class="line">-------------------------------------------------------------------------</span><br><span class="line">master    redis-server /etc/redis/re ...   Up      0.0.0.0:8001-&gt;6379/tcp</span><br><span class="line">slave01   redis-server /etc/redis/re ...   Up      0.0.0.0:8002-&gt;6379/tcp</span><br><span class="line">slave02   redis-server /etc/redis/re ...   Up      0.0.0.0:8003-&gt;6379/tcp</span><br><span class="line">➜  redis ifconfig |grep inet |grep -v 127.0.0.1</span><br><span class="line">        inet6 ::1 prefixlen 128</span><br><span class="line">        inet6 fe80::1%lo0 prefixlen 64 scopeid 0x1</span><br><span class="line">        inet6 fe80::475:d879:2a90:ac35%en0 prefixlen 64 secured scopeid 0x5</span><br><span class="line">        inet 10.1.195.19 netmask 0xffffff00 broadcast 10.1.195.255</span><br></pre></td></tr></table></figure><p>上述命令, 分别启动了一台<code>master</code>主机, 两台<code>slave01</code>,<code>slave02</code>从机, 并得知当前宿主机ip为<code>10.1.195.19</code></p><p>登录从机发送<code>slaveof</code>指令, 开始主从复制同步,<br>主机<code>master</code> 执行命令,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">➜  docker exec -it master redis-cli -h 10.1.195.19 -p 8001</span><br><span class="line">10.1.195.19:8001&gt; flushdb</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8001&gt; hmset info name mike city shanghai code 110</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8001&gt; hgetall info</span><br><span class="line">1) "name"</span><br><span class="line">2) "mike"</span><br><span class="line">3) "city"</span><br><span class="line">4) "shanghai"</span><br><span class="line">5) "code"</span><br><span class="line">6) "110"</span><br><span class="line">10.1.195.19:8001&gt;</span><br></pre></td></tr></table></figure></p><p>从机<code>slave01</code> 查询命令,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">➜  docker exec -it slave01 redis-cli -h 10.1.195.19 -p 8002</span><br><span class="line">10.1.195.19:8002&gt; slaveof no one</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8002&gt; flushdb</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8002&gt; slaveof 10.1.195.19 8001</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8002&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "info"</span><br><span class="line">10.1.195.19:8002&gt; hgetall info</span><br><span class="line">1) "name"</span><br><span class="line">2) "mike"</span><br><span class="line">3) "city"</span><br><span class="line">4) "shanghai"</span><br><span class="line">5) "code"</span><br><span class="line">6) "110"</span><br><span class="line">10.1.195.19:8002&gt;</span><br></pre></td></tr></table></figure></p><p>从机<code>slave02</code>查询命令,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">➜  docker exec -it slave02 redis-cli -h 10.1.195.19 -p 8003</span><br><span class="line">10.1.195.19:8003&gt; slaveof no one</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8003&gt; flushdb</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8003&gt; slaveof 10.1.195.19 8002</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8003&gt; hgetall info</span><br><span class="line">1) "name"</span><br><span class="line">2) "mike"</span><br><span class="line">3) "city"</span><br><span class="line">4) "shanghai"</span><br><span class="line">5) "code"</span><br><span class="line">6) "110"</span><br><span class="line">10.1.195.19:8003&gt;</span><br></pre></td></tr></table></figure></p><ul><li><code>docker exec -it ${docker-name} redis-cli -h ${localhost-ip} -p ${port}</code>命令登录到各个<code>redis</code>实例服务;</li><li><code>slaveof no one</code>命令将当前<code>redis</code>实例的主从服务;</li><li>从上述实例可见, 通过在<code>master</code>主机中执行<code>hmset</code>命令, 相应的从机以及级联从机也都同步了主机的执行命令, 上述示例显示主从复制同步成功;</li></ul><p>从机配置默认开启了只读模式<code>slave-read-only yes</code>,所以对从机进行修改操作是不许可的, 也不建议这么做;<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">10.1.195.19:8003&gt; flushdb</span><br><span class="line">(error) READONLY You can't write against a read only replicx</span><br><span class="line">10.1.195.19:8003&gt;</span><br></pre></td></tr></table></figure></p><p>当对主机操作<code>flushdb</code>时, 可见从机也执行了<code>flushdb</code>命令<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">10.1.195.19:8001&gt; flushdb</span><br><span class="line">OK</span><br><span class="line">10.1.195.19:8001&gt;</span><br><span class="line"></span><br><span class="line">10.1.195.19:8002&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) (empty list or set)</span><br><span class="line">10.1.195.19:8002&gt;</span><br><span class="line"></span><br><span class="line">10.1.195.19:8003&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) (empty list or set)</span><br><span class="line">10.1.195.19:8003&gt;</span><br></pre></td></tr></table></figure></p><p>当关闭<code>master</code>服务后, 对从机服务无影响,  所以从机服务的启动顺序及服务提供 与<code>master</code>主机服务是否已启动及启动顺序无关;</p><p>当然上面<code>docker-compose</code>配置也可以直接配置<code>slaveof</code>参数， 就不需要手动去发起命令, 可参看 <a href="https://github.com/researchlab/dockerenv/tree/master/docker-compose-redis-replication" target="_blank" rel="noopener">docker-compose-redis-replication</a></p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li><code>redis</code>的主从同步是异步进行的, 这意味着主从同步不会影响主逻辑, 也不会降低<code>redis</code>的处理性能。</li><li>主从架构中, 可以考虑关闭主服务器的数据持久化功能, 只让从服务器进行持久化, 这样可以提高主服务器的处理性能。</li><li>在主从架构中, 从服务器通常被设置为只读模式, 这样可以避免从服务器的数据被误修改。但是从服务器仍然可以接受<code>config</code>等指令, 所以还是不应该将从服务器直接暴露到不安全的网络环境中。如果必须如此, 那可以考虑给重要指令进行重命名, 来避免命令被外人误执行。</li><li>主从同步分为<code>全量同步</code>和<code>增量同步</code>, 文中对<code>全量同步</code>和<code>增量同步</code>原理,实现过程进行了阐述分析;</li><li>进一步阐述了主从不同执行策略, 即从机初始连接主机时, 先进行增量同步, 若增量同步失败, 则进行全量同步,  同时可以利用<code>wait</code>指令 将redis主从同步的异步行为转变为同步行为;</li><li>分析了主从同步过程,  主从同步开始至复制, 大致进来7个过程, 1.发起<code>slaveof</code>指令;2.建立套接字连接;3.发送ping指令测试连接状态;4.身份认证;5.发送端口信息;6.同步初始化阶段,从机载入主机RDB,准备接受主机命令;7.增量同步;</li><li>通过docker-compose 构建<code>主-从-从</code>架, 深入实践分析<code>redis</code>主从复制同步过程;</li><li>主从复制是 <code>redis</code> 分布式的基础, <code>redis</code> 的高可用离开了主从复制将无从进行;</li><li>不过复制功能也不是必须的, 如果你将 <code>redis</code> 只用来做缓存, 跟<code>memcache</code>一样来对待, 也就无需要从库做备份, 挂掉了重新启动一下就行。但是只要你使用了 <code>redis</code> 的持久化功能, 就必须认真对待主从复制, 它是系统数据安全的基础保障;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在生产环境中需要用到&lt;code&gt;redis&lt;/code&gt;做数据持久化落地数据库时,  一般应搭建专属的&lt;code&gt;redis&lt;/code&gt;集群来避免单点故障及单点读写性能问题, 如不是重度&lt;code&gt;redis&lt;/code&gt;用户, 数据量压力不是特别大时, 也可以考虑采用&lt;code&gt;redis&lt;/code&gt;主从同步架构代替, 本文将试图对&lt;code&gt;redis&lt;/code&gt;主从同步原理, 步骤, 配置项, 实践等方面进行学习总结;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题16 数据持久化实践</title>
    <link href="http://researchlab.github.io/2018/10/13/redis-16-storage-solution-opt/"/>
    <id>http://researchlab.github.io/2018/10/13/redis-16-storage-solution-opt/</id>
    <published>2018-10-13T19:12:11.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p>通过示例分析，深入了解<code>redis</code>数据持久化策略执行机制；<br><a id="more"></a></p><h5 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜ docker run -itd --name lredis -p7002:6379 -v ~/workbench/docker/redis/conf/redis.conf:/etc/redis/redis.conf redis redis-server /etc/redis/redis.conf</span><br></pre></td></tr></table></figure><h4 id="版本日志"><a href="#版本日志" class="headerlink" title="版本日志"></a>版本日志</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜ docker logs -f lredis</span><br><span class="line">1:C 24 Oct 2018 09:24:03.601 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo</span><br><span class="line">1:C 24 Oct 2018 09:24:03.602 # Redis version=5.0.0, bits=64, commit=00000000, modified=0, pid=1, just started</span><br><span class="line">...</span><br><span class="line">1:M 24 Oct 2018 09:24:03.606 # Server initialized</span><br><span class="line">1:M 24 Oct 2018 09:24:03.606 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command &apos;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&apos; as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.</span><br><span class="line">1:M 24 Oct 2018 09:24:03.606 * Ready to accept connections</span><br></pre></td></tr></table></figure><h4 id="RDB方式持久化"><a href="#RDB方式持久化" class="headerlink" title="RDB方式持久化"></a>RDB方式持久化</h4><p><code>Redis</code>默认的持久化方式是<code>RDB</code>，并且默认是打开的。<code>RDB</code>的保存有方式分为<code>主动保存</code>与<code>被动保存</code>。<code>主动保存</code>可以在<code>redis-cli</code>中输入<code>save</code>即可；<code>被动保存</code>需要满足配置文件中设定的触发条件，满足触发条件后，数据才会被保存为快照，正是因为这样才说<code>RDB</code>的数据完整性是比不上<code>AOF</code>;<br>触发保存条件后，会在指定的目录生成一个名为<code>dump.rdb</code>的文件，等到下一次启动<code>Redis</code>时，<code>Redis</code>会去读取该目录下的<code>dump.rdb</code>文件，将里面的数据恢复到<code>Redis</code>;</p><p><code>dump.rdb</code>文件路径,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; config get dir</span><br><span class="line">1) "dir"</span><br><span class="line">2) "/data"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p><p>目前官方默认的触发条件可以在<code>redis.conf</code>中看到,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">save 900 1              #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。</span><br><span class="line"></span><br><span class="line">save 300 10            #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。</span><br><span class="line"></span><br><span class="line">save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。</span><br></pre></td></tr></table></figure></p><p>为了便于测试， 把上面默认的配置修改为，<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">save 900 1              #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。</span><br><span class="line"></span><br><span class="line">save 300 10            #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。</span><br><span class="line"></span><br><span class="line">save 20 5        #在20秒之后，如果至少有5个key发生变化，则dump内存快照。</span><br></pre></td></tr></table></figure></p><ol><li><strong><code>RDB</code>被动触发保存实践</strong><br>input<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; set a 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set b 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set c 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set d 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set e 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set f 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "a"</span><br><span class="line">   2) "e"</span><br><span class="line">   3) "b"</span><br><span class="line">   4) "d"</span><br><span class="line">   5) "f"</span><br><span class="line">   6) "c"</span><br></pre></td></tr></table></figure></li></ol><p><code>RDB</code>被动保存成功生成了<code>rdb</code>文件及日志,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker exec -it lredis ls /data</span><br><span class="line">dump.rdb</span><br></pre></td></tr></table></figure></p><p>日志记录,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1:M 24 Oct 2018 09:47:49.394 * DB loaded from disk: 0.000 seconds</span><br><span class="line">1:M 24 Oct 2018 09:47:49.394 * Ready to accept connections</span><br><span class="line">1:M 24 Oct 2018 09:48:48.758 * 5 changes in 20 seconds. Saving...</span><br><span class="line">1:M 24 Oct 2018 09:48:48.759 * Background saving started by pid 25</span><br><span class="line">25:C 24 Oct 2018 09:48:48.768 * DB saved on disk</span><br><span class="line">25:C 24 Oct 2018 09:48:48.769 * RDB: 0 MB of memory used by copy-on-write</span><br><span class="line">1:M 24 Oct 2018 09:48:48.860 * Background saving terminated with success</span><br></pre></td></tr></table></figure></p><p>日志提示<code>redis</code>检测到<code>20</code>秒内有至少<code>5</code>条记录被改动，满足<code>redis.conf</code>中对于<code>RDB</code>数据保存的条件，所以这里执行数据保存操作，并且提示开辟了一个<code>25</code>的进程出来执行保存操作，最后提示保存成功;</p><p>现在将redis进程kill，哪些数据会被保存？</p><p>通过命令<code>docker restart lredis</code>模拟<code>Redis</code>异常关闭，然后再启动<code>Redis</code>，再次查看之前<code>set</code>设置的内容,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "b"</span><br><span class="line">   2) "e"</span><br><span class="line">   3) "f"</span><br><span class="line">   4) "d"</span><br><span class="line">   5) "a"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p><p>发现<code>c</code>不见了， 可见<code>RDB</code>方式的数据完整性是不可靠的，除非断掉的那一刻正好是满足触发条件的条数;</p><p>关闭<code>RDB</code>方式持久化<br>修改<code>redis.conf</code>配置为,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">save ""</span><br><span class="line"><span class="meta">#</span><span class="bash">save 900 1</span></span><br><span class="line"><span class="meta">#</span><span class="bash">save 300 10</span></span><br><span class="line"><span class="meta">#</span><span class="bash">save 20 5</span></span><br></pre></td></tr></table></figure></p><p>重复上述<code>RDB</code>被动保存过程,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">➜ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "a"</span><br><span class="line">   2) "d"</span><br><span class="line">   3) "c"</span><br><span class="line">   4) "e"</span><br><span class="line">   5) "b"</span><br><span class="line">127.0.0.1:6379&gt; set f 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set i 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set j 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "a"</span><br><span class="line">   2) "j"</span><br><span class="line">   3) "f"</span><br><span class="line">   4) "d"</span><br><span class="line">   5) "c"</span><br><span class="line">   6) "e"</span><br><span class="line">   7) "b"</span><br><span class="line">   8) "i"</span><br><span class="line">127.0.0.1:6379&gt; exit</span><br><span class="line">➜ docker restart lredis</span><br><span class="line">lredis</span><br><span class="line">➜ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "e"</span><br><span class="line">   2) "d"</span><br><span class="line">   3) "b"</span><br><span class="line">   4) "c"</span><br><span class="line">   5) "a"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p><p>发现后面添加的<code>3</code>条记录并没有被保存，恢复数据的时候仅仅只是恢复了之前的<code>5</code>条。并且观察<code>Redis</code>服务端窗口日志，并未发现像之前一样的触发保存的提示，证明<code>RDB</code>方式已经被关闭;</p><p>通过配置文件关闭被动触发，那么主动关闭是否还会生效呢？</p><ol start="2"><li><strong><code>RDB</code>主动保存实践</strong><br>通过<code>del</code>命令删除几条记录，然后输入<code>save</code>命令执行保存操作,<br>input opt<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "e"</span><br><span class="line">   2) "d"</span><br><span class="line">   3) "b"</span><br><span class="line">   4) "c"</span><br><span class="line">   5) "a"</span><br><span class="line">127.0.0.1:6379&gt; del e d</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "b"</span><br><span class="line">   2) "c"</span><br><span class="line">   3) "a"</span><br><span class="line">127.0.0.1:6379&gt; save</span><br><span class="line">OK</span><br></pre></td></tr></table></figure></li></ol><p>log output<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1:M 24 Oct 2018 10:09:55.295 * Ready to accept connections</span><br><span class="line">1:M 24 Oct 2018 10:14:28.366 * DB saved on disk</span><br></pre></td></tr></table></figure></p><p>然后执行 <code>docker restart lredis</code>,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker restart lredis</span><br><span class="line">lredis</span><br><span class="line">➜  ~ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "a"</span><br><span class="line">   2) "c"</span><br><span class="line">   3) "b"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p><p>可以看到当<code>RDB</code>被动保存关闭后，可以通过主动<code>save</code>保存成功, 证明主动关闭不受 配置文件的影响;</p><p>除了save还有其他的保存方式么？</p><p><code>Redis</code>提供了<code>save</code>和<code>bgsave</code>这两种不同的保存方式, 并且这两个方式在执行的时候都会调用<code>rdbSave</code>函数，但它们调用的方式各有不同:</p><blockquote><p><code>save</code>直接调用<code>rdbSave</code>方法, 阻塞<code>Redis</code>主进程，直到保存完成为止。在主进程阻塞期间，服务器不能处理客户端的任何请求。</p></blockquote><blockquote><p><code>bgsave</code>则<code>fork</code>出一个子进程，子进程负责调用<code>rdbSave</code>，并在保存完成之后向主进程发送信号，通知保存已完成。因为<code>rdbSave</code>在子进程被调用，所以 <code>Redis</code>服务器在<code>bgsave</code>执行期间仍然可以继续处理客户端的请求。</p></blockquote><p>显然， <code>save</code>是同步操作, <code>bgsave</code>是异步操作。bgsave命令的使用方法和save命令的使用方法是一样的,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "a"</span><br><span class="line">   2) "c"</span><br><span class="line">   3) "b"</span><br><span class="line">127.0.0.1:6379&gt; set e 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set d 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; bgsave</span><br><span class="line">Background saving started</span><br></pre></td></tr></table></figure></p><p><code>redis</code>除了提供<code>save</code>和<code>bgsave</code>来保存数据外, 还可以通过<code>shutdown</code>命令来保存数据，不过要让<code>shutdown</code>保存数据生效需要打开持久化配置才行，即应将<code>redis.conf</code>中的配置从<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">save ""</span><br></pre></td></tr></table></figure></p><p>修改为如下，打开被动保存持久化配置才生效;<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure></p><p>总结<code>RDB</code>持久化有<code>被动保存</code>和<code>主动保存</code>两种方式，</p><blockquote><p>被动保存即通过<code>redis.conf</code>通过保存条件触发被动保存，这种情况数据有可能丢失;<br>主动保存即通过显示执行<code>save</code>, <code>bgsave</code>,<code>shutdown(在被动保存配置下才生效)</code>命令，这种情况数据不会丢失;</p></blockquote><h5 id="AOF方式持久化"><a href="#AOF方式持久化" class="headerlink" title="AOF方式持久化"></a>AOF方式持久化</h5><p><code>redis</code>默认没有开启<code>AOF</code>，需要修改redis.conf配置文件中开启,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 将appendonly改为 yes</span></span><br><span class="line">appendonly yes</span><br></pre></td></tr></table></figure></p><p><code>AOF</code>可以需要设置同步方式<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">appendfsync always  # 每次有数据修改发生时都会写入AOF文件（安全但是费时）。</span><br><span class="line">appendfsync everysec  # 每秒钟同步一次，该策略为AOF的缺省策略。</span><br><span class="line">appendfsync no  # 从不同步。高效但是数据不会被持久化。</span><br></pre></td></tr></table></figure></p><p>根据上面的设置重启<code>redis</code>后，可见<code>data</code>目录下已创建了<code>aof</code>空文件,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker exec -it lredis ls -lh /data</span><br><span class="line">total 4.0K</span><br><span class="line">-rw-r--r-- 1 redis redis   0 Oct 24 10:31 appendonly.aof</span><br><span class="line">-rw-r--r-- 1 redis redis 122 Oct 24 10:20 dump.rdb</span><br></pre></td></tr></table></figure></p><p>input<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; set name china</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set age 80</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set city "shanghai.china"</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "age"</span><br><span class="line">   2) "name"</span><br><span class="line">   3) "city"</span><br><span class="line">127.0.0.1:6379&gt; quit</span><br><span class="line">➜  ~ docker exec -it lredis cat /data/appendonly.aof</span><br><span class="line">*2</span><br><span class="line"><span class="meta">$</span><span class="bash">6</span></span><br><span class="line">SELECT</span><br><span class="line"><span class="meta">$</span><span class="bash">1</span></span><br><span class="line">0</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">name</span><br><span class="line"><span class="meta">$</span><span class="bash">5</span></span><br><span class="line">china</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">age</span><br><span class="line"><span class="meta">$</span><span class="bash">2</span></span><br><span class="line">80</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">city</span><br><span class="line"><span class="meta">$</span><span class="bash">14</span></span><br><span class="line">shanghai.china</span><br><span class="line">➜  ~ docker exec -it lredis ls -lh /data</span><br><span class="line">total 8.0K</span><br><span class="line">-rw-r--r-- 1 redis redis 131 Oct 24 10:35 appendonly.aof</span><br><span class="line">-rw-r--r-- 1 redis redis 122 Oct 24 10:20 dump.rdb</span><br></pre></td></tr></table></figure></p><p>由上可见, <code>appendonly.aof</code>文件由<code>0</code>增大到<code>131</code> bytes, 可见<code>AOF</code>方式持久化成功了， 可以看见<code>appendonly.aof</code>文件中不仅仅保存了设置的变量及值，这些变量及值前后还有一些特殊的符号，这正是根据<code>redis</code>采用的<code>RESP</code>文本协议生成的， 详情可见之前总结的 <a href="http://researchlab.github.io/2018/10/09/redis-12-resp/">redis专题12 redis通信协议</a><br>分析<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">14</span></span><br><span class="line">shanghai.china</span><br><span class="line">多字符用$开头， $后边紧跟字符串的长度, 然后是 \r\n, 然后是字符串值本身</span><br></pre></td></tr></table></figure></p><blockquote><p><code>AOF</code> 同样也会把<code>del</code>等执行命令保存到<code>AOF</code>文件中;</p></blockquote><blockquote><p>当关闭<code>RDB</code>持久化方式， 只打开<code>AOF</code>方式时， 显示执行<code>save</code>和<code>bgsave</code> 都会将当前数据同时保存到<code>AOF</code>文件和<code>RDB</code>文件中;</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">➜ docker exec -it lredis ls -lh /data</span><br><span class="line">total 0</span><br><span class="line">-rw-r--r-- 1 redis redis 0 Oct 24 10:55 appendonly.aof</span><br><span class="line">➜ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; set name china</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set age 80</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; quit</span><br><span class="line">➜ docker exec -it lredis ls -lh /data</span><br><span class="line">total 4.0K</span><br><span class="line">-rw-r--r-- 1 redis redis 87 Oct 24 10:55 appendonly.aof</span><br><span class="line">➜ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; set city shanghai</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; save</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; quit</span><br><span class="line">➜ docker exec -it lredis ls -lh /data</span><br><span class="line">total 8.0K</span><br><span class="line">-rw-r--r-- 1 redis redis 124 Oct 24 10:56 appendonly.aof</span><br><span class="line">-rw-r--r-- 1 redis redis 131 Oct 24 10:56 dump.rdb</span><br><span class="line">➜ docker exec -it lredis redis-cli</span><br><span class="line">127.0.0.1:6379&gt; set local library</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; bgsave</span><br><span class="line">Background saving started</span><br><span class="line">127.0.0.1:6379&gt; quit</span><br><span class="line">➜ docker exec -it lredis ls -lh /data</span><br><span class="line">total 8.0K</span><br><span class="line">-rw-r--r-- 1 redis redis 161 Oct 24 10:56 appendonly.aof</span><br><span class="line">-rw-r--r-- 1 redis redis 146 Oct 24 10:56 dump.rdb</span><br><span class="line">➜ docker exec -it lredis cat /data/appendonly.aof</span><br><span class="line">*2</span><br><span class="line"><span class="meta">$</span><span class="bash">6</span></span><br><span class="line">SELECT</span><br><span class="line"><span class="meta">$</span><span class="bash">1</span></span><br><span class="line">0</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">name</span><br><span class="line"><span class="meta">$</span><span class="bash">5</span></span><br><span class="line">china</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">age</span><br><span class="line"><span class="meta">$</span><span class="bash">2</span></span><br><span class="line">80</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">city</span><br><span class="line"><span class="meta">$</span><span class="bash">8</span></span><br><span class="line">shanghai</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">5</span></span><br><span class="line">local</span><br><span class="line"><span class="meta">$</span><span class="bash">7</span></span><br><span class="line">library</span><br></pre></td></tr></table></figure><p>从<code>RDB</code>方式切换到<code>AOF</code>方式<br>在<code>Redis2.2</code>或以上版本，可以在不重启的情况下，从<code>RDB</code>切换到<code>AOF</code>,<br>为最新的<code>dump.rdb</code>文件创建一个备份、将备份放到一个安全的地方。执行以下两条命令:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli config set appendonly yes</span><br><span class="line">redis-cli config set save “”</span><br></pre></td></tr></table></figure></p><blockquote><p>执行的第一条命令开启了<code>AOF</code>功能: <code>Redis</code>会阻塞直到初始<code>AOF</code>文件创建完成为止, 之后<code>Redis</code>会继续处理命令请求, 并开始将写入命令追加到<code>AOF</code>文件末尾;<br>通过上述<code>CONFIG SET</code>命令设置的配置， 在重启<code>redis</code>服务器之后将失效，重启会依然按照之前的配置启动，所以建议在<code>redis.conf</code>配置中也应同步修改;</p></blockquote><h5 id="备份建议"><a href="#备份建议" class="headerlink" title="备份建议"></a>备份建议</h5><p>确保你的数据有完整的备份，磁盘故障、节点失效等问题问题可能让你的数据消失不见， 不进行备份是非常危险的。<br><code>Redis</code>对于数据备份是非常友好的， 因为你可以在服务器运行的时候对<code>RDB</code>文件进行复制, RDB 文件一旦被创建, 就不会进行任何修改。 当服务器要创建一个新的<code>RDB</code>文件时，先将文件的内容保存在一个临时文件里面, 当临时文件写入完毕时, 程序才使用<code>rename(2)</code>原子地用临时文件替换原来的<code>RDB</code>文件。<br>即无论何时, 复制<code>RDB</code>文件都是绝对安全的。</p><blockquote><p>创建一个定期任务, 每小时将一个<code>RDB</code>文件备份到一个文件夹, 并且每天将一个<code>RDB</code>文件备份到另一个文件夹;</p></blockquote><blockquote><p>确保快照的备份都带有相应的日期和时间信息, 每次执行定期任务脚本时, 使用 find 命令来删除过期的快照, 比如保留最近<code>48</code>小时内的每小时快照, 还可以保留最近一两个月的每日快照;</p></blockquote><blockquote><p>至少每天一次, 将<code>RDB</code> 备份到你的数据中心之外, 或者至少是备份到你运行<code>Redis</code>服务器的物理机器之外;</p></blockquote><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>为实践<code>redis</code>持久化机制，创建了<code>docker</code>容器环境;</li><li>针对<code>RDB</code>方式持久化，分别测试了其主动保存和被动保存机制， 被动保存存在丢数据的可能，而主动保存则不会， 被动保存通过配置触发保存条件实现, 主动保存主要通过显示执行<code>save</code>,<code>bgsave</code>,<code>shutdown(需开启被动保存)</code>来执行数据保存操作;</li><li>针对<code>AOF</code>方式持久化进行了实例分析测试，<code>AOF</code> 开启后自动保存操作记录到<code>AOF</code>文件， 当显示执行<code>save</code>, <code>bgsave</code>,<code>shutdown</code>操作时也会自动保存数据到<code>AOF</code>和<code>RDB</code>文件中；</li><li>探讨了在不停服情况下从<code>RDB</code>方式切换至<code>AOF</code>的方法，并给出了几点备份建议;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;通过示例分析，深入了解&lt;code&gt;redis&lt;/code&gt;数据持久化策略执行机制；&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题15 事务系列问题</title>
    <link href="http://researchlab.github.io/2018/10/12/redis-15-transaction/"/>
    <id>http://researchlab.github.io/2018/10/12/redis-15-transaction/</id>
    <published>2018-10-12T15:39:41.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p>为了确保连续多个操作的原子性, 一个成熟的数据库通常都会有事务支持, <code>Redis</code> 也不例外, <code>Redis</code> 通过<code>MULTI</code>, <code>DISCARD</code>, <code>EXEC</code>, <code>WATCH</code>和<code>UNWATCH</code> 五个命令来实现事务功能;<br><a id="more"></a></p><h5 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h5><p>事务提供了一种”将多个命令打包， 然后一次性、按顺序地执行”的机制, 并且事务在执行的期间不会主动中断 —— 服务器在执行完事务中的所有命令之后, 才会继续处理其他客户端的其他命令。</p><h5 id="Redis事务"><a href="#Redis事务" class="headerlink" title="Redis事务"></a><code>Redis</code>事务</h5><p>一个基本<code>Redis</code>事务从MULIT命令开始一个事务, 然后将多个命令入队到事务中， 最后由<code>EXEC</code>命令触发事务,</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; `MULTI`</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set name mike</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; incr name</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; set city shanghai</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; get city</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; `EXEC`</span><br><span class="line">1) OK</span><br><span class="line">2) (error) ERR value is not an integer or out of range</span><br><span class="line">3) OK</span><br><span class="line">4) "mike"</span><br><span class="line">5) "shanghai"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><ul><li><code>MULTI</code>命令唯一做的就是, 将客户端的 <code>Redis</code>_<code>MULTI</code> 选项打开, 让客户端从非事务状态切换到事务状态;</li><li>当客户端处于非事务状态下时， 所有发送给服务器端的命令都会立即被服务器执行; 当客户端进入事务状态之后, 服务器在收到来自客户端的命令时, 不会立即执行命令, 而是将这些命令全部放进一个事务队列里, 然后返回QUEUED, 表示命令已入队;</li><li>事务队列里的所有命令被执行完之后, <code>EXEC</code>命令会将回复队列作为自己的执行结果返回给客户端, 客户端从事务状态返回到非事务状态, 事务执行完毕;</li><li>从上述示例中可得当<code>incr name</code>失败后, 依然继续执行后继的<code>set city</code>等命令，可见<code>Redis</code>事务不保证执行<code>原子性</code>操作, 仅满足<code>隔离性</code>执行;</li></ul><p>事务与非事务状态的区别<br>事务中的命令和普通命令在执行上还是有一点区别的，其中最重要的两点是：</p><blockquote><p>非事务状态下的命令以单个命令为单位执行，前一个命令和后一个命令的客户端不一定是同一个; 而事务状态则是以一个事务为单位，执行事务队列中的所有命令:除非当前事务执行完毕，否则服务器不会中断事务，也不会执行其他客户端的其他命令;</p></blockquote><blockquote><p>在非事务状态下, 执行命令所得的结果会立即被返回给客户端; 而事务则是将所有命令的结果集合到回复队列，再作为<code>EXEC</code>命令的结果返回给客户端;</p></blockquote><ul><li>并不是所有的命令都会被放进事务队列, 其中的例外就是<code>EXEC</code>, <code>DISCARD</code>, <code>MULTI</code>和<code>WATCH</code>及<code>UNWATCH</code>命令;</li></ul><blockquote><p><code>DISCARD</code> 命令用于取消一个事务, 它清空客户端的整个事务队列, 然后将客户端从事务状态调整回非事务状态, 最后返回字符串OK给客户端, 说明事务已被取消;</p></blockquote><blockquote><p><code>Redis</code>的事务是不可嵌套的, 当客户端已经处于事务状态, 而客户端又再向服务器发送<code>MULTI</code>时, 服务器只是简单地向客户端发送一个错误, 然后继续等待其他命令的入队; <code>MULTI</code>命令的发送不会造成整个事务失败, 也不会修改事务队列中已有的数据;</p></blockquote><blockquote><p><code>WATCH</code>只能在客户端进入事务状态之前执行, 在事务状态下发送 <code>WATCH</code> 命令会引发一个错误, 但它不会造成整个事务失败, 也不会修改事务队列中已有的数据(和前面处理 <code>MULTI</code> 的情况一样);</p></blockquote><blockquote><p><code>WATCH</code>命令用于在事务开始之前监视任意数量的键, 当调用<code>EXEC</code>命令执行事务时, 如果任意一个被监视的键已经被其他客户端修改了, 那么整个事务不再执行, 直接返回失败;</p></blockquote><h5 id="与MySQL事务的区别"><a href="#与MySQL事务的区别" class="headerlink" title="与MySQL事务的区别"></a>与<code>MySQL</code>事务的区别</h5><p>在<code>MySQL</code>中只有使用了Innodb数据库引擎的数据库或表才支持事务;</p><blockquote><p>事务使用的目的是统一管理insert, update, delete 这些write操作，以此来维护数据完整性。</p></blockquote><p><strong>命令区别</strong><br><code>MySQL</code></p><blockquote><p><code>BEGIN</code>: 显式地开启一个事务;<br><code>COMMIT</code>: 提交事务，将对数据库进行的所有修改变成为永久性的;<br><code>ROLLBACK</code>: 结束用户的事务，并撤销正在进行的所有未提交的修改;</p></blockquote><p><code>Redis</code></p><blockquote><p><code>MULTI</code>: 标记事务的开始;<br><code>EXEC</code>: 执行事务的commands队列;<br><code>DISCARD</code>: 结束事务，并清除commands队列;</p></blockquote><p><strong>默认状态</strong><br><code>MySQL</code></p><blockquote><p><code>MySQL</code>会默认开启一个事务，且缺省设置是自动提交，即，每成功执行一个SQL，一个事务就会马上 <code>COMMIT</code>。所以不能<code>ROLLBACK</code>。</p></blockquote><p><code>Redis</code></p><blockquote><p><code>Redis</code>默认不会开启事务，即command会立即执行，而不会排队。并不支持<code>ROLLBACK</code></p></blockquote><p><strong>使用方式</strong><br><code>MySQL</code>包含两种</p><blockquote><p>用<code>BEGIN</code>, <code>ROLLBACK</code>, <code>COMMIT</code> 显式开启并控制一个 <code>新的</code> Transaction。<br>执行命令<code>SET AUTOCOMMIT=0</code>, 用来禁止当前会话自动<code>COMMIT</code>, 控制默认开启的事务。</p></blockquote><p><code>Redis</code></p><blockquote><p>用<code>MULTI</code>, <code>EXEC</code>, <code>DISCARD</code>, 显式开启并控制一个<code>Transaction</code>(注意这里没有强调<code>新的</code>, 因为默认是不会开启事务的);</p></blockquote><p><strong>实现原理</strong><br>显然<code>Redis</code>与<code>MySQL</code>中事务的区别其根本原因就是实现不同方式造成的;</p><p><code>MySQL</code></p><blockquote><p><code>MySQL</code>实现事务，是基于<code>UNDO/REDO</code>日志;<br><code>UNDO日志</code>记录修改前状态, <code>ROLLBACK</code>基于<code>UNDO日志</code>实现;<br><code>REDO日志</code>记录修改后的状态, <code>COMMIT</code>基于<code>REDO日志</code>实现;<br>在<code>MySQL</code>中无论是否开启事务, 每一个<code>SQL</code>都会被立即执行并返回执行结果。但是事务开启后执行后的状态只是记录在<code>REDO日志</code>, 执行<code>COMMIT</code>, 数据才会被写入磁盘。</p></blockquote><p><code>Redis</code></p><blockquote><p><code>Redis</code>实现事务, 是基于<code>COMMANDS</code>队列;<br>如果没有开启事务, <code>command</code>将会被立即执行并返回执行结果, 并且直接写入磁盘;<br>如果事务开启, <code>command</code>不会被立即执行, 而是排入队列并返回排队状态。调用<code>EXCE</code>才会执行<code>COMMANDS</code>队列;</p></blockquote><h5 id="不支持回滚"><a href="#不支持回滚" class="headerlink" title="不支持回滚"></a>不支持回滚</h5><p><code>Redis</code>事务不支持回滚, 官方解释, </p><blockquote><p><code>Redis</code>命令只会因为错误的语法而失败(并且这些问题不能在入队时发现), 或是命令用在了错误类型的键上面; 从实用性的角度来说, 失败的命令是由编程错误造成的, 而这些错误应该在开发的过程中被发现, 而不应该出现在生产环境中;<br>因为不需要对回滚进行支持，所以<code>Redis</code>的内部可以保持简单且快速;</p></blockquote><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>事务提供了一种将多个命令打包, 然后一次性, 有序地执行的机制; 且在执行过程中不会被中断, 所有事务命令执行完之后, 事务才能结束;</li><li>多个命令会被入队到事务队列中，然后按先进先出（FIFO）的顺序执行;</li><li><code>Redis</code>事务仅保证了事务的隔离执行; 不保证原子性：<code>Redis</code>同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚;</li><li>可以通过管道技术对事务进行优化;</li><li>通过<code>WATCH</code>命令在事务执行之前监控了多个Keys，倘若在<code>WATCH</code>之后有任何Key的值发生了变化，<code>EXEC</code>命令执行的事务都将被放弃，同时返回Null<code>MULTI</code>-bulk应答以通知调用者事务执行失败</li><li>悲观锁(Pessimistic Lock), 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁;</li><li>乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改, 所以不会上锁, 但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，乐观锁策略:提交版本必须大于记录当前版本才能执行更新;</li><li>对比分析了<code>Redis</code>事务与<code>MySQL</code>事务的异同点;</li><li>从官方解释中阐述为何<code>Redis</code>事务没有必要支持回滚机制;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;为了确保连续多个操作的原子性, 一个成熟的数据库通常都会有事务支持, &lt;code&gt;Redis&lt;/code&gt; 也不例外, &lt;code&gt;Redis&lt;/code&gt; 通过&lt;code&gt;MULTI&lt;/code&gt;, &lt;code&gt;DISCARD&lt;/code&gt;, &lt;code&gt;EXEC&lt;/code&gt;, &lt;code&gt;WATCH&lt;/code&gt;和&lt;code&gt;UNWATCH&lt;/code&gt; 五个命令来实现事务功能;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题14 性能提升之管道技术</title>
    <link href="http://researchlab.github.io/2018/10/11/redis-14-pipeline/"/>
    <id>http://researchlab.github.io/2018/10/11/redis-14-pipeline/</id>
    <published>2018-10-11T15:37:51.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p>用<code>redis管道技术</code>对执行结果没有互相依赖，对结果响应也无需立即获得的命令集批量提交到<code>redis</code>服务器的方式，能在一定程度上提升<code>redis</code>性能，性能提升的原因主要是TCP连接中减少了<code>交互往返</code>的时间。<br><a id="more"></a></p><blockquote><p><code>Redis管道(Pipeline)</code>本身并不是<code>Redis</code>服务器直接提供的技术，这个技术本质上是由客户端提供的，跟服务器没有什么直接的关系。</p></blockquote><h5 id="消息交互"><a href="#消息交互" class="headerlink" title="消息交互"></a>消息交互</h5><p><code>redis</code>是使用客户端-服务器模型的TCP服务器，称为请求/响应协议。<br>这意味着通常一个请求是通过以下步骤完成的:</p><blockquote><p>客户端向服务器发送查询，并通常以阻塞的方式从套接字读取服务器响应。<br>服务器处理命令并将响应发送回客户端。</p></blockquote><p>每一个<code>redis</code>命令request/response都需要经历一个<code>RTT</code>(Round-Trip Time 往返时间), 如果需要执行很多短小的命令，这些往返时间的开销是很大的，在此情形下，redis提出了<code>管道</code>来提高执行效率。</p><h5 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h5><blockquote><p>如果client执行一些相互之间无关的命令或者不需要获取命令的返回值，那么redis允许你连续发送多条命令，而不需要等待前面命令执行完毕;</p></blockquote><blockquote><p>比如我们执行3条INCR命令，如果使用管道，理论上只需要一个RTT+3条命令的执行时间即可，如果不适用管道，那么可能需要额外的两个RTT时间;</p></blockquote><blockquote><p>因此，管道相当于批处理脚本，相当于是命令集;</p></blockquote><blockquote><p>执行管道命令中, <code>redis</code>必须在处理完所有命令前先缓存起所有命令的处理结果。打包的命令越多，缓存消耗内存也越多。所以并不是打包的命令越多越好。具体多少合适需要根据具体情况测试。</p></blockquote><p><strong>注意</strong></p><blockquote><p>执行<code>管道</code>命令期间将<code>独占</code>链接，此期间将不能进行非<code>管道</code>类型的其他操作，直到管道关闭；</p></blockquote><blockquote><p>如果<code>管道</code>的指令集很庞大，为了不干扰链接中的其他操作，建议为<code>管道</code>操作新建Client链接，让<code>管道</code>和其他正常操作分离在2个client中; </p></blockquote><blockquote><p>不过<code>管道</code>事实上所能容忍的操作个数，和socket-output缓冲区大小/返回结果的数据尺寸都有很大的关系；同时也意味着每个redis-server同时所能支撑的管道链接的个数，也是有限的，这将受限于server的物理内存或网络接口的缓冲能力。</p></blockquote><h5 id="压力测试"><a href="#压力测试" class="headerlink" title="压力测试"></a>压力测试</h5><p>Redis 自带了一个压力测试工具redis-benchmark，使用这个工具就可以进行管道测试。</p><p>对一个普通的<code>set</code>指令进行压测，QPS 大约<code>6w/s</code>。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  02 docker exec -it redisbloom redis-benchmark -t set -q</span><br><span class="line">SET: 64350.06 requests per second</span><br></pre></td></tr></table></figure></p><p><code>-P</code>参数，表示单个管道内并行的请求数量，看下面<code>P=2</code>，QPS 达到了<code>8w/s</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it redisbloom redis-benchmark -t set -q -P 2</span><br><span class="line">SET: 89365.51 requests per second</span><br></pre></td></tr></table></figure><p>再看看<code>P=5</code>，<code>QPS</code>达到了<code>10w/s</code>。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  02 docker exec -it redisbloom redis-benchmark -t set -q -P 5</span><br><span class="line">SET: 106723.59 requests per second</span><br></pre></td></tr></table></figure></p><p>但如果再继续提升<code>P</code>参数，发现<code>QPS</code>已经上不去了。这是为什么呢？</p><p>因为这里<code>CPU</code>处理能力已经达到了瓶颈，<code>Redis</code>的单线程<code>CPU</code>已经飙到了<code>100%</code>，所以无法再继续提升了。</p><p>深入理解管道本质<br>接下来我们深入分析一个请求交互的流程，真实的情况是它很复杂，因为要经过网络协议栈，这个就得深入内核了。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">client ---&gt; request  ---&gt; send buffer ---&gt; NIC ---&gt; Gateway Router ---&gt; NIC ---&gt; recv buffer ---&gt; request  ---&gt; server </span><br><span class="line">                                                                                                                 |</span><br><span class="line">client &lt;--- response &lt;--- recv buffer &lt;--- NIC &lt;--- Gateway Router &lt;--- NIC &lt;--- send buffer &lt;--- response &lt;---  V</span><br></pre></td></tr></table></figure></p><p>上图就是一个完整的请求交互流程图,</p><ol><li>客户端进程调用<code>write</code>将消息写到操作系统内核为套接字分配的发送缓冲<code>send buffer</code>;</li><li>客户端操作系统内核将发送缓冲的内容发送到<code>网卡</code>，<code>网卡</code>硬件将数据通过「路由」送到服务器的<code>网卡</code>;</li><li>服务器操作系统内核将<code>网卡</code>的数据放到内核为套接字分配的接收缓冲<code>recv buffer</code>;</li><li>服务器进程调用<code>read</code>从接收缓冲中取出消息进行处理;</li><li>服务器进程调用<code>write</code>将响应消息写到内核为套接字分配的发送缓冲<code>send buffer</code>;</li><li>服务器操作系统内核将发送缓冲的内容发送到<code>网卡</code>，<code>网卡</code>硬件将数据通过「路由」送到客户端的<code>网卡</code>。</li><li>客户端操作系统内核将<code>网卡</code>的数据放到内核为套接字分配的接收缓冲<code>recv buffer</code>;</li><li>客户端进程调用<code>read</code>从接收缓冲中取出消息返回给上层业务逻辑进行处理;</li></ol><blockquote><p><code>write</code>操作不是等到对方收到消息才会返回。<code>write</code>操作只负责将数据写到本地操作系统内核的发送缓冲然后就返回了。剩下的事交给操作系统内核异步将数据送到目标机器。但是如果发送缓冲满了，那么就需要等待缓冲空出空闲空间来，这个就是写操作<code>IO</code>操作的真正耗时。</p></blockquote><blockquote><p><code>read</code>操作不是从目标机器拉取数据。<code>read</code>操作只负责将数据从本地操作系统内核的接收缓冲中取出来就了事了。但是如果缓冲是空的，那么就需要等待数据到来，这个就是读操作<code>IO</code>操作的真正耗时。</p></blockquote><p>所以对于<code>value = redis.get(key)</code>这样一个简单的请求来说，<code>write</code>操作几乎没有耗时，直接写到发送缓冲就返回，而<code>read</code>就会比较耗时了，因为它要等待消息经过网络路由到目标机器处理后的响应消息,再回送到当前的内核读缓冲才可以返回。这才是一个网络来回的真正开销。</p><p>而对于管道来说，连续的<code>write</code>操作根本就没有耗时，之后第一个<code>read</code>操作会等待一个网络的来回开销，然后所有的响应消息就都已经回送到内核的读缓冲了，后续的<code>read</code>操作直接就可以从缓冲拿到结果，瞬间就返回了。</p><h5 id="管道VS事务"><a href="#管道VS事务" class="headerlink" title="管道VS事务"></a>管道VS事务</h5><blockquote><p>管道和事务是不同的，pipeline只是表达”交互”中操作的传递的方向性，pipeline也可以在事务中运行，也可以不在。</p></blockquote><blockquote><p>无论如何，pipeline中发送的每个command都会被server立即执行，如果执行失败，将会在此后的相应结果集中得到信息；也就是pipeline并不是表达”所有command都一起成功”的语义，管道中前面命令失败，后面命令不会有影响，继续执行。</p></blockquote><blockquote><p>简单来说就是管道中的命令是没有关系的，它们只是像管道一样流水发给server，而不是串行执行，仅此而已; 但是如果pipeline的操作被封装在事务中，那么将有事务来确保操作的成功与失败。</p></blockquote><blockquote><p>pipeline 只是把多个redis指令一起发出去，redis并没有保证这些指定的执行是原子的；multi相当于一个redis的transaction的，保证整个操作的原子性，避免由于中途出错而导致最后产生的数据不一致</p></blockquote><h5 id="管道VS脚本"><a href="#管道VS脚本" class="headerlink" title="管道VS脚本"></a>管道VS脚本</h5><blockquote><p>使用管道可能在效率上比使用script要好，但是有的情况下只能使用script。因为在执行后面的命令时, 无法得到前面命令的结果，就像事务一样，所以如果需要在后面命令中使用前面命令的value等结果，则只能使用script或者事务+watch;</p></blockquote><blockquote><p>使用Redis脚本(在Redis版本2.6+), 可以使用执行服务器端所需的大量工作的脚本更高效地处理一些pipelining用例;</p></blockquote><blockquote><p>脚本的一大优势是它能够以最小的延迟读取和写入数据，使得读取，计算，写入等操作非常快速(在这种情况下, 流水线操作无法提供帮助, 因为客户端先需要读命令的回应, 它才可以调用写命令);</p></blockquote><blockquote><p>有时，应用程序可能还想在管道中发送<code>EVAL</code>或<code>EVALSHA</code>命令。这是完全可能的，Redis通过SCRIPT LOAD命令明确地支持它(它保证可以调用EVALSHA而没有失败的风险);</p></blockquote><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>从分析<code>redis</code>采用<code>tcp</code>消息协议入手, 为进一步提升<code>redis</code>性能的角度，探讨了<code>管道</code>技术在<code>redis</code>中的应用;  </li><li>进一步分析了管道的原理, 因为<code>redis</code>需要在处理完管道命令集前把之前的结果先缓存下来，所以管道并不是打包的命令越多越好，因为打包的命令越多占用的缓存也会相应的增大, 同时在执行管道命令完成前, 同一个<code>redis</code>连接无法继续执行非管道命令;</li><li>通过消息交互示例， 进一步深入分析了管道的本质，管道打包多条命令为客服端–服务端节省了往返(RTT)等待耗时, 因而进一步提升了<code>redis</code>性能;</li><li>最后对比分析了<code>管道</code>与<code>redis事务</code>, <code>redis脚本</code>之间的区别， 进一步阐述了<code>管道</code>，<code>事务</code>, <code>脚本</code>各自适用的场景;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;用&lt;code&gt;redis管道技术&lt;/code&gt;对执行结果没有互相依赖，对结果响应也无需立即获得的命令集批量提交到&lt;code&gt;redis&lt;/code&gt;服务器的方式，能在一定程度上提升&lt;code&gt;redis&lt;/code&gt;性能，性能提升的原因主要是TCP连接中减少了&lt;code&gt;交互往返&lt;/code&gt;的时间。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题13 数据存储与持久化</title>
    <link href="http://researchlab.github.io/2018/10/10/redis-13-data-storage-solution/"/>
    <id>http://researchlab.github.io/2018/10/10/redis-13-data-storage-solution/</id>
    <published>2018-10-10T12:36:10.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p><code>redis</code>提供两种方式进行持久化，一种是<code>RDB</code>快照持久化(原理是将Reids在内存中的数据库记录压缩后定时dump到磁盘上的<code>RDB</code>持久化,存储紧凑)，另外一种是<code>AOF</code>(append only file)持久化(原理是将Reids的操作日志以追加的方式写入文件), <code>AOF</code> 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载<code>AOF</code>日志进行指令重放，这个时间就会无比漫长。所以需要定期进行<code>AOF</code>重写，给<code>AOF</code>日志进行瘦身。<br><a id="more"></a></p><h4 id="RDB快照原理"><a href="#RDB快照原理" class="headerlink" title="RDB快照原理"></a><code>RDB</code>快照原理</h4><p><code>RDB</code>(快照/内存快照)，就是<code>redis</code>按照一定的时间周期将目前服务中的所有数据全部写入到磁盘中。<br>我们知道<code>redis</code>是单线程程序，这个线程要同时负责多个客户端套接字的并发读写操作和内存数据结构的逻辑读写。</p><p>在服务线上请求的同时，<code>redis</code> 还需要进行内存快照，内存快照要求<code>redis</code> 必须进行文件IO操作，可<strong>文件IO操作是不能使用多路复用API</strong>。那该怎么办呢？</p><p><code>redis</code>使用操作系统的多进程<code>COW(Copy On Write) 机制</code>来实现快照持久化。</p><p><code>redis</code> 在持久化时会<code>fork</code>一个子进程，<strong>快照持久化完全交给子进程来处理，父进程继续处理客户端请求</strong>。子进程做数据持久化，它不会修改现有的内存数据结构，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。但是父进程不一样，它必须持续服务客户端请求，然后对内存数据结构进行不间断的修改。</p><p>这个时候就会使用操作系统的<code>COW机制</code>来进行数据段页面的分离。数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改。这时子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据。</p><p>随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，内存就会持续增长。但是也不会超过原有数据内存的<code>2</code>倍大小。另外一个<code>redis</code>实例里冷数据占的比例往往是比较高的，所以很少会出现所有的页面都会被分离，被分离的往往只有其中一部分页面。每个页面的大小只有<code>4K</code>，一个 <code>redis</code>实例里面一般都会有成千上万的页面。<br>原理过程<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">0.假设现在redis数据存储在内存的A区;</span><br><span class="line">1.此时因配置或某种原因触发了RDB快照事件;</span><br><span class="line">2.触发RDB快照事件后，父进程会先fork出一个子进程, 把处理RDB快照的事情完全交给这个子进程处理，而父进程则继续处理来自客服端的请求;</span><br><span class="line">3.子进程会先将当前内存A区数据压缩, 然后dump刷盘到一个临时RDB文件中, 当dump完成后，再将这个临时RDB文件替换之前的RDB文件, 然后子进程结束退出;</span><br><span class="line">4.同样，在子进程处理快照dump过程中, 如果父进程接收到新的客服端请求，则父进程需要先拷贝一份内存A区中相关数据页的信息到内存B区，然后在B区上完成客服端的请求; </span><br><span class="line">5.当父进程完成新的客服端请求后，发现子进程已经完成了RDB快照处理， 则将刚才更新的B区数据取替换A区数据, 如果子进程还没有完成则等待;</span><br></pre></td></tr></table></figure></p><h5 id="AOF-原理"><a href="#AOF-原理" class="headerlink" title="AOF 原理"></a><code>AOF</code> 原理</h5><p><code>AOF</code>日志存储的是<code>redis</code>服务器的顺序指令序列，<code>AOF</code>日志<strong>只记录对内存进行修改的指令记录(查询/删除指令是不记录的)</strong>。<br>假设 <code>AOF</code> 日志记录了自<code>redis</code>实例创建以来所有的修改性指令序列，那么就可以通过对一个空的<code>redis</code> 实例顺序执行所有的指令，也就是「重放」，来恢复<code>redis</code>当前实例的内存数据结构的状态。</p><p><code>redis</code>会在收到客户端修改指令后，进行参数校验进行逻辑处理后，如果没问题，就立即将该指令文本存储到<code>AOF</code>日志中，也就是先执行指令才将日志存盘。这点不同于<code>leveldb、hbase</code>等存储引擎，它们都是先存储日志再做逻辑处理。</p><p><code>redis</code> 在长期运行的过程中，<code>AOF</code> 的日志会越变越长。如果实例宕机重启，重放整个 <code>AOF</code> 日志会非常耗时，导致长时间<code>redis</code>无法对外提供服务。所以需要对 <code>AOF</code> 日志瘦身。</p><p><strong>AOF重写</strong><br><code>redis</code> 提供了<code>bgrewrite AOF</code>指令用于对 <code>AOF</code> 日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历转换成一系列 <code>redis</code> 的操作指令，序列化到一个新的 <code>AOF</code> 日志文件中。序列化完毕后再将操作期间发生的增量 <code>AOF</code> 日志追加到这个新的 <code>AOF</code> 日志文件中，追加完毕后就立即替代旧的 <code>AOF</code> 日志文件了，瘦身工作就完成了。</p><p><strong>fsync</strong><br><code>AOF</code> 日志是以文件的形式存在的，当程序对 <code>AOF</code> 日志文件进行写操作时，实际上是将内容写到了内核为文件描述符分配的一个内存缓存中，然后内核会异步将脏数据刷回到磁盘的。</p><p>这就意味着如果机器突然宕机，<code>AOF</code> 日志内容可能还没有来得及完全刷到磁盘中，这个时候就会出现日志丢失。那该怎么办？ 可以通过开启<code>fsync</code>配置来强制同步刷盘, 过于频繁的<code>fsync</code>会严重拖慢<code>redis</code>性能，所以在生产环境的服务器中，<code>redis</code> 通常是每隔<code>1s</code>左右执行一次<code>fsync</code>操作, 在保持高性能的同时，尽可能使得数据少丢失。</p><h5 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h5><p>重启 <code>redis</code> 时，我们很少使用 <code>RDB</code> 来恢复内存状态，因为会丢失大量数据。我们通常使用 <code>AOF</code> 日志重放，但是重放 <code>AOF</code> 日志性能相对 <code>RDB</code> 来说要慢很多，这样在<code>redis</code> 实例很大的情况下，启动需要花费很长的时间。</p><p><code>redis4.0</code>为了解决这个问题，带来了一个新的持久化选项——混合持久化。将 <code>RDB</code> 文件的内容和增量的 <code>AOF</code> 日志文件存在一起。这里的 <code>AOF</code> 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 <code>AOF</code> 日志，通常这部分 <code>AOF</code> 日志很小。</p><p>于是在<code>redis</code> 重启的时候，可以先加载 <code>RDB</code> 的内容，然后再重放增量 <code>AOF</code> 日志就可以完全替代之前的 <code>AOF</code> 全量文件重放，重启效率因此大幅得到提升。</p><h5 id="RDB优势"><a href="#RDB优势" class="headerlink" title="RDB优势"></a>RDB优势</h5><blockquote><p> 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。</p></blockquote><blockquote><p>对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。</p></blockquote><blockquote><p> 性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。</p></blockquote><blockquote><p> 相比于AOF机制，如果数据集很大，RDB的启动效率会更高。</p></blockquote><h5 id="RDB劣势"><a href="#RDB劣势" class="headerlink" title="RDB劣势"></a>RDB劣势</h5><blockquote><p>如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。</p></blockquote><blockquote><p>由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。</p></blockquote><h4 id="AOF优势"><a href="#AOF优势" class="headerlink" title="AOF优势"></a>AOF优势</h4><blockquote><p>该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言，我想大家都能正确的理解它。</p></blockquote><blockquote><p>由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。</p></blockquote><blockquote><p> 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。</p></blockquote><blockquote><p>AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。</p></blockquote><h5 id="AOF劣势"><a href="#AOF劣势" class="headerlink" title="AOF劣势"></a>AOF劣势</h5><blockquote><p> 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</p></blockquote><blockquote><p>根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。</p></blockquote><h5 id="常用配置"><a href="#常用配置" class="headerlink" title="常用配置"></a>常用配置</h5><p><strong>RDB持久化配置</strong><br>Redis会将数据集的快照dump到dump.rdb文件中。此外，我们也可以通过配置文件来修改Redis服务器dump快照的频率，在打开6379.conf文件之后，我们搜索save，可以看到下面的配置信息:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">save 900 1              #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。</span><br><span class="line"></span><br><span class="line">save 300 10            #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。</span><br><span class="line"></span><br><span class="line">save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。</span><br></pre></td></tr></table></figure></p><p><strong>AOF持久化配置</strong><br>在Redis的配置文件中存在三种同步方式，它们分别是:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">appendfsync always     #每次有数据修改发生时都会写入AOF文件。</span><br><span class="line"></span><br><span class="line">appendfsync everysec  #每秒钟同步一次，该策略为AOF的缺省策略。</span><br><span class="line"></span><br><span class="line">appendfsync no          #从不同步。高效但是数据不会被持久化。</span><br></pre></td></tr></table></figure></p><h5 id="过期策略"><a href="#过期策略" class="headerlink" title="过期策略"></a>过期策略</h5><p><strong>RDB过期key处理策略</strong></p><blockquote><p>已过期的键不会被保存到新创建的RDB文件中。举个例子，如果数据库中包含三个键k1、k2、k3，并且k2已经过期，那么当执行SAVE命令或者BGSAVE命令时，程序只会将k1和k3的数据保存到RDB文件中，而k2则会被忽略。因此，数据库中包含过期键不会对生成新的RDB文件造成影响。</p></blockquote><p>在启动Redis服务器时，如果服务器开启了RDB功能，那么服务器将对RDB文件进行载入:</p><blockquote><p>如果服务器以主服务器模式运行，那么在载入RDB文件时，程序会对文件中保存的键进行检查，未过期的键会被载入到数据库中，而过期键则会被忽略，所以过期键对载入RDB文件的主服务器不会造成影响；</p></blockquote><blockquote><p>如果服务器以从服务器模式运行，那么在载入RDB文件时，文件中保存的所有键，不论是否过期，都会被载入到数据库中。不过，因为主从服务器在进行数据同步的时候，从服务器的数据库就会被清空，所以一般来讲，过期键对载入RDB文件的从服务器也不会造成影响；</p></blockquote><p><strong>AOF过期key处理策略</strong></p><blockquote><p>当服务器以AOF持久化模式运行时，如果数据库中的某个键已经过期，但它还没有被惰性删除或者定期删除，那么AOF文件不会因为这个过期键而产生任何影响。<strong>当过期键被惰性删除或者定期删除之后，程序会向AOF文件追加（append）一条DEL命令，来显式地记录该键已被删除。</strong></p></blockquote><blockquote><p>和生成RDB文件时类似，在执行AOF重写的过程中，程序会对数据库中的键进行检查，已过期的键不会被保存到重写后的AOF文件中。举个例子，如果数据库中包含三个键k1、k2、k3，并且k2已经过期，那么在进行重写工作时，程序只会对k1和k3进行重写，而k2则会被忽略。</p></blockquote><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>在<code>redis</code>数据存储持久化机制上, 探讨了<code>RDB快照</code> 和 <code>AOF</code>两种持久化方案，对其原理,区别等进行了进一步的说明;</li><li>进一步探讨了<code>redis.4.0</code>提供的混合持久化方案;</li><li>归类总结了<code>RDB</code>和<code>AOF</code>两种方案的优缺点;</li><li>从经验出发， 进一步总结了实际中常用的配置方案;</li><li>进一步总结了<code>RDB</code>和<code>AOF</code>对过期key的处理策略;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;redis&lt;/code&gt;提供两种方式进行持久化，一种是&lt;code&gt;RDB&lt;/code&gt;快照持久化(原理是将Reids在内存中的数据库记录压缩后定时dump到磁盘上的&lt;code&gt;RDB&lt;/code&gt;持久化,存储紧凑)，另外一种是&lt;code&gt;AOF&lt;/code&gt;(append only file)持久化(原理是将Reids的操作日志以追加的方式写入文件), &lt;code&gt;AOF&lt;/code&gt; 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载&lt;code&gt;AOF&lt;/code&gt;日志进行指令重放，这个时间就会无比漫长。所以需要定期进行&lt;code&gt;AOF&lt;/code&gt;重写，给&lt;code&gt;AOF&lt;/code&gt;日志进行瘦身。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题12 redis通信协议</title>
    <link href="http://researchlab.github.io/2018/10/09/redis-12-resp/"/>
    <id>http://researchlab.github.io/2018/10/09/redis-12-resp/</id>
    <published>2018-10-09T15:34:03.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p>Redis的客户端与服务端采用一种叫做<code>RESP(REdis Serialization Protocol)</code>的网络通信协议交换数据。 这种协议采用明文传输，易读也易解析。<code>Redis</code>客户端采用此协议格式来对服务端发送不同的命令，服务端会根据具体的操作而返回具体的答复。客户端和服务端采用的是简单的<code>请求-响应</code>模型进行通信的。<br><a id="more"></a></p><h5 id="RESP"><a href="#RESP" class="headerlink" title="RESP"></a>RESP</h5><p><code>RESP(Redis Serialization Protocol)</code>是 Redis序列化协议的简写。它是一种直观的文本协议，优势在于实现异常简单，解析性能极好。</p><p>Redis协议将传输的结构数据分为<code>5</code>种最小单元类型，单元结束时统一加上回车换行符号<code>\r\n</code>。</p><blockquote><p>单行字符串 以<code>+</code>符号开头。<br>多行字符串 以<code>$</code>符号开头，后跟字符串长度。<br>整数值 以<code>:</code>符号开头，后跟整数的字符串形式。<br>错误消息 以<code>-</code>符号开头。<br>数组 以<code>*</code>号开头，后跟数组的长度。</p></blockquote><p><strong>单行字符串</strong> <code>hello world</code><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">+hello world\r\n</span><br></pre></td></tr></table></figure></p><p><strong>多行字符串</strong> <code>hello world</code><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">11\r\nhello world\r\n</span></span><br></pre></td></tr></table></figure></p><p>多行字符串当然也可以表示单行字符串。</p><p><strong>整数</strong> <code>1024</code><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:1024\r\n</span><br></pre></td></tr></table></figure></p><p><strong>错误</strong> 参数类型错误<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-WRONGTYPE Operation against a key holding the wrong kind of value\r\n</span><br></pre></td></tr></table></figure></p><p><strong>数组</strong> <code>[1,2,3]</code><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*3\r\n:1\r\n:2\r\n:3\r\n</span><br></pre></td></tr></table></figure></p><p><code>NULL</code>用多行字符串表示，不过长度要写成<code>-1</code>。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">-1\r\n</span></span><br></pre></td></tr></table></figure></p><p><strong>空串</strong> 用多行字符串表示，长度填<code>0</code>。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">0\r\n\r\n</span></span><br></pre></td></tr></table></figure></p><p><strong>注:</strong> 这里有两个<code>\r\n</code>。为什么是两个?因为两个<code>\r\n</code>之间,隔的是空串。</p><h5 id="客户端-gt-服务器"><a href="#客户端-gt-服务器" class="headerlink" title="客户端 -&gt; 服务器"></a>客户端 -&gt; 服务器</h5><p><strong>客户端向服务器发送的指令只有一种格式，多行字符串数组</strong>。比如一个简单的<code>set</code>指令<code>set learn redis</code>会被序列化成下面的字符串。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*3\r\n$3\r\nset\r\n$6\r\nlearn\r\n$8\r\nredis\r\n</span><br></pre></td></tr></table></figure></p><h5 id="服务器-gt-客户端"><a href="#服务器-gt-客户端" class="headerlink" title="服务器 -&gt; 客户端"></a>服务器 -&gt; 客户端</h5><p>服务器向客户端回复的响应要支持多种数据结构，所以消息响应在结构上要复杂不少。不过再复杂的响应消息也是以上<code>5</code>中基本类型的组合。</p><p><strong>1.单行字符串响应</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set learn redis</span><br><span class="line">OK</span><br></pre></td></tr></table></figure></p><p>这里的<code>OK</code>就是单行响应，没有使用引号括起来。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">+OK</span><br></pre></td></tr></table></figure></p><p><strong>2.错误响应</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; incr learn </span><br><span class="line">(error) ERR value is not an integer or out of range</span><br></pre></td></tr></table></figure></p><p>试图对一个字符串进行自增，服务器抛出一个通用的错误。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-ERR value is not an integer or out of range</span><br></pre></td></tr></table></figure></p><p><strong>3.整数响应</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; incr books</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure></p><p>这里的<code>1</code>就是整数响应<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:1</span><br></pre></td></tr></table></figure></p><p><strong>4.多行字符串响应</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; get learn </span><br><span class="line">"redis"</span><br></pre></td></tr></table></figure></p><p><u>这里使用双引号括起来的字符串就是多行字符串响应</u></p><p><strong>5.数组响应</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hset shanghai num 021</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; hset shanghai date 10.1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; hset shanghai abbr sh</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; hgetall shanghai</span><br><span class="line">1) "num"</span><br><span class="line">2) "021"</span><br><span class="line">3) "date"</span><br><span class="line">4) "10.1"</span><br><span class="line">5) "abbr"</span><br><span class="line">6) "sh"</span><br></pre></td></tr></table></figure></p><p>这里的<code>hgetall</code>命令返回的就是一个数组，第<code>0|2|4</code>位置的字符串是<code>hash</code>表的<code>key</code>，第<code>1|3|5</code>位置的字符串是<code>value</code>，客户端负责将数组组装成字典再返回。</p><p><strong>6.嵌套</strong><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "shanghai"</span><br><span class="line">   2) "learn"</span><br></pre></td></tr></table></figure></p><p><code>scan</code>命令用来扫描服务器包含的所有<code>key</code>列表，它是以游标的形式获取，一次只获取一部分。</p><p><code>scan</code>命令返回的是一个嵌套数组。数组的第一个值表示游标的值，如果这个值为零，说明已经遍历完毕。如果不为零，使用这个值作为<code>scan</code>命令的参数进行下一次遍历。数组的第二个值又是一个数组，这个数组就是<code>key</code>列表。</p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li><code>Redis</code>协议里有大量冗余的回车换行符，但是这不影响它成为互联网技术领域非常受欢迎的一个文本协议。有很多开源项目使用<code>RESP</code>作为它的通讯协议。在技术领域性能并不总是一切，还有简单性、易理解性和易实现性，这些都需要进行适当权衡。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis的客户端与服务端采用一种叫做&lt;code&gt;RESP(REdis Serialization Protocol)&lt;/code&gt;的网络通信协议交换数据。 这种协议采用明文传输，易读也易解析。&lt;code&gt;Redis&lt;/code&gt;客户端采用此协议格式来对服务端发送不同的命令，服务端会根据具体的操作而返回具体的答复。客户端和服务端采用的是简单的&lt;code&gt;请求-响应&lt;/code&gt;模型进行通信的。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题11 线程IO模型</title>
    <link href="http://researchlab.github.io/2018/10/08/redis-11-redisio/"/>
    <id>http://researchlab.github.io/2018/10/08/redis-11-redisio/</id>
    <published>2018-10-08T15:31:15.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p><code>Redis</code>是单进程单线程模型的KV数据库,那为什么还常应用在高并发场景中? 其中一个重要原因是<code>Redis</code>是一个<strong>单进程单线程</strong>且采用<strong>多路I/O复用模型，非阻塞IO</strong>技术, 使之可以同时处理多个连接请求(减少网络IO耗时), 也不需要关心锁，线程切换等资源消耗问题;<br><a id="more"></a></p><h5 id="redis为什么设计为单线程"><a href="#redis为什么设计为单线程" class="headerlink" title="redis为什么设计为单线程"></a>redis为什么设计为单线程</h5><p>官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，<strong>Redis的瓶颈最有可能是机器内存的大小或者网络带宽</strong>。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦)。</p><blockquote><p>正因为<code>Redis</code>是单线程，所以要小心使用那些时间复杂度为<code>O(n)</code>级别的<code>Redis</code>指令，一不小心就可能会导致<code>Redis</code>卡顿。</p></blockquote><blockquote><p>但单线程的方式无法发挥多核CPU 性能，不过可通过在单机开多个Redis 实例来完善;</p></blockquote><blockquote><p>多线程处理可能涉及到锁, 多线程处理会涉及到线程切换而消耗CPU</p></blockquote><blockquote><p>多进程单线程模型: <code>Nginx</code>(单进程启动只有一个进程, 多进程启动时会有一个Master,多个worker进程), <code>Node.js</code></p></blockquote><blockquote><p>单进程多线程模型: <code>MySQL</code>, <code>Memcached</code></p></blockquote><blockquote><p>进程是一个实体。每一个进程都有它自己的地址空间，一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region)</p></blockquote><blockquote><p>一个进程中至少有一个线程。线程可以利用进程所拥有的资源，在引入线程的操作系统中，通常都是把进程作为分配资源的基本单位，而把线程作为独立运行和独立调度的基本单位，由于线程比进程更小，基本上不拥有系统资源，故对它的调度所付出的开销就会小得多，能更高效的提高系统多个程序间并发执行的程度。</p></blockquote><blockquote><p>进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。</p></blockquote><h5 id="Redis单线程为什么还能这么快？"><a href="#Redis单线程为什么还能这么快？" class="headerlink" title="Redis单线程为什么还能这么快？"></a><code>Redis</code>单线程为什么还能这么快？</h5><ul><li><p>完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；</p></li><li><p>数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；</p></li><li><p>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；</p></li><li><p>使用多路I/O复用模型，非阻塞IO；</p></li><li><p>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；</p></li></ul><p><code>Redis</code>单线程如何处理那么多的并发客户端连接？<br>因为<code>Redis</code>采用了<code>多路IO复用</code>及<code>非阻塞IO</code>技术, <code>多路IO复用</code>模型是利用<code>select、poll、epoll</code>可以同时监察多个流的<code>IO</code>事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。</p><blockquote><p><strong>多路</strong>指的是多个网络连接，<strong>复用</strong>指的是复用同一个线程。<br>采用<code>多路IO复用</code>技术可以让单个线程高效的处理多个连接请求(尽量减少网络IO的时间消耗)，且<code>Redis</code>在内存中操作数据的速度非常快(内存内的操作不会成为这里的性能瓶颈)，主要以上两点造就了<code>Redis</code>具有很高的吞吐量。</p></blockquote><h5 id="非阻塞IO"><a href="#非阻塞IO" class="headerlink" title="非阻塞IO"></a>非阻塞IO</h5><p>当我们调用套接字的读写方法，默认它们是阻塞的，比如read方法要传递进去一个参数n，表示最多读取这么多字节后再返回，如果一个字节都没有，那么线程就会卡在那里，直到新的数据到来或者连接关闭了，read方法才可以返回，线程才能继续处理。而write方法一般来说不会阻塞，除非内核为套接字分配的写缓冲区已经满了，write方法就会阻塞，直到缓存区中有空闲空间挪出来了。</p><p><strong>非阻塞IO</strong> 在套接字对象上提供了一个选项<code>Non_Blocking</code>，当这个选项打开时，读写方法不会阻塞，而是能读多少读多少，能写多少写多少。<strong>能读多少取决于内核为套接字分配的读缓冲区内部的数据字节数，能写多少取决于内核为套接字分配的写缓冲区的空闲空间字节数</strong>。读方法和写方法都会通过返回值来告知程序实际读写了多少字节。</p><p>有了<code>非阻塞IO</code>意味着线程在读写<code>IO</code>时可以不必再阻塞了，读写可以瞬间完成然后线程可以继续干别的事了。</p><h5 id="事件轮询-多路复用"><a href="#事件轮询-多路复用" class="headerlink" title="事件轮询 (多路复用)"></a>事件轮询 (<code>多路复用</code>)</h5><p><code>非阻塞IO</code>有个问题，那就是线程要读数据，结果读了一部分就返回了，线程如何知道何时才应该继续读。也就是当数据到来时，线程如何得到通知。写也是一样，如果缓冲区满了，写不完，剩下的数据何时才应该继续写，线程也应该得到通知。</p><p><strong>事件轮询API</strong> 就是用来解决这个问题的，最简单的<code>事件轮询API</code>是<code>select函数</code>，它是操作系统提供给用户程序的<code>API</code>。输入是读写描述符列表<code>read_fds &amp; write_fds</code>，输出是与之对应的可读可写事件。同时还提供了一个<code>timeout</code>参数，如果没有任何事件到来，那么就最多等待<code>timeout</code>时间，线程处于阻塞状态。一旦期间有任何事件到来，就可以立即返回。时间过了之后还是没有任何事件到来，也会立即返回。拿到事件后，线程就可以继续挨个处理相应的事件。处理完了继续过来轮询。于是线程就进入了一个死循环，我们把这个死循环称为事件循环，一个循环为一个周期。</p><p>每个客户端套接字<code>socket</code>都有对应的读写文件描述符。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">read_events, write_events = select(read_fds, write_fds, timeout)</span><br><span class="line">for event in read_events:</span><br><span class="line">    handle_read(event.fd)</span><br><span class="line">for event in write_events:</span><br><span class="line">    handle_write(event.fd)</span><br><span class="line">handle_others()  # 处理其它事情，如定时任务等</span><br></pre></td></tr></table></figure></p><p>因为我们通过<code>select</code>系统调用同时处理多个通道描述符的读写事件，因此我们将这类系统调用称为<code>多路复用</code> API。现代操作系统的<code>多路复用</code> API 已经不再使用<code>select</code>系统调用，而改用<code>epoll(linux)</code>和<code>kqueue(freebsd &amp; macosx)</code>，因为<code>select</code>系统调用的性能在描述符特别多时性能会非常差。它们使用起来可能在形式上略有差异，但是本质上都是差不多的，都可以使用上面的伪代码逻辑进行理解。</p><p>服务器套接字<code>serversocket</code>对象的读操作是指调用<code>accept</code>接受客户端新连接。何时有新连接到来，也是通过<code>select</code>系统调用的读事件来得到通知的。</p><h5 id="指令队列"><a href="#指令队列" class="headerlink" title="指令队列"></a>指令队列</h5><p><code>Redis</code> 会将每个客户端套接字都关联一个指令队列。客户端的指令通过队列来排队进行顺序处理，先到先服务。</p><h5 id="响应队列"><a href="#响应队列" class="headerlink" title="响应队列"></a>响应队列</h5><p><code>Redis</code> 同样也会为每个客户端套接字关联一个响应队列。<code>Redis</code> 服务器通过响应队列来将指令的返回结果回复给客户端。 如果队列为空，那么意味着连接暂时处于空闲状态，不需要去获取写事件，也就是可以将当前的客户端描述符从<code>write_fds</code>里面移出来。等到队列有数据了，再将描述符放进去。避免<code>select</code>系统调用立即返回写事件，结果发现没什么数据可以写。出这种情况的线程会飙高<code>CPU</code>。</p><h5 id="定时任务"><a href="#定时任务" class="headerlink" title="定时任务"></a>定时任务</h5><p>服务器处理要响应<code>IO</code>事件外，还要处理其它事情。比如定时任务就是非常重要的一件事。如果线程阻塞在<code>select</code>系统调用上，定时任务将无法得到准时调度。那<code>Redis</code>是如何解决这个问题的呢？</p><p><code>Redis</code> 的定时任务会记录在一个称为最小堆的数据结构中。这个堆中，最快要执行的任务排在堆的最上方。在每个循环周期，<code>Redis</code> 都会将最小堆里面已经到点的任务立即进行处理。处理完毕后，将最快要执行的任务还需要的时间记录下来，这个时间就是<code>select</code>系统调用的timeout参数。因为 <code>Redis</code> 知道未来timeout时间内，没有其它定时任务需要处理，所以可以安心睡眠timeout的时间。</p><p><code>Nginx</code>和<code>Node</code>的事件处理原理和<code>Redis</code>也是类似的</p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>引用官方说明，阐述了为何<code>Redis</code>被设计为单线程模型; </li><li>进一步阐述了为何单线程模型设计的<code>Redis</code>可以非常快的处理高并发等场景的原因;</li><li>对多路复用IO模型及非阻塞IO技术进行了原理阐述及分析;</li><li>此外注意到截止目前最新redis文档版本已更新到redis5.0，并引入新的数据类型<code>stream</code>，并对<code>HyperLogLog</code>等作出了很多优化改进;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;是单进程单线程模型的KV数据库,那为什么还常应用在高并发场景中? 其中一个重要原因是&lt;code&gt;Redis&lt;/code&gt;是一个&lt;strong&gt;单进程单线程&lt;/strong&gt;且采用&lt;strong&gt;多路I/O复用模型，非阻塞IO&lt;/strong&gt;技术, 使之可以同时处理多个连接请求(减少网络IO耗时), 也不需要关心锁，线程切换等资源消耗问题;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题10 海量数据扫描神器之scan</title>
    <link href="http://researchlab.github.io/2018/10/07/redis-10-scan/"/>
    <id>http://researchlab.github.io/2018/10/07/redis-10-scan/</id>
    <published>2018-10-07T17:11:41.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p>用<code>redis</code>模糊匹配<code>key</code>时，官方建议不要使用<code>keys</code>或<code>smembers</code>，他们的时间复杂度都是<code>O(N)</code>,使用<code>scan</code>，<code>zscan</code>，<code>hscan</code>等。<code>scan</code>系列增量式迭代命令每次执行的复杂度为<code>O(1)</code>， 对数据集进行一次完整迭代的复杂度为<code>O(N)</code>， 其中<code>N</code>为数据集中的元素数量。相比<code>keys</code>命令执行时会阻塞掉整个<code>redis</code>线程而言，<code>scan</code>系列则是通过游标分步进行的，不会阻塞<code>redis</code>线程, 且在同一时间，可以有任意多个客户端对同一数据集进行迭代。<br><a id="more"></a></p><p><code>keys</code>有两个显著缺点,</p><ul><li>没有<code>offset, limit</code>参数，一次性吐出所有满足条件的<code>key</code>, 万一实例中有几百w个<code>key</code>满足条件, 当你看到满屏的字符串刷的没有尽头时，你就知道难受了。</li><li><code>keys</code>算法是遍历算法, 复杂度是<code>O(n)</code>，如果实例中有千万级以上的<code>key</code>，这个指令就会导致<code>Redis</code>服务卡顿, 所有读写<code>Redis</code>的其它的指令都会被延后甚至会超时报错，因为<code>Redis</code>是单线程程序，顺序执行所有指令，其它指令必须等到当前的<code>keys</code>指令执行完了才可以继续。</li></ul><p><code>redis</code>为了解决这个问题, 它在2.8版本中加入了<code>scan</code>系列增量式迭代命令。<code>scan</code>相比<code>keys</code>具备有以下特点:</p><ul><li>复杂度虽然也是<code>O(n)</code>，但是它是通过游标分步进行的，不会阻塞线程;</li><li>提供<code>limit</code>参数，可以控制每次返回结果的最大条数, <code>limit</code>只是一个<code>hint</code>，返回的结果可多可少;</li><li>同<code>keys</code>一样，它也提供模式匹配功能;</li><li>服务器不需要为游标保存状态，游标的唯一状态就是<code>scan</code>返回给客户端的游标整数;</li><li>返回的结果可能会有重复，需要客户端去重复，这点非常重要;</li><li>遍历的过程中如果有数据修改，改动后的数据能不能遍历到是不确定的;</li><li>单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零;</li></ul><blockquote><p>当然<code>增量式迭代命令</code>也不是没有缺点, 如使用<code>SMEMBERS</code>命令可以返回集合键当前包含的所有元素， 但是对于<code>SCAN</code>这类增量式迭代命令来说， 因为在对键进行增量式迭代的过程中，键可能会被修改，所以增量式迭代命令只能对被返回的元素提供有限的保证(offer limited guarantees about the returned elements)。</p></blockquote><blockquote><p>同一个元素可能会被返回多次。<code>scan</code>系列命令无法保证同一元素被多次返回, 所以处理重复元素的工作交由应用程序负责处理(过滤/幂等操作)。</p></blockquote><p><strong>scan</strong></p><blockquote><p>命令: <code>SCAN cursor [MATCH pattern] [COUNT count]</code></p><blockquote><p><code>count</code>表示每次迭代中应该从数据集里最多返回多少元素, 默认值为10, 用户可以在每次迭代时随机修改此值;</p></blockquote></blockquote><blockquote><blockquote><p>在迭代一个足够大的、由哈希表实现的数据库、集合键、哈希键或者有序集合键时, 如果用户没有使用<code>match</code>选项, 那么命令返回的元素数量通常和<code>COUNT</code>选项指定的一样, 或者比<code>COUNT</code>选项指定的数量稍多一些。</p></blockquote></blockquote><blockquote><blockquote><p>在迭代一个编码为整数集合(<code>intset</code>, 一个只由整数值构成的小集合), 或者编码为压缩列表<code>ziplist</code>, 由不同值构成的一个小哈希或者一个小有序集合)时, 增量式迭代命令通常会无视<code>COUNT</code>选项指定的值， 在第一次迭代就将数据集包含的所有元素都返回给用户。</p></blockquote></blockquote><blockquote><blockquote><p><code>match</code>表示对返回的元素再进行模式匹配并将匹配结果最终返回, <strong>需要注意的是, 对元素的模式匹配工作是在命令从数据集中取出元素之后, 向客户端返回元素之前的这段时间内进行的, 所以如果被迭代的数据集中只有少量元素和模式相匹配, 那么迭代命令或许会在多次执行中都不返回任何元素。</strong></p></blockquote></blockquote><blockquote><p>功能: 用于迭代当前数据库中的数据库键;</p></blockquote><blockquote><p>返回值: <code>SCAN</code>命令的回复是一个包含两个元素的数组, 第一个数组元素是用于进行下一次迭代的新游标, 而第二个数组元素则是一个数组, 这个数组中包含了所有被迭代的元素。</p><blockquote><p>当返回的新游标为0 表示当前迭代全部完成;</p></blockquote></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; keys key*</span><br><span class="line">1) "key11"</span><br><span class="line">2) "key2"</span><br><span class="line">3) "key22"</span><br><span class="line">4) "key222"</span><br><span class="line">5) "key1"</span><br><span class="line">6) "key111"</span><br><span class="line">127.0.0.1:6379&gt; scan 0 match key1* count 10</span><br><span class="line">1) "0"</span><br><span class="line">2) 1) "key111"</span><br><span class="line">   2) "key11"</span><br><span class="line">   3) "key1"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><h5 id="字典结构"><a href="#字典结构" class="headerlink" title="字典结构"></a>字典结构</h5><p>在<code>redis</code>中所有的<code>key</code>都存储在一个很大的字典中, 即一维数组 + 二维链表结构, 示例,<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">0</span><br><span class="line">1 -&gt;e-&gt;f-&gt;h</span><br><span class="line">2</span><br><span class="line">3 -&gt;g-&gt;x</span><br><span class="line">4</span><br><span class="line">5 -&gt;a-&gt;c</span><br></pre></td></tr></table></figure></p><p><code>scan</code>指令返回的游标就是第一维数组的位置索引，我们将这个位置索引称为槽<code>(slot)</code>。如果不考虑字典的扩容缩容，直接按数组下标挨个遍历就行了。<code>count</code>参数就表示需要遍历的槽位数，之所以返回的结果可能多可能少，是因为不是所有的槽位上都会挂接链表，有些槽位可能是空的，还有些槽位上挂接的链表上的元素可能会有多个。每一次遍历都会将<code>count</code>数量的槽位上挂接的所有链表元素进行模式匹配过滤后，一次性返回给客户端。</p><blockquote><p><code>scan</code>的遍历顺序非常特别。它不是从第一维数组的第<code>0</code>位一直遍历到末尾，而是采用了高位进位加法来遍历。之所以使用这样特殊的方式进行遍历，是考虑到字典的扩容和缩容时避免槽位的遍历重复和遗漏。</p></blockquote><p>redis字典扩容采用了·渐进式rehash`操作。</p><p><code>渐进式rehash</code>会同时保留旧数组和新数组，然后在定时任务中以及后续对<code>hash</code>的指令操作中渐渐地将旧数组中挂接的元素迁移到新数组上。这意味着要操作处于<code>rehash</code>中的字典，需要同时访问新旧两个数组结构。如果在旧数组下面找不到元素，还需要去新数组下面去寻找。</p><p><code>scan</code>也需要考虑这个问题，对与<code>rehash</code>中的字典，它需要同时扫描新旧槽位，然后将结果融合后返回给客户端。</p><p><code>scan</code>系列命令目前共计4条,</p><blockquote><p><code>SCAN</code>  命令用于迭代当前数据库中的数据库键;<br><code>SSCAN</code> 命令用于迭代集合键中的元素;<br><code>HSCAN</code> 命令用于迭代哈希键中的键值对;<br><code>ZSCAN</code> 命令用于迭代有序集合中的元素(包括元素成员和元素分值);</p></blockquote><h5 id="定位大key"><a href="#定位大key" class="headerlink" title="定位大key"></a>定位大key</h5><p>为了避免对线上<code>redis</code>带来卡顿，这就要用到<code>scan</code>指令，对于扫描出来的每一个<code>key</code>，使用<code>type</code>指令获得<code>key</code>的类型，然后使用相应数据结构的<code>size</code>或者<code>len</code>方法来得到它的大小，对于每一种类型，保留大小的前<code>N</code>名作为扫描结果展示出来。</p><p>上面这样的过程<code>redis</code>官方已经在<code>redis-cli</code>指令中提供了这样的扫描功能，我们可以直接拿来即用。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 6370 –-bigkeys</span><br></pre></td></tr></table></figure></p><p>如果你担心这个指令会大幅抬升<code>redis</code>的<code>ops</code>导致线上报警，还可以增加一个休眠参数。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 6370 –-bigkeys -i 0.1</span><br></pre></td></tr></table></figure></p><p>上面这个指令每隔<code>100</code>条<code>scan</code>指令就会休眠<code>0.1s,</code>ops`就不会剧烈抬升，但是扫描的时间会变长。</p><p>可进一步参考 <a href="https://mp.weixin.qq.com/s/ufoLJiXE0wU4Bc7ZbE9cDQ" target="_blank" rel="noopener">美团针对Redis Rehash机制的探索和实践</a></p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>从<code>redis</code>模糊匹配场景分析入手，引入<code>keys</code>和<code>scan</code>系列增量迭代式命令方法，结合使用场景对其优劣进行了比较说明;</li><li>阐述了<code>scan</code>遍历方法，并对字典扩容进行了简单探讨;</li><li>从定位大<code>key</code>场景出发，引出了<code>redis-cli</code>已支持的 <code>--bigkeys</code>命令， 可以非常方便的协助用户定位大<code>key</code>问题;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;用&lt;code&gt;redis&lt;/code&gt;模糊匹配&lt;code&gt;key&lt;/code&gt;时，官方建议不要使用&lt;code&gt;keys&lt;/code&gt;或&lt;code&gt;smembers&lt;/code&gt;，他们的时间复杂度都是&lt;code&gt;O(N)&lt;/code&gt;,使用&lt;code&gt;scan&lt;/code&gt;，&lt;code&gt;zscan&lt;/code&gt;，&lt;code&gt;hscan&lt;/code&gt;等。&lt;code&gt;scan&lt;/code&gt;系列增量式迭代命令每次执行的复杂度为&lt;code&gt;O(1)&lt;/code&gt;， 对数据集进行一次完整迭代的复杂度为&lt;code&gt;O(N)&lt;/code&gt;， 其中&lt;code&gt;N&lt;/code&gt;为数据集中的元素数量。相比&lt;code&gt;keys&lt;/code&gt;命令执行时会阻塞掉整个&lt;code&gt;redis&lt;/code&gt;线程而言，&lt;code&gt;scan&lt;/code&gt;系列则是通过游标分步进行的，不会阻塞&lt;code&gt;redis&lt;/code&gt;线程, 且在同一时间，可以有任意多个客户端对同一数据集进行迭代。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题09 geo地理位置模块</title>
    <link href="http://researchlab.github.io/2018/10/06/redis-09-geohash/"/>
    <id>http://researchlab.github.io/2018/10/06/redis-09-geohash/</id>
    <published>2018-10-06T17:09:06.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p><code>redis3.2</code>版本里面新增的一个功能就是对<code>GEO(地理位置)</code>的支持。意味着可以用<code>redis</code>来实现查找<code>附件的人</code>的等搜索功能了；<br><a id="more"></a><br>地图元素的位置数据使用二维的经纬度表示，经度范围 (-180, 180]，纬度范围 (-90, 90]，纬度正负以赤道为界，北正南负，经度正负以本初子午线 (英国格林尼治天文台) 为界，东正西负。</p><p>当两个元素的距离不是很远时，可以直接使用勾股定理就能算得元素之间的距离。我们平时使用的「附近的人」的功能，元素距离都不是很大，勾股定理算距离足矣。不过需要注意的是，经纬度坐标的密度不一样 (地球是一个椭圆)，勾股定律计算平方差时之后再求和时，需要按一定的系数比加权求和，如果不求精确的话，也可以不必加权。</p><p>问题：经度总共360度，维度总共只有180度，为什么距离密度不是2:1？</p><p>现在，如果要计算「附近的人」，也就是给定一个元素的坐标，然后计算这个坐标附近的其它元素，按照距离进行排序，该如何下手？<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">假设待计算坐标为(x,y),以这个坐标为圆点, r为半径，进行搜索其附近的元素</span><br></pre></td></tr></table></figure></p><p>如果现在元素的经纬度坐标使用关系数据库 (元素<code>id</code>, 经度<code>x</code>, 纬度<code>y</code>) 存储，你该如何计算？</p><p>首先，你不可能通过遍历来计算所有的元素和目标元素的距离然后再进行排序，这个计算量太大了，性能指标肯定无法满足。一般的方法都是通过矩形区域来限定元素的数量，然后对区域内的元素进行全量距离计算再排序。这样可以明显减少计算量。如何划分矩形区域呢？ 可以指定一个半径<code>r</code>，使用一条<code>SQL</code>就可以圈出来。当用户对筛出来的结果不满意，那就扩大半径继续筛选。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id from positions where x0-r &lt; x &lt; x0+r and y0-r &lt; y &lt; y0+r</span><br></pre></td></tr></table></figure></p><p>为了满足高性能的矩形区域算法，数据表需要在经纬度坐标加上双向复合索引(x, y)，这样可以最大优化查询性能。</p><p>但是数据库查询性能毕竟有限，如果「附近的人」查询请求非常多，在高并发场合，这可能并不是一个很好的方案。</p><h5 id="GeoHash算法"><a href="#GeoHash算法" class="headerlink" title="GeoHash算法"></a>GeoHash算法</h5><p>业界比较通用的地理位置距离排序算法是<code>GeoHash</code>算法，<code>redis</code>也使用<code>GeoHash</code>算法。<code>GeoHash</code>算法将二维的经纬度数据映射到一维的整数，这样所有的元素都将在挂载到一条线上，距离靠近的二维坐标映射到一维后的点之间距离也会很接近。当我们想要计算「附近的人时」，首先将目标位置映射到这条线上，然后在这个一维的线上获取附近的点就行了。</p><p>那这个映射算法具体是怎样的呢？ 它将整个地球看成一个二维平面，然后划分成了一系列正方形的方格，就好比围棋棋盘。所有的地图元素坐标都将放置于唯一的方格中。方格越小，坐标越精确。然后对这些方格进行整数编码，越是靠近的方格编码越是接近。那如何编码呢？一个最简单的方案就是切蛋糕法。设想一个正方形的蛋糕摆在你面前，二刀下去均分分成四块小正方形，这四个小正方形可以分别标记为 00,01,10,11 四个二进制整数。然后对每一个小正方形继续用二刀法切割一下，这时每个小小正方形就可以使用 4bit 的二进制整数予以表示。然后继续切下去，正方形就会越来越小，二进制整数也会越来越长，精确度就会越来越高。</p><h5 id="redis-Geo模块应用"><a href="#redis-Geo模块应用" class="headerlink" title="redis Geo模块应用"></a>redis Geo模块应用</h5><p><code>Geo</code>地理模块到目前为止提供了6条命令:</p><table><thead><tr><th>序号</th><th>命令</th><th>备注</th></tr></thead><tbody><tr><td>1</td><td><code>geoadd</code></td><td>将指定的地理空间位置(纬度, 经度, 名称)添加到指定的key中</td></tr><tr><td>2</td><td><code>geodist</code></td><td>返回两个给定位置之间的距离</td></tr><tr><td>3</td><td><code>geohash</code></td><td>返回一个或多个位置元素的<code>Geohash</code>表示</td></tr><tr><td>4</td><td><code>geopos</code></td><td>从key里返回所有给定位置元素的位置(经度和纬度)</td></tr><tr><td>5</td><td><code>georadius</code></td><td>以给定的经纬度为中心， 返回键包含的位置元素当中， 与中心的距离不超过给定最大距离的所有位置元素</td></tr><tr><td>6</td><td><code>georadiusbymember</code></td><td>查找给定元素给定范围内的元素值</td></tr></tbody></table><p><strong><code>geoadd</code></strong></p><blockquote><p>命令: <code>GEOADD key longitude latitude member [longitude latitude member ...]</code><br>命令描述: 将指定的地理空间位置(纬度, 经度, 名称)添加到指定的key中;<br>返回值: 添加到sorted set元素的数目, 但不包括已更新score的元素;<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geoadd location 116.111 39.111 position.one</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; geoadd location 116.333 39.333 position.two 116.555 39.556 position.three</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p></blockquote><p><strong><code>geodist</code></strong></p><blockquote><p>命令: <code>GEODIST key member1 member2 [unit]</code><br>命令描述: 返回两个给定位置之间的距离。如果两个位置之间的其中一个不存在,  那么命令返回空值。指定单位的参数 unit 必须是以下单位的其中一个:</p><blockquote><p><code>m</code> 表示单位为米;<br><code>km</code> 表示单位为千米;<br><code>mi</code> 表示单位为英里;<br><code>ft</code> 表示单位为英尺;</p></blockquote></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geodist location position.one position.three m</span><br><span class="line">"62520.6181"</span><br><span class="line">127.0.0.1:6379&gt; geodist location position.one position.three km</span><br><span class="line">"62.5206"</span><br><span class="line">127.0.0.1:6379&gt; geodist location position.one position.five m</span><br><span class="line">(nil)</span><br></pre></td></tr></table></figure><p><strong><code>geohash</code></strong></p><blockquote><p>命令: <code>GEOHASH key member [member ...]</code><br>命令描述: 返回一个或多个位置元素的<code>Geohash</code>表示。通常使用表示位置的元素使用不同的技术, 使用<code>Geohash</code>位置52点整数编码。由于编码和解码过程中所使用的初始最小和最大坐标不同, 编码的编码也不同于标准。此命令返回一个标准的<code>Geohash</code>值<br>返回值: 一个数组, 数组的每个项都是一个<code>Geohash</code> 。 命令返回的<code>Geohash</code>的位置与用户给定的位置元素的位置一一对应。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geohash location position.one position.two position.three position.five</span><br><span class="line">1) "wwfw6pvqn60"</span><br><span class="line">2) "wwfxz0r5760"</span><br><span class="line">3) "wx4ch2by2k0"</span><br><span class="line">4) (nil)</span><br></pre></td></tr></table></figure><p><strong><code>geopos</code></strong></p><blockquote><p>命令: <code>GEOPOS key member [member ...]</code><br>命令描述: 从<code>key</code>里返回所有给定位置元素的位置(经度和纬度);<br>返回值: <code>GEOPOS</code>命令返回一个数组, 数组中的每个项都由两个元素组成: 第一个元素为给定位置元素的经度, 而第二个元素则为给定位置元素的纬度。当给定的位置元素不存在时, 对应的数组项为空值。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geopos location position.one position.five position.three</span><br><span class="line">1) 1) "116.11100167036056519"</span><br><span class="line">   2) "39.11099969335537452"</span><br><span class="line">2) (nil)</span><br><span class="line">3) 1) "116.55499845743179321"</span><br><span class="line">   2) "39.55600040953122942"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p><strong><code>georadius</code></strong></p><blockquote><p>命令: <code>GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count]</code><br>命令描述: 以给定的经纬度为中心, 返回键包含的位置元素当中, 与中心的距离不超过给定最大距离的所有位置元素, 范围可以使用以下其中一个单位:</p><blockquote><p><code>m</code> 表示单位为米;<br><code>km</code> 表示单位为千米;<br><code>mi</code> 表示单位为英里;<br><code>ft</code> 表示单位为英尺;</p></blockquote></blockquote><blockquote><p>在给定以下可选项时, 命令会返回额外的信息:</p><blockquote><p><code>WITHDIST</code>: 在返回位置元素的同时, 将位置元素与中心之间的距离也一并返回。 距离的单位和用户给定的范围单位保持一致。<br><code>WITHCOORD</code>: 将位置元素的经度和维度也一并返回。<br><code>WITHHASH</code>: 以52位有符号整数的形式, 返回位置元素经过原始<code>Geohash</code>编码的有序集合分值。这个选项主要用于底层应用或者调试, 实际中的作用并不大。</p></blockquote></blockquote><blockquote><p>命令默认返回未排序的位置元素。通过以下两个参数, 用户可以指定被返回位置元素的排序方式:</p><blockquote><p><code>ASC</code>: 根据中心的位置, 按照从近到远的方式返回位置元素;<br><code>DESC</code>: 根据中心的位置, 按照从远到近的方式返回位置元素;</p></blockquote></blockquote><blockquote><p>在默认情况下, <code>GEORADIUS</code>命令会返回所有匹配的位置元素;<br>虽然用户可以使用<code>COUNT &lt;count&gt;</code>选项去获取前<code>N</code> 个匹配元素,  但是因为命令在内部可能会需要对所有被匹配的元素进行处理<code>所以在对一个非常大的区域进行搜索时, 即使只使用</code>COUNT<code>选项去获取少量元素,  命令的执行速度也可能会非常慢。 但是从另一方面来说， 使用</code>COUNT<code>选项去减少需要返回的元素数量</code> 对于减少带宽来说仍然是非常有用的。</p></blockquote><blockquote><p>返回值:<br>在没有给定任何<code>WITH</code>选项的情况下, 命令只会返回一个像<code>[&quot;New York&quot;, &quot;Milan&quot;,&quot;Paris&quot;] 这样的线性(linear)列表。在指定了</code>WITHCOORD<code>,</code>WITHDIST<code>,</code>WITHHASH`等选项的情况下, 命令返回一个二层嵌套数组, 内层的每个子数组就表示一个元素。<br>在返回嵌套数组时, 子数组的第一个元素总是位置元素的名字。 至于额外的信息, 则会作为子数组的后续元素, 按照以下顺序被返回:</p><blockquote><p>1.以浮点数格式返回的中心与位置元素之间的距离, 单位与用户指定范围时的单位一致。<br>2.<code>Geohash</code>整数。<br>3.由两个元素组成的坐标, 分别为经度和纬度。</p></blockquote></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; georadius location 116.111 39.111 50 km withcoord withdist withhash</span><br><span class="line">1) 1) "position.one"</span><br><span class="line">   2) "0.0001"</span><br><span class="line">   3) (integer) 4069074382584591</span><br><span class="line">   4) 1) "116.11100167036056519"</span><br><span class="line">      2) "39.11099969335537452"</span><br><span class="line">2) 1) "position.two"</span><br><span class="line">   2) "31.2350"</span><br><span class="line">   3) (integer) 4069124900607885</span><br><span class="line">   4) 1) "116.33299738168716431"</span><br><span class="line">      2) "39.33300071137491472"</span><br><span class="line">127.0.0.1:6379&gt; georadius location 116.111 39.111 50 km withcoord withdist withhash  count 1</span><br><span class="line">1) 1) "position.one"</span><br><span class="line">   2) "0.0001"</span><br><span class="line">   3) (integer) 4069074382584591</span><br><span class="line">   4) 1) "116.11100167036056519"</span><br><span class="line">      2) "39.11099969335537452"</span><br><span class="line">127.0.0.1:6379&gt; georadius location 116.111 39.111 50 km withcoord withdist withhash  count 2 asc</span><br><span class="line">1) 1) "position.one"</span><br><span class="line">   2) "0.0001"</span><br><span class="line">   3) (integer) 4069074382584591</span><br><span class="line">   4) 1) "116.11100167036056519"</span><br><span class="line">      2) "39.11099969335537452"</span><br><span class="line">2) 1) "position.two"</span><br><span class="line">   2) "31.2350"</span><br><span class="line">   3) (integer) 4069124900607885</span><br><span class="line">   4) 1) "116.33299738168716431"</span><br><span class="line">      2) "39.33300071137491472"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p><strong><code>georadiusbymember</code></strong></p><blockquote><p>命令: <code>GEORADIUSBYMEMBER key member radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count]</code><br>命令描述: 这个命令和<code>GEORADIUS</code>命令一样, 都可以找出位于指定范围内的元素, 但是<code>GEORADIUSBYMEMBER</code>的中心点是由给定的位置元素决定的。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 表示对key `location` 以`position.one`为原点, 100km为半径, 帅选出最多5个position 并且对结果进行正向(由近到远)排序</span></span><br><span class="line">127.0.0.1:6379&gt; georadiusbymember location position.one 100 km count 5 asc</span><br><span class="line">1) "position.one"</span><br><span class="line">2) "position.two"</span><br><span class="line">3) "position.three"</span><br><span class="line">127.0.0.1:6379&gt; georadiusbymember location position.one 100 km count 5 asc withcoord withdist withhash</span><br><span class="line">1) 1) "position.one"</span><br><span class="line">   2) "0.0000"</span><br><span class="line">   3) (integer) 4069074382584591</span><br><span class="line">   4) 1) "116.11100167036056519"</span><br><span class="line">      2) "39.11099969335537452"</span><br><span class="line">2) 1) "position.two"</span><br><span class="line">   2) "31.2349"</span><br><span class="line">   3) (integer) 4069124900607885</span><br><span class="line">   4) 1) "116.33299738168716431"</span><br><span class="line">      2) "39.33300071137491472"</span><br><span class="line">3) 1) "position.three"</span><br><span class="line">   2) "62.5206"</span><br><span class="line">   3) (integer) 4069148683788633</span><br><span class="line">   4) 1) "116.55499845743179321"</span><br><span class="line">      2) "39.55600040953122942"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><h5 id="问题及建议"><a href="#问题及建议" class="headerlink" title="问题及建议"></a>问题及建议</h5><p>在一个地图应用中，车的数据、餐馆的数据、人的数据可能会有百万千万条，如果使用<code>redis</code>的<code>Geo</code>数据结构，它们将全部放在一个<code>zset</code> 集合中。在<code>redis</code>的集群环境中，集合可能会从一个节点迁移到另一个节点，如果单个<code>key</code>的数据过大，会对集群的迁移工作造成较大的影响，在集群环境中单个<code>key</code>对应的数据量不宜超过<code>1M</code>，否则会导致集群迁移出现卡顿现象，影响线上服务的正常运行。</p><p>所以，这里建议<code>Geo</code>的数据使用单独的<code>redis</code>实例部署，不使用集群环境。</p><p>如果数据量过亿甚至更大，就需要对<code>Geo</code>数据进行拆分，按国家拆分、按省拆分，按市拆分，在人口特大城市甚至可以按区拆分。这样就可以显著降低单个<code>zset</code>集合的大小。</p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>从地图中元素的二维表示入手，分析引入在<code>redis3.2</code>中提供的<code>Geo</code>地理模块,并对<code>Geo</code>地理模块提供的基础命令原理及使用进行了阐述说明，并进一步通过示例作出了说明；</li><li><code>Geo</code>地理模块对于计算地图中元素位置及查找元素非常方便; </li><li>但值得注意的时，有关使用经验表明当<code>redis</code>集群中单个<code>key</code>数据量比较大如超出<code>1M</code>时，建议按照业务特性进行拆分，分流到多个<code>redis</code>实例中去，以免在进行迁移时影响运营服务;</li></ul><p>此外，可进一步参考</p><hr><p>[1] <a href="https://www.cnblogs.com/zhenbianshu/p/6817569.html" target="_blank" rel="noopener">空间索引 - 各数据库空间索引使用报告</a><br>[2] <a href="https://www.cnblogs.com/zhenbianshu/p/6863405.html" target="_blank" rel="noopener">空间索引 - GeoHash算法及其实现优化</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;redis3.2&lt;/code&gt;版本里面新增的一个功能就是对&lt;code&gt;GEO(地理位置)&lt;/code&gt;的支持。意味着可以用&lt;code&gt;redis&lt;/code&gt;来实现查找&lt;code&gt;附件的人&lt;/code&gt;的等搜索功能了；&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题08 redis分布式限流之redis-cell</title>
    <link href="http://researchlab.github.io/2018/10/05/redis-08-redis-cell/"/>
    <id>http://researchlab.github.io/2018/10/05/redis-08-redis-cell/</id>
    <published>2018-10-05T17:05:32.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p><code>redis4.0</code>以后开始支持扩展模块，<code>redis-cell</code>是一个用<code>rust</code>语言编写的基于<code>令牌桶算法</code>的的限流模块，提供原子性的限流功能，并允许突发流量，可以很方便的应用于分布式环境中。<br><a id="more"></a></p><h5 id="令牌桶限流算法原理"><a href="#令牌桶限流算法原理" class="headerlink" title="令牌桶限流算法原理"></a>令牌桶限流算法原理</h5><p>令牌桶算法的原理是定义一个按一定速率产生<code>token</code>的桶，每次去桶中申请<code>token</code>，若桶中没有足够的<code>token</code>则申请失败，否则成功。在请求不多的情况下，桶中的<code>token</code>基本会饱和，此时若流量激增，并不会马上拒绝请求，所以这种算法允许一定的流量激增。</p><p>1.定义一个令牌桶<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">令牌桶其拥有几个关键属性为，</span><br><span class="line">桶容量</span><br><span class="line">令牌产生速率</span><br><span class="line">当前桶中令牌数</span><br><span class="line">最近一次取（生成）令牌时间</span><br></pre></td></tr></table></figure></p><p>2.从桶中申请令牌，这一步中有两个关键动作</p><blockquote><p>根据上一次生成令牌时间到现在的时间，及生成速率计算出当前令牌桶中的令牌数<br>判断令牌桶中是否有足够的令牌，并返回结果</p></blockquote><p>这几个步骤可以采用<code>redis</code>提供的原生命令去实现，但是高并发的时候数据会不一致，所以<code>redis-cell</code>将这个过程原子化，完美解决了分布式环境下数据的一致性问题。</p><p><code>redis-cell</code>模块只提供了一个命令<code>cl.throttle</code></p><p>示例<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt;cl.throttle test 100 500 20 1</span><br></pre></td></tr></table></figure></p><p>参数依次说明</p><ul><li><p><code>test</code> 表示<code>redis key</code></p></li><li><p><code>100</code> 官方叫·max_burst·，其值为令牌桶的容量<code>-1</code>， 首次执行时令牌桶会默认填满</p></li><li><p><code>500</code> 与下一个参数一起，表示在指定时间窗口内允许访问的次数</p></li><li><p><code>20</code> 指定的时间窗口，单位：秒</p></li><li><p><code>1</code>  表示本次要申请的令牌数，不写则默认为<code>1</code></p></li></ul><blockquote><p>以上命令表示从一个初始值为100的令牌桶中取1个令牌，该令牌桶的速率限制为500次/20秒。</p></blockquote><p>结果示例<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; CL.THROTTLE test 100 500 20 1</span><br><span class="line">1) (integer) 0</span><br><span class="line">2) (integer) 101</span><br><span class="line">3) (integer) 98</span><br><span class="line">4) (integer) -1</span><br><span class="line">5) (integer) 0</span><br></pre></td></tr></table></figure></p><ul><li><code>1)</code> 是否成功，0：成功，1：拒绝</li><li><code>2)</code> 令牌桶的容量，大小为初始值+1</li><li><code>3)</code> 当前令牌桶中可用的令牌</li><li><code>4)</code> 若请求被拒绝，这个值表示多久后才令牌桶中会重新添加令牌，单位：秒，可以作为重试时间</li><li><code>5)</code> 表示多久后令牌桶中的令牌会存满</li></ul><blockquote><p>由于<code>redis-Cell</code>是基于Rust语言写的插件，因此在安装插件前要先安装rust, 具体可参看官方README <a href="https://github.com/brandur/redis-cell" target="_blank" rel="noopener">github</a></p></blockquote><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>从限制用户行为频率场景出发，引入<code>redis-cell</code>分布式限流解决方案，阐述了其算法原理及步骤，并给出实例说明;</li><li>频率限制的实现有多种方式，例如<code>Nginx</code>和<code>Haproxy</code>都有限制模块、通过Redis来实现也是常见的方式之一;</li><li>除了引入<code>redis-cell</code>分布式限流模块， 也可以将上述令牌通的实现思路通过<code>Lua</code>脚本实现，然后嵌入到<code>redis</code>中执行， 实际上在<code>redis</code>还不支持<code>redis-cell</code>模块时， 实际使用场景中大多采用<code>redis+lua</code>方式来实现限流策略;</li><li>将<code>redis-cell</code>限流应用于微服务接口访问频次上也灰常方便;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;redis4.0&lt;/code&gt;以后开始支持扩展模块，&lt;code&gt;redis-cell&lt;/code&gt;是一个用&lt;code&gt;rust&lt;/code&gt;语言编写的基于&lt;code&gt;令牌桶算法&lt;/code&gt;的的限流模块，提供原子性的限流功能，并允许突发流量，可以很方便的应用于分布式环境中。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题07 redis应用之限流策略</title>
    <link href="http://researchlab.github.io/2018/10/04/redis-07-limit-rate/"/>
    <id>http://researchlab.github.io/2018/10/04/redis-07-limit-rate/</id>
    <published>2018-10-04T17:01:59.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p>限流算法在分布式领域是一个经常被提起的话题，当系统的处理能力有限时，如何阻止计划外的请求继续对系统施压，这是一个需要重视的问题。除了控制流量，限流还有一个应用目的是用于控制用户行为，避免垃圾请求。比如在<code>UGC</code>社区, <code>用户的发帖</code>, <code>回复</code>, <code>点赞</code>等行为都要严格受控，一般要严格限定某行为在规定时间内允许的次数，超过了次数那就是非法行为。<br><a id="more"></a></p><h5 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h5><p>系统要限定用户的某个行为在指定的时间里只能允许发生<code>N</code>次，如何使用<code>redis</code>的数据结构来实现这个限流的功能？</p><h5 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h5><p>这个限流需求中存在一个滑动时间窗口，想想<code>zset</code>数据结构的<code>score</code>值，是不是可以通过<code>score</code>来圈出这个时间窗口来。而且我们只需要保留这个时间窗口，窗口之外的数据都可以砍掉。用一个<code>zset</code>结构记录用户的行为历史，每一个行为都会作为<code>zset</code>中的一个<code>key</code>保存下来。同一个用户同一种行为用一个<code>zset</code>记录。为节省内存，我们只需要保留时间窗口内的行为记录，同时如果用户是冷用户，滑动时间窗口内的行为是空记录，那么这个<code>zset</code>就可以从内存中移除，不再占用空间。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ZADD key score member [[score member] [score member] ...]</span><br><span class="line"></span><br><span class="line">key: 'hist:userid:actionkey</span><br><span class="line"></span><br><span class="line">score: 'time.Millisecond'</span><br><span class="line"></span><br><span class="line">member: 'time.Millisecond'</span><br></pre></td></tr></table></figure><blockquote><p>每个用户的每个行为单独作为一个<code>key</code>;<br>指定时间时间内，刚好可以利用<code>zset</code>集合中的<code>rangebyscore</code>命令， 通过把时间设置为<code>score</code>值来动态维持一个有效的指定时间内的时间窗口;<br><code>zset</code>中插入的<code>key</code>值的<code>member</code>如果相同， 则只会更新这个相同<code>member</code>的<code>score</code>值，所以需要保证<code>member</code>在同一个行为多次发生时都不同即可， 所以可以简单设置为时间值，但在实际中应保证每次<code>member</code>是绝对不同的;</p></blockquote><p>golang代码如下<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line"><span class="string">"log"</span></span><br><span class="line"><span class="string">"time"</span></span><br><span class="line"></span><br><span class="line"><span class="string">"github.com/go-redis/redis"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">addr = <span class="string">"127.0.0.1:6378"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"></span><br><span class="line">client := redis.NewClient(&amp;redis.Options&#123;</span><br><span class="line">Addr:     addr,</span><br><span class="line">Password: <span class="string">""</span>, <span class="comment">//no password set</span></span><br><span class="line">DB:       <span class="number">0</span>,  <span class="comment">// use default DB</span></span><br><span class="line">&#125;)</span><br><span class="line"><span class="keyword">defer</span> client.Close()</span><br><span class="line">pong, err := client.Ping().Result()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">panic</span>(err)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> pong == <span class="string">"PONG"</span> &#123;</span><br><span class="line">log.Println(<span class="string">"redis service is ready."</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">1</span>; i &lt;= <span class="number">10</span>; i++ &#123;</span><br><span class="line">fmt.Println(<span class="string">"nums:"</span>, i, <span class="string">" result:"</span>, isActionAllowd(client, <span class="string">"test"</span>, <span class="string">"reply"</span>, <span class="number">60</span>*time.Second, <span class="number">5</span>))</span><br><span class="line">time.Sleep(time.Millisecond) #为了实验效果，这里适当sleep一下，在实际环境中应保证每次member是不同的</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">isActionAllowd</span><span class="params">(client *redis.Client, userID, actionKey <span class="keyword">string</span>, period time.Duration, maxCount <span class="keyword">int64</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">key := fmt.Sprintf(<span class="string">"hist:%s:%s"</span>, userID, actionKey)</span><br><span class="line">mperiod := period.Nanoseconds() / <span class="number">1e6</span>       <span class="comment">//转毫秒</span></span><br><span class="line">now := <span class="keyword">int64</span>(time.Now().Nanosecond() / <span class="number">1e6</span>) <span class="comment">// 毫秒时间戳</span></span><br><span class="line">    <span class="comment">// 注意这里 不能使用 now = time.Now().Seconds()*1000  因为这样精度就丢失了，导致一秒内的所有now值都一样;</span></span><br><span class="line"></span><br><span class="line">pipe := client.Pipeline()</span><br><span class="line">pipe.ZAdd(key, redis.Z&#123;</span><br><span class="line">Score:  <span class="keyword">float64</span>(now),</span><br><span class="line">Member: now,</span><br><span class="line">&#125;) <span class="comment">//记录行为， value 和score 都使用毫秒时间戳;</span></span><br><span class="line"><span class="comment">//移除时间窗口之前的行为记录, 剩下的都是时间窗口内的</span></span><br><span class="line">pipe.ZRemRangeByScore(key, <span class="string">"0"</span>, fmt.Sprintf(<span class="string">"%v"</span>, now-mperiod))</span><br><span class="line"><span class="comment">// 获取窗口内的行为数量</span></span><br><span class="line">pipe.ZCard(key)</span><br><span class="line"><span class="comment">// 设置zset 过期时间, 避免冷用户持续占用内存</span></span><br><span class="line"><span class="comment">// 过期时间应该等于时间窗口的长度, 再多宽限1s</span></span><br><span class="line">pipe.Expire(key, time.Duration(period+<span class="number">1</span>))</span><br><span class="line"><span class="comment">//执行</span></span><br><span class="line">res, err := pipe.Exec()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Println(err)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line">cmd, ok := res[<span class="number">2</span>].(*redis.IntCmd)</span><br><span class="line"><span class="keyword">if</span> ok &#123;</span><br><span class="line"><span class="keyword">return</span> cmd.Val() &lt;= maxCount</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>output<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">2018/10/23 11:50:01 redis service is ready.</span><br><span class="line">nums: 1  result: true</span><br><span class="line">nums: 2  result: true</span><br><span class="line">nums: 3  result: true</span><br><span class="line">nums: 4  result: true</span><br><span class="line">nums: 5  result: true</span><br><span class="line">nums: 6  result: false</span><br><span class="line">nums: 7  result: false</span><br><span class="line">nums: 8  result: false</span><br><span class="line">nums: 9  result: false</span><br><span class="line">nums: 10  result: false</span><br></pre></td></tr></table></figure></p><blockquote><p>执行结果可知，通过统计滑动窗口内的行为数量与阈值<code>maxCount</code>进行比较就可以得出当前的行为是否允许, 从而起到限流策略;</p></blockquote><blockquote><p>因为这几个连续的 Redis 操作都是针对同一个<code>key</code>的，使用<code>pipeline</code>可以显著提升<code>redis</code>存取效率。</p></blockquote><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>通过限制规定时间内用户行为次数的场景，引入<code>redis</code>在限流策略中的应用，并给出实例分析及代码验证说明;</li><li>但这种方案也有缺点，因为它要记录时间窗口内所有的行为记录，如果这个量很大，比如限定<code>60s</code>内操作不得超过<code>100w</code>次这样的参数，它是不适合做这样的限流的，因为会消耗大量的存储空间。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;限流算法在分布式领域是一个经常被提起的话题，当系统的处理能力有限时，如何阻止计划外的请求继续对系统施压，这是一个需要重视的问题。除了控制流量，限流还有一个应用目的是用于控制用户行为，避免垃圾请求。比如在&lt;code&gt;UGC&lt;/code&gt;社区, &lt;code&gt;用户的发帖&lt;/code&gt;, &lt;code&gt;回复&lt;/code&gt;, &lt;code&gt;点赞&lt;/code&gt;等行为都要严格受控，一般要严格限定某行为在规定时间内允许的次数，超过了次数那就是非法行为。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题06 布隆过滤器</title>
    <link href="http://researchlab.github.io/2018/10/03/redis-06-bloom-filter/"/>
    <id>http://researchlab.github.io/2018/10/03/redis-06-bloom-filter/</id>
    <published>2018-10-03T16:57:48.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p>灰常方便用<code>redis</code>的<code>HyperLogLog</code>来<strong>进行数值估数</strong>, <u><strong>可以解决很多精确度不高的统计需求。</strong></u></p><p>但是如果想知道某一个值是不是已经在<code>HyperLogLog</code>结构里面了，它就无能为力了，它只提供了<code>pfadd</code>, <code>pfcount</code>和<code>pfmerge</code>等方法，没有提供<code>pfcontains</code>这样类似的方法。<br><a id="more"></a></p><p>讲个使用场景，比如我们在使用新闻客户端看新闻时，它会给我们不停地推荐新的内容，它每次推荐时要去重，去掉那些已经看过的内容。问题来了，新闻客户端推荐系统如何实现推送去重的？</p><p>你会想到服务器记录了用户看过的所有历史记录，当推荐系统推荐新闻时会从每个用户的历史记录里进行筛选，过滤掉那些已经存在的记录。问题是当用户量很大，每个用户看过的新闻又很多的情况下，这种方式，推荐系统的去重工作在性能上跟的上么？</p><p>实际上，如果历史记录存储在关系数据库里，去重就需要频繁地对数据库进行<code>exists</code>查询，当系统并发量很高时，数据库是很难扛住压力的。</p><p>你可能又想到了缓存，但是如此多的历史记录全部缓存起来，那得浪费多大存储空间啊？而且这个存储空间是随着时间线性增长，你撑得住一个月，你能撑得住几年么？但是不缓存的话，性能又跟不上，这该怎么办？</p><p>这时，<font color="red"><strong><code>布隆过滤器(Bloom Filter)</code>闪亮登场了，它就是专门用来解决这种去重问题的。它在起到去重的同时，在空间上还能节省 90%`以上，只是稍微有那么点不精确，也就是有一定的误判概率。</strong></font></p><blockquote><p>数据量小时， 可以用<code>redis</code>提供的集合<code>set</code>去重;</p></blockquote><blockquote><p>当数据量很大，且没有很严格的精度要求时， 就可以用<code>redis</code>提供的布隆过滤器来去重，而且还能极大的节省空间, 所以在存储空间上相比<code>set</code>集合优势十分明显;</p></blockquote><h5 id="布隆过滤器是什么"><a href="#布隆过滤器是什么" class="headerlink" title="布隆过滤器是什么?"></a>布隆过滤器是什么?</h5><p>布隆过滤器可以理解为一个不怎么精确的<code>set</code>结构，当你使用它的<code>contains</code>方法判断某个对象是否存在时，它可能会误判。但是布隆过滤器也不是特别不精确，只要参数设置的合理，它的精确度可以控制的相对足够精确，只会有小小的误判概率。</p><blockquote><p>当布隆过滤器说某个值存在时，这个值可能不存在；<br>当它说不存在时，那就肯定不存在。打个比方，当它说不认识你时，肯定就不认识；当它说见过你时，可能根本就没见过面，不过因为你的脸跟它认识的人中某脸比较相似 (某些熟脸的系数组合)，所以误判以前见过你。</p></blockquote><p>套在上面的使用场景中，布隆过滤器能准确过滤掉那些已经看过的内容，那些没有看过的新内容，它也会过滤掉极小一部分 (误判)，但是绝大多数新内容它都能准确识别。这样就可以完全保证推荐给用户的内容都是无重复的。</p><h5 id="redis中布隆过滤器基本使用"><a href="#redis中布隆过滤器基本使用" class="headerlink" title="redis中布隆过滤器基本使用"></a>redis中布隆过滤器基本使用</h5><h6 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h6><p><code>redis</code>官方提供的布隆过滤器到了<code>redis4.0</code>提供了插件功能之后才正式登场。布隆过滤器作为一个插件加载到<code>Redis Server</code>中，给<code>Redis</code>提供了强大的布隆去重功能。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">➜  02 docker exec -it myredis redis-cli --version</span><br><span class="line">redis-cli 4.0.11</span><br><span class="line">➜  02 docker pull redislabs/rebloom</span><br><span class="line">➜  02 docker run -itd --name redisbloom -p6378:6379 redislabs/rebloom</span><br><span class="line">➜  02 docker exec -it redisbloom redis-cli</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p><p>布隆过滤器有二个基本指令，<code>bf.add</code>添加元素，<code>bf.exists</code>查询元素是否存在，它的用法和<code>set</code>集合的<code>sadd</code>和 <code>sismember</code>差不多。注意<code>bf.add</code>只能一次添加一个元素，如果想要一次添加多个，就需要用到<code>bf.madd</code>指令。同样如果需要一次查询多个元素是否存在，就需要用到<code>bf.mexists</code>指令。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; bf.add visitor user1</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加的元素如果原来不存在 则返回1， 否则返回0</span></span><br><span class="line">127.0.0.1:6379&gt; bf.add visitor user1</span><br><span class="line">(integer) 0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> bf.madd 返回值为数组</span></span><br><span class="line">127.0.0.1:6379&gt; bf.madd visitor user2 user3</span><br><span class="line">1) (integer) 1</span><br><span class="line">2) (integer) 1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> bf.exists 如果存在返回1， 否则返回0;</span></span><br><span class="line">127.0.0.1:6379&gt; bf.exists visitor user1</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">bf.mexists 返回一个数组， 1表示存在， 0表示不存在;</span></span><br><span class="line">127.0.0.1:6379&gt; bf.mexists visitor user1 user2 user3</span><br><span class="line">1) (integer) 1</span><br><span class="line">2) (integer) 1</span><br><span class="line">3) (integer) 1</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p><p><code>布隆过滤器</code>判断元素是否存在时，存在一定的误差， 可以通过调节<code>布隆过滤器</code>参数来降低误差值， 在没有设置误差参数值时，<code>redis</code>会启用布隆过滤器的默认参数，它在第一次<code>add</code>的时候自动创建。用户可以在<code>add</code>之前使用<code>bf.reserve</code>指令显式自定义布隆过滤器参数值。如果对应的<code>key</code>已经存在，<code>bf.reserve</code>会报错。<code>bf.reserve</code>有三个参数，分别是<code>key</code>, <code>error_rate</code>和<code>initial_size</code>。错误率越低，需要的空间越大。<code>initial_size</code>参数表示预计放入的元素数量，当实际数量超出这个数值时，误判率会上升。所以需要提前设置一个较大的数值避免超出导致误判率升高。</p><blockquote><p>默认的<code>error_rate</code>是<code>0.01</code>，默认的<code>initial_size</code>是<code>100</code>。</p></blockquote><blockquote><p>布隆过滤器的<code>initial_size</code>估计的过大，会浪费存储空间，估计的过小，就会影响准确率，用户在使用之前一定要尽可能地精确估计好元素数量，还需要加上一定的冗余空间以避免实际元素可能会意外高出估计值很多。</p></blockquote><blockquote><p>布隆过滤器的<code>error_rate</code>越小，需要的存储空间就越大，对于不需要过于精确的场合，<code>error_rate</code>设置稍大一点也无伤大雅。比如在新闻去重上而言，误判率高一点只会让小部分文章不能让合适的人看到，文章的整体阅读量不会因为这点误判率就带来巨大的改变。</p></blockquote><h5 id="布隆过滤器实现原理"><a href="#布隆过滤器实现原理" class="headerlink" title="布隆过滤器实现原理"></a>布隆过滤器实现原理</h5><p>每个<code>布隆过滤器</code>对应到<code>redis</code>的数据结构里面就是一个大型的<code>位数组</code>和几个不一样的<code>无偏hash函数</code>。</p><blockquote><p><code>无偏</code>就是能够把元素的<code>hash</code>值算得比较均匀。</p></blockquote><p>向<code>布隆过滤器</code>中添加<code>key</code>时，会使用多个<code>hash</code>函数对<code>key</code>进行<code>hash</code>算得一个<code>整数索引值</code>然后对位数组长度进行取模运算得到一个位置，每个<code>hash</code>函数都会算得一个不同的位置。再把位数组的这几个位置都置为<code>1</code>就完成了<code>add</code>操作。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">       key1     key2</span><br><span class="line">       /  |    /  \</span><br><span class="line">      /   |   /    \</span><br><span class="line">     /    |  /      \</span><br><span class="line">0 0 1 0 0 1  1 0 0 0 1 0 0 0</span><br></pre></td></tr></table></figure><p>向<code>布隆过滤器</code>询问<code>key</code>是否存在时，跟<code>add</code>一样，也会把<code>hash</code>的几个位置都算出来，看看位数组中这几个位置是否都为<code>1</code>，只要有一个位为<code>0</code>，那么说明布隆过滤器中这个<code>key</code>不存在。如果都是<code>1</code>，这并不能说明这个<code>key</code>就一定存在，只是极有可能存在，因为这些位被置为<code>1</code>可能是因为其它的<code>key</code>存在所致。如果这个位数组比较稀疏，判断正确的概率就会很大，如果这个位数组比较拥挤，判断正确的概率就会降低。</p><p>使用时不要让实际元素远大于初始化大小，当实际元素开始超出初始化大小时，应该对<code>布隆过滤器</code>进行重建，重新分配一个<code>size</code>更大的过滤器，再将所有的历史元素批量<code>add</code>进去 (这就要求我们在其它的存储器中记录所有的历史元素)。因为<code>error_rate</code>不会因为数量超出就急剧增加，这就给我们重建过滤器提供了较为宽松的时间。</p><h5 id="占用空间估计"><a href="#占用空间估计" class="headerlink" title="占用空间估计"></a>占用空间估计</h5><p><code>布隆过滤器</code>有两个参数，第一个是预计元素的数量<code>n</code>，第二个是错误率<code>f</code>。公式根据这两个输入得到两个输出，第一个输出是<code>位数组</code>的长度<code>l</code>，也就是需要的存储空间大小<code>(bit)</code>，第二个输出是<code>hash</code>函数的最佳数量<code>k</code>。<code>hash</code>函数的数量也会直接影响到错误率，最佳的数量会有最低的错误率。<code>布隆过滤器</code>的空间占用有一个简单的计算公式，<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">k=0.7*(l/n)  # 约等于</span><br><span class="line">f=0.6185^(l/n)  # ^ 表示次方计算，也就是 math.pow</span><br></pre></td></tr></table></figure></p><p>从公式中可以看出</p><p>位数组相对越长<code>(l/n)</code>，错误率<code>f</code>越低，这个和直观上理解是一致的<br>位数组相对越长<code>(l/n)</code>，hash<code>函数需要的最佳数量也越多，影响计算效率当一个元素平均需要</code>1<code>个字节</code>(8bit)<code>的指纹空间时</code>(l/n=8)<code>，错误率大约为</code>2%`</p><blockquote><p>错误率为<code>10%</code>，一个元素需要的平均指纹空间为<code>4.792</code>个<code>bit</code>，大约为<code>5bit</code><br>错误率为<code>1%</code>，一个元素需要的平均指纹空间为<code>9.585</code>个<code>bit</code>，大约为<code>10bit</code><br>错误率为<code>0.1%</code>，一个元素需要的平均指纹空间为<code>14.377</code>个 bit，大约为<code>15bit</code></p></blockquote><p>你也许会想，如果一个元素需要占据<code>15</code>个<code>bit</code>，那相对<code>set</code>集合的空间优势是不是就没有那么明显了？</p><blockquote><p><u><strong>这里需要明确的是，<code>set</code>中会存储每个元素的内容，而<code>布隆过滤器</code>仅仅存储元素的指纹。元素的内容大小就是字符串的长度，它一般会有多个字节，甚至是几十个上百个字节，每个元素本身还需要一个指针被<code>set</code>集合来引用，这个指针又会占去<code>4</code>个字节或<code>8</code>个字节，取决于系统是 32bit 还是 64bit。而指纹空间只有接近<code>2</code>个字节，所以布隆过滤器的空间优势还是非常明显的。</strong></u></p></blockquote><p>当实际元素超出预计元素时，错误率会有多大变化，它会急剧上升么，还是平缓地上升，这就需要另外一个公式，引入参数<code>t</code>表示实际元素和预计元素的倍数<code>t</code><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f=(1-0.5^t)^k  # 极限近似，k 是 hash 函数的最佳数量</span><br></pre></td></tr></table></figure></p><p>当<code>t</code>增大时，错误率，<code>f</code>也会跟着增大，分别选择错误率为<code>10%,1%,0.1%</code>的<code>k</code>值，实验得知</p><blockquote><p>错误率为<code>10%</code>时，倍数比为<code>2</code>时，错误率就会升至接近<code>40%</code>，这个就比较危险了<br>错误率为<code>1%</code>时，倍数比为<code>2</code>时，错误率升至<code>15%</code>，也挺可怕的<br>错误率为<code>0.1%</code>，倍数比为<code>2</code>时，错误率升至<code>5%</code>，也比较悬了</p></blockquote><h5 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h5><blockquote><p>在爬虫系统中，我们需要对<code>URL</code>进行去重，已经爬过的网页就可以不用爬了。但是<code>URL</code>太多了，几千万几个亿，如果用一个集合装下这些<code>URL</code>地址那是非常浪费空间的。这时候就可以考虑使用布隆过滤器。它可以大幅降低去重存储消耗，只不过也会使得爬虫系统错过少量的页面。</p></blockquote><blockquote><p>布隆过滤器在<code>NoSQL</code>数据库领域使用非常广泛，我们平时用到的<code>HBase</code>、<code>Cassandra</code>还有<code>LevelDB</code>、<code>RocksDB</code>内部都有布隆过滤器结构，布隆过滤器可以显著降低数据库的<code>IO</code>请求数量。当用户来查询某个<code>row</code>时，可以先通过内存中的布隆过滤器过滤掉大量不存在的<code>row</code>请求，然后再去磁盘进行查询。</p></blockquote><blockquote><p>邮箱系统的垃圾邮件过滤功能也普遍用到了布隆过滤器，因为用了这个过滤器，所以平时也会遇到某些正常的邮件被放进了垃圾邮件目录中，这个就是误判所致，概率很低。</p></blockquote><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li><code>布隆过滤</code>（Bloom Filter）是由布隆（Burton Howard Bloom）在1970年提出的。<u>它实际上是由一个很长的二进制向量和一系列随机映射函数组成，布隆过滤器可以用于检索一个元素是否在一个集合中</u>。本文引入了其基本原理，并给出实例分析;</li><li>它的优点是<code>空间效率和查询时间</code>都远远超过一般的算法，布隆过滤器存储空间和插入/查询时间都是常数。另外, Hash 函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势。</li><li><p>缺点是有一定的误识别率（假正例False positives，即Bloom Filter报告某一元素存在于某集合中，但是实际上该元素并不在集合中）和删除困难，但是没有识别错误的情形（即假反例False negatives，如果某个元素确实没有在该集合中，那么Bloom Filter 是不会报告该元素存在于集合中的，所以不会漏报）。</p></li><li><p>目前我们知道布隆过滤器可以支持<code>add</code>和<code>isExist</code>操作，那么<code>delete</code>操作可以么，很难实现， 如位数组中的<code>bit</code>位 被两个值共同覆盖的话，一旦你删除其中一个值而将其置位<code>0</code>，那么下次判断另一个值是否存在的话，会直接返回<code>false</code>，而实际上你并没有删除它。如何解决这个问题，答案是<code>计数删除</code>。但是计数删除需要存储一个数值，而不是原先的<code>bit</code>位，会增大占用的内存大小。这样的话，增加一个值就是将对应索引槽上存储的值加一，删除则是减一，判断是否存在则是看值是否大于0。</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;灰常方便用&lt;code&gt;redis&lt;/code&gt;的&lt;code&gt;HyperLogLog&lt;/code&gt;来&lt;strong&gt;进行数值估数&lt;/strong&gt;, &lt;u&gt;&lt;strong&gt;可以解决很多精确度不高的统计需求。&lt;/strong&gt;&lt;/u&gt;&lt;/p&gt;
&lt;p&gt;但是如果想知道某一个值是不是已经在&lt;code&gt;HyperLogLog&lt;/code&gt;结构里面了，它就无能为力了，它只提供了&lt;code&gt;pfadd&lt;/code&gt;, &lt;code&gt;pfcount&lt;/code&gt;和&lt;code&gt;pfmerge&lt;/code&gt;等方法，没有提供&lt;code&gt;pfcontains&lt;/code&gt;这样类似的方法。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>Socket套接字概念</title>
    <link href="http://researchlab.github.io/2018/09/20/socket-concept/"/>
    <id>http://researchlab.github.io/2018/09/20/socket-concept/</id>
    <published>2018-09-20T19:32:29.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p>套接字是一种通信机制(通信的两方的一种约定), 凭借这种机制, 不同主机之间的进程可以进行通信。下面通过套接字中的相关函数来进一步学习理解通信过程;<br><a id="more"></a></p><h5 id="套接字"><a href="#套接字" class="headerlink" title="套接字"></a>套接字</h5><hr><p>套接字有域(domain), 类型(type), 和协议(protocol)三个属性;</p><ul><li>域<blockquote><p>域指定套接字通信中使用的网络介质。最常见的套接字域是 AF_INET, 它是指 Internet 网络, 许多 Linux 局域网使用的都是该网络, 当然, 因特网自身用的也是它。</p></blockquote></li></ul><ul><li>套接字类型</li></ul><table><thead><tr><th style="text-align:left">套接字类型</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">流套接字(SOCK_STREAM)</td><td style="text-align:left">流套接字用于提供面向连接、可靠的数据传输服务。该服务将保证数据能够实现无差错、无重复发送, 并按顺序接收。流套接字之所以能够实现可靠的数据服务, 原因在于其使用了传输控制协议, 即TCP(The Transmission Control Protocol)协议。</td></tr><tr><td style="text-align:left">数据报套接字(SOCK_DGRAM)</td><td style="text-align:left">数据报套接字提供了一种无连接的服务。该服务并不能保证数据传输的可靠性, 数据有可能在传输过程中丢失或出现数据重复, 且无法保证顺序地接收到数据。数据报套接字使用UDP(User Datagram Protocol)协议进行数据的传输。由于数据报套接字不能保证数据传输的可靠性, 对于有可能出现的数据丢失情况, 需要在程序中做相应的处理。</td></tr><tr><td style="text-align:left">原始套接字(SOCK_RAW)</td><td style="text-align:left">原始套接字与标准套接字(标准套接字指的是前面介绍的流套接字和数据报套接字)的区别在于: 原始套接字可以读写内核没有处理的IP数据包, 而流套接字只能读取TCP协议的数据, 数据报套接字只能读取UDP协议的数据。因此, 如果要访问其他协议发送数据必须使用原始套接字。</td></tr></tbody></table><ul><li>套接字协议(协议类别)<blockquote><p>只要底层的传输机制允许不止一个协议来提供要求的套接字类型, 我们就可以为套接字选择一个特定的协议。通常使用默认即可(也就是最后一个参数填”0”)。</p></blockquote></li></ul><h5 id="创建套接字"><a href="#创建套接字" class="headerlink" title="创建套接字"></a>创建套接字</h5><hr><p>socket系统调用创建一个套接字并返回一个描述符, 该描述符可以用来访问该套接字。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">include &lt;sys/socket.h&gt;</span></span><br><span class="line">int socket(int family,int type,int protocol);</span><br></pre></td></tr></table></figure></p><p><strong>功能</strong><br>创建一个用于网络通信的 socket 套接字(描述符)</p><p><strong>参数</strong><br>family: 协议族(AF_UNIX、AF_INET、AF_INET6、PF_PACKET等)</p><blockquote><p>最常见的套接字域是 AF_UNIX 和 AF_INET, 前者用于通过 Unix 和 Linux 文件系统实现的本地套接字, 后者用于 Unix 网络套接字。AF_INET 套接字可以用于通过包括因特网在内的 TCP/IP 网络进行通信的程序。微软 Windows 系统的 winsock 接口也提供了对这个套接字域的访问功能。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * Address families.</span><br><span class="line"> */</span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_UNSPEC       0               /* unspecified */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_UNIX         1               /* <span class="built_in">local</span> to host (pipes, portals) */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_INET         2               /* internetwork: UDP, TCP, etc. */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_IMPLINK      3               /* arpanet imp addresses */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_PUP          4               /* pup protocols: e.g. BSP */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_CHAOS        5               /* mit CHAOS protocols */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_IPX          6               /* IPX and SPX */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_NS           6               /* XEROX NS protocols */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_ISO          7               /* ISO protocols */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_OSI          AF_ISO          /* OSI is ISO */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_ECMA         8               /* european computer manufacturers */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_DATAKIT      9               /* datakit protocols */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_CCITT        10              /* CCITT protocols, X.25 etc */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_SNA          11              /* IBM SNA */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_DECnet       12              /* DECnet */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_DLI          13              /* Direct data link interface */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_LAT          14              /* LAT */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_HYLINK       15              /* NSC Hyperchannel */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_APPLETALK    16              /* AppleTalk */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_NETBIOS      17              /* NetBios-style addresses */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_VOICEVIEW    18              /* VoiceView */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_FIREFOX      19              /* FireFox */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_UNKNOWN1     20              /* Somebody is using this! */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_BAN          21              /* Banyan */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define AF_MAX          22</span></span><br></pre></td></tr></table></figure><p>type: 套接字类型(SOCK_STREAM、SOCK_DGRAM、SOCK_RAW等)<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * Types</span><br><span class="line"> */</span><br><span class="line"><span class="meta">#</span><span class="bash">define SOCK_STREAM     1               /* stream socket */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define SOCK_DGRAM      2               /* datagram socket */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define SOCK_RAW        3               /* raw-protocol interface */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define SOCK_RDM        4               /* reliably-delivered message */</span></span><br><span class="line"><span class="meta">#</span><span class="bash">define SOCK_SEQPACKET  5               /* sequenced packet stream */</span></span><br></pre></td></tr></table></figure></p><p>protocol: 协议类别(0、IPPROTO_TCP、IPPROTO_UDP等), 设为 0 表示使用默认协议。</p><p><strong>返回</strong></p><table><thead><tr><th style="text-align:left">状态</th><th style="text-align:left">返回值</th></tr></thead><tbody><tr><td style="text-align:left">成功</td><td style="text-align:left">套接字</td></tr><tr><td style="text-align:left">失败</td><td style="text-align:left">(&lt;0)</td></tr></tbody></table><p>Reference</p><hr><p>[1] <a href="https://blog.csdn.net/tennysonsky/article/details/45047209" target="_blank" rel="noopener">Linux 网络编程——套接字的介绍</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;套接字是一种通信机制(通信的两方的一种约定), 凭借这种机制, 不同主机之间的进程可以进行通信。下面通过套接字中的相关函数来进一步学习理解通信过程;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="DevOps" scheme="http://researchlab.github.io/categories/DevOps/"/>
    
    
      <category term="socket" scheme="http://researchlab.github.io/tags/socket/"/>
    
  </entry>
  
  <entry>
    <title>TCP通信过程完整分析</title>
    <link href="http://researchlab.github.io/2018/08/27/tcp-communication/"/>
    <id>http://researchlab.github.io/2018/08/27/tcp-communication/</id>
    <published>2018-08-27T18:32:59.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p>学习<code>TCP</code>连接需要三次握手四次挥手过程后, 进一步分析学习<code>TCP</code>连接通信过程及过程状态信息, 将有助于排除和定位网络或系统故障;<br><a id="more"></a></p><h5 id="TCP通信完整过程"><a href="#TCP通信完整过程" class="headerlink" title="TCP通信完整过程"></a>TCP通信完整过程</h5><hr><p><strong>TCP通信过程</strong><br><img src="/2018/08/27/tcp-communication/state02.png" alt=""></p><p><strong>TCP通信过程状态信息</strong><br><img src="/2018/08/27/tcp-communication/state01.png" alt=""></p><h5 id="TCP通信过程状态"><a href="#TCP通信过程状态" class="headerlink" title="TCP通信过程状态"></a>TCP通信过程状态</h5><hr><p>深入理解<code>TCP</code>通信过程, 对排除和定位网络或系统故障时大有帮助, 但是怎样牢牢地将这张图刻在脑中呢？ 那么你就一定要对这张图的每一个状态, 及转换的过程有深刻的认识, 不能只停留在一知半解之中。下面对这张图的11种状态详细解析一下, </p><table><thead><tr><th style="text-align:left"></th><th style="text-align:left">状态</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left"><code>CLOSED</code></td><td style="text-align:left">表示初始状态。</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left"><code>LISTEN</code></td><td style="text-align:left">表示服务器端的某个 <code>SOCKET</code> 处于监听状态, 可以接收连接了。</td></tr><tr><td style="text-align:left">3</td><td style="text-align:left"><code>SYN_RCVD</code></td><td style="text-align:left">这个状态表示接收到了 SYN 报文, 在正常情况下, 这个状态是服务器端的<code>SOCKET</code> 在建立 <code>TCP</code> 连接时的三次握手会话过程中的一个中间状态, 很短暂, 基本上用 netstat 你是很难看到这种状态的, 除非你特意写了一个客户端测试程序, 故意将三次 <code>TCP</code> 握手过程中最后一个 <code>ACK</code> 报文不予发送。因此这种状态时, 当收到客户端的 <code>ACK</code> 报文后, 它会进入到 ESTABLISHED 状态。</td></tr><tr><td style="text-align:left">4</td><td style="text-align:left"><code>SYN_SENT</code></td><td style="text-align:left">这个状态与 <code>SYN_RCVD</code> 相呼应, 当客户端 <code>SOCKET</code> 执行 <code>CONNECT</code> 连接时, 它首先发送<code>SYN</code>报文, 因此也随即它会进入到了 <code>SYN_SENT</code> 状态, 并等待服务端的发送三次握手中的第 2 个报文。<code>SYN_SENT</code> 状态表示客户端已发送<code>SYN</code>报文。</td></tr><tr><td style="text-align:left">5</td><td style="text-align:left"><code>ESTABLISHED</code></td><td style="text-align:left">表示连接已经建立了。</td></tr><tr><td style="text-align:left">6</td><td style="text-align:left"><code>FIN_WAIT_1</code></td><td style="text-align:left"><code>FIN_WAIT_1</code> 和 <code>FIN_WAIT_2</code> 状态的真正含义都是表示等待对方的 FIN 报文。而这两种状态的区别是: <code>FIN_WAIT_1</code> 状态实际上是当 <code>SOCKET</code> 在 <code>ESTABLISHED</code> 状态时, 它想主动关闭连接, 向对方发送了 FIN 报文, 此时该 <code>SOCKET</code> 即进入到 <code>FIN_WAIT_1</code> 状态。而当对方回应 <code>ACK</code> 报文后, 则进入到 <code>FIN_WAIT_2</code> 状态, 当然在实际的正常情况下, 无论对方何种情况下, 都应该马 上回应 <code>ACK</code> 报文, 所以 <code>FIN_WAIT_1</code> 状态一般是比较难见到的, 而 <code>FIN_WAIT_2</code> 状态还有时常常可以用 netstat 看到。</td></tr><tr><td style="text-align:left">7</td><td style="text-align:left"><code>FIN_WAIT_2</code></td><td style="text-align:left"><code>FIN_WAIT_2</code> 状态下的 <code>SOCKET</code>, 表示半连接, 也即有一方要求<code>close</code>连接, 但另外还告诉对方, 我暂时还有点数据需要传送给你, 稍后再关闭连接。</td></tr><tr><td style="text-align:left">8</td><td style="text-align:left"><code>TIME_WAIT</code></td><td style="text-align:left">表示收到了对方的<code>FIN</code>报文, 并发送出了 <code>ACK</code> 报文, 就等<code>2MSL</code>后即可回到<code>CLOSED</code>可用状态了。如果 <code>FIN_WAIT_1</code> 状态下, 收到了对方同时带<code>FIN</code>标志和<code>ACK</code> 标志的报文时, 可以直接进入到<code>TIME_WAIT</code>状态, 而无须经过 <code>FIN_WAIT_2</code> 状态。</td></tr><tr><td style="text-align:left">9</td><td style="text-align:left"><code>CLOSING</code></td><td style="text-align:left">(图中没有标志这种状态) 这种状态比较特殊, 实际情况中应该是很少见, 属于一种比较罕见的例外状态。正常情况下, 当你发送 <code>FIN</code> 报文后, 按理来说是应该先收到（或同时收到）对方的 <code>ACK</code> 报文, 再收到对方的 <code>FIN</code> 报文。但是 CLOSING 状态表示你发送 <code>FIN</code> 报文后, 并没有收到对方的 <code>ACK</code> 报文, 反而却也收到了对方的 <code>FIN</code> 报文。什么情况下会出现此种情况呢？其实细想一下, 也不难得出结论: 那就是如果双方几乎在同时<code>close</code>一个 <code>SOCKET</code> 的话, 那么就出现了双方同时发送 <code>FIN</code> 报文的情况, 也即会出现<code>CLOSING</code>状态, 表示双方都正在关闭 <code>SOCKET</code> 连接。</td></tr><tr><td style="text-align:left">10</td><td style="text-align:left"><code>CLOSE_WAIT</code></td><td style="text-align:left">这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方 <code>close</code> 一个 <code>SOCKET</code> 后发送 FIN 报文给自己, 系统毫无疑问地会回应一个 <code>ACK</code> 报文给对方, 此时则进入到 <code>CLOSE_WAIT</code> 状态。接下来若没有数据要发送给对方, 就可以 <code>close</code> 这个 <code>SOCKET</code>, 发送<code>FIN</code>报文给对方, 也即关闭连接。所以你在 <code>CLOSE_WAIT</code> 状态下, 需要完成的事情是等待你去关闭连接。</td></tr><tr><td style="text-align:left">11</td><td style="text-align:left"><code>LAST_ACK</code></td><td style="text-align:left">它是被动关闭一方在发送 FIN 报文后, 最后等待对方的 <code>ACK</code> 报文。当收到 <code>ACK</code> 报文后, 也即可以进入到<code>CLOSED</code>可用状态了。</td></tr></tbody></table><p>Reference</p><hr><p>[1] <a href="https://blog.csdn.net/tennysonsky/article/details/45646561" target="_blank" rel="noopener">TCP 通信过程中各步骤的状态</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;学习&lt;code&gt;TCP&lt;/code&gt;连接需要三次握手四次挥手过程后, 进一步分析学习&lt;code&gt;TCP&lt;/code&gt;连接通信过程及过程状态信息, 将有助于排除和定位网络或系统故障;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="DevOps" scheme="http://researchlab.github.io/categories/DevOps/"/>
    
    
      <category term="TCP" scheme="http://researchlab.github.io/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>TCP三次握手和四次挥手过程完整分析</title>
    <link href="http://researchlab.github.io/2018/08/26/tcp-established-closed-process/"/>
    <id>http://researchlab.github.io/2018/08/26/tcp-established-closed-process/</id>
    <published>2018-08-26T15:59:57.000Z</published>
    <updated>2018-10-26T12:04:15.902Z</updated>
    
    <content type="html"><![CDATA[<p>理解<code>TCP</code>连接三次握手和四次挥手过程对深入学习应用<code>TCP</code>网络编程十分重要, 相关网络资源也灰常丰富,  本文对<code>TCP</code>建立和关闭连接中的三次握手和四次挥手过程进行完整分析, 同时参考网络学习资源归纳总结成文;<br><a id="more"></a></p><h5 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h5><hr><p>在<code>TCP/IP</code>协议中, <code>TCP</code>协议提供可靠的连接服务, 采用三次握手建立一个连接。</p><p><img src="/2018/08/26/tcp-established-closed-process/established01.png" alt=""></p><p><strong>第一次握手:</strong> 建立连接时, 客户端发送<code>SYN</code>包(syn=j)到服务器, 并进入 <code>SYN_SEND</code> 状态, 等待服务器确认;  </p><p><strong>第二次握手:</strong> 服务器收到<code>SYN</code>包, 必须确认客户的 <code>SYN</code>（ack=j+1）, 同时自己也发送一个 <code>SYN</code> 包（syn=k）, 即 <code>SYN</code>+<code>ACK</code> 包, 此时服务器进入 SYN_RECV 状态;  </p><p><strong>第三次握手:</strong> 客户端收到服务器的 <code>SYN</code>＋<code>ACK</code> 包, 向服务器发送确认包 <code>ACK</code>(ack=k+1), 此包发送完毕, 客户端和服务器进入 <code>ESTABLISHED</code> 状态, 完成三次握手。</p><p><img src="/2018/08/26/tcp-established-closed-process/established02.png" alt=""></p><p>通过这样的三次握手, 客户端与服务端建立起可靠的<code>双工</code>的连接, 开始传送数据。 三次握手的最主要目的是保证连接是<code>双工</code>的, 可靠更多的是通过重传机制来保证的。</p><p><strong> 但是为什么一定要进行三次握手来保证连接是<code>双工</code>的呢, 一次握手不行么？两次不行么？</strong></p><p>前两次握手是为了保证服务端能收接受到客户端的信息并能做出正确的应答, 为了保证客户端能够接收到服务端的信息并能做出正确的应答而进行后两次(第二次和第三次)握手。 </p><h5 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h5><hr><p>由于 <code>TCP</code> 连接是<code>全双工</code>的, 因此每个方向都必须单独进行关闭。那<code>TCP</code> 的四次握手, 是为了保证通信双方都关闭了连接, 具体过程如下: </p><p><img src="/2018/08/26/tcp-established-closed-process/tcp_close.png" alt=""></p><p>1）客户端发送一个 <code>FIN</code>, 用来关闭客户端到服务器的数据传送;<br>2）服务器收到这个 <code>FIN</code>, 它发回一个 <code>ACK</code>, 确认序号为收到的序号加 1。和 <code>SYN</code> 一样, 一个<code>FIN</code>将占用一个序号;<br>3）服务器关闭与客户端的连接, 发送一个<code>FIN</code>给客户端;<br>4）客户端发回 <code>ACK</code> 报文确认, 并将确认序号设置为收到序号加1。</p><p><img src="/2018/08/26/tcp-established-closed-process/closed.png" alt=""></p><p><strong>为什么建立连接协议是三次握手, 而关闭连接却是四次握手呢？</strong></p><p>这是因为服务端的 <code>LISTEN</code> 状态下的 <code>SOCKET</code> 当收到 <code>SYN</code> 报文的建连请求后, 它可以把 <code>ACK</code> 和 <code>SYN</code>（<code>ACK</code> 起应答作用, 而 <code>SYN</code> 起同步作用）放在一个报文里来发送。但关闭连接时, 当收到对方的 <code>FIN</code> 报文通知时, 它仅仅表示对方没有数据发送给你了, 但是你还可以给对方发送数据, 也有这么种可能, 你还有一些数据在传给对方的途中, 所以你不能立马关闭连接,也即你可能还需要把在传输途中的数据给对方之后, 又或者, 你还有一些数据需要传输给对方后, （再关闭连接）再发送<code>FIN</code> 报文给对方来表示你同意现在可以关闭连接了, 所以它这里的 <code>ACK</code> 报文和 <code>FIN</code> 报文多数情况下都是分开发送的。</p><p><strong>为什么 <code>TIME_WAIT</code> 状态还需要等<code>2MSL</code>(Wait For Double Maximum Segment Life(MSL) Time) 后才能返回到 <code>CLOSED</code> 状态？</strong></p><p>这是因为虽然双方都同意关闭连接了, 而且握手的<code>4</code>个报文也都协调和发送完毕, 按理可以直接回到 <code>CLOSED</code> 状态（就好比从 <code>SYN_SEND</code> 状态到<code>ESTABLISH</code>状态那样）; 但是因为我们必须要假想网络是不可靠的, 你无法保证你最后发送的 <code>ACK</code> 报文会一定被对方收到, 因此对方处于 <code>LAST_ACK</code> 状态下的 <code>SOCKET</code> 可能会因为超时未收到 <code>ACK</code> 报文, 而重发 <code>FIN</code> 报文, 所以这个<code>TIME_WAIT</code>状态的作用就是用来重发可能丢失的 <code>ACK</code> 报文。</p><p>Reference </p><hr><p>[1] <a href="https://blog.csdn.net/tennysonsky/article/details/45622395" target="_blank" rel="noopener">Linux网络编程——浅谈 TCP 三次握手和四次挥手</a><br>[2] <a href="https://huoding.com/2016/09/05/542" target="_blank" rel="noopener">关于FIN_WAIT2</a><br>[3] <a href="https://blog.csdn.net/dog250/article/details/81256550" target="_blank" rel="noopener">一个TCP FIN_WAIT2状态细节引发的感慨</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;理解&lt;code&gt;TCP&lt;/code&gt;连接三次握手和四次挥手过程对深入学习应用&lt;code&gt;TCP&lt;/code&gt;网络编程十分重要, 相关网络资源也灰常丰富,  本文对&lt;code&gt;TCP&lt;/code&gt;建立和关闭连接中的三次握手和四次挥手过程进行完整分析, 同时参考网络学习资源归纳总结成文;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="DevOps" scheme="http://researchlab.github.io/categories/DevOps/"/>
    
    
      <category term="TCP" scheme="http://researchlab.github.io/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>Docker操作提示Get Permission Denied</title>
    <link href="http://researchlab.github.io/2018/06/06/docker-permission-denied/"/>
    <id>http://researchlab.github.io/2018/06/06/docker-permission-denied/</id>
    <published>2018-06-06T15:40:41.000Z</published>
    <updated>2018-10-26T12:04:15.890Z</updated>
    
    <content type="html"><![CDATA[<p>在ubuntu16.04上重新安装docker后，执行docker相关命令，出现”Got permission denied”提示,如下,<br><a id="more"></a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~ » docker ps </span><br><span class="line">Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.37/containers/json: dial unix /var/run/docker.sock: connect: permission denied</span><br></pre></td></tr></table></figure></p><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>摘自docker mannual上的一段话<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Manage Docker as a non-root user</span><br><span class="line"></span><br><span class="line">The docker daemon binds to a Unix socket instead of a TCP port. By default that Unix socket is owned by the user root and other users can only access it using sudo. The docker daemon always runs as the root user.</span><br><span class="line"></span><br><span class="line">If you don’t want to use sudo when you use the docker command, create a Unix group called docker and add users to it. When the docker daemon starts, it makes the ownership of the Unix socket read/writable by the docker group.</span><br></pre></td></tr></table></figure></p><p>大概的意思就是：docker进程使用Unix Socket而不是TCP端口。而默认情况下，Unix socket属于root用户，需要root权限才能访问。</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>docker守护进程启动的时候，会默认赋予名字为docker的用户组读写Unix socket的权限，因此只要创建docker用户组，并将当前用户加入到docker用户组中，那么当前用户就有权限访问Unix socket了，进而也就可以执行docker相关命令;<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo groupadd docker#添加docker用户组</span><br><span class="line">sudo gpasswd -a $USER docker #将登陆用户加入到docker用户组中</span><br><span class="line">newgrp docker#更新用户组</span><br><span class="line">docker ps#测试docker命令是否可以使用sudo正常使用</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在ubuntu16.04上重新安装docker后，执行docker相关命令，出现”Got permission denied”提示,如下,&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="docker-practice" scheme="http://researchlab.github.io/categories/docker-practice/"/>
    
    
      <category term="docker" scheme="http://researchlab.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>redis专题05 海量数据处理之HyperLogLog</title>
    <link href="http://researchlab.github.io/2018/02/18/redis-05-hyperloglog/"/>
    <id>http://researchlab.github.io/2018/02/18/redis-05-hyperloglog/</id>
    <published>2018-02-18T18:48:44.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p><code>HyperLoglog</code>是<code>redis</code>新支持的两种类型中的另外一种(上一种是位图类型<code>Bitmaps</code>)。主要适用场景是海量数据的计算。特点是速度快, 占用空间小。<br><a id="more"></a><br>同样是用于计算，<code>Bitmaps</code>可能更适合用于验证的大数据，比如签到，记录某用户是不是当天进行了签到，签到了多少天的时候。也就是说，你不光需要记录数据，还需要对数据进行验证的时候使用<code>Bitmaps</code>。</p><p>而<code>HyperLoglog</code>则用于只记录的时候，如统计每个网页每天的访问UV,</p><p>如果统计<code>PV</code>那非常好办，给每个网页一个独立的<code>Redis</code>计数器就可以了，这个计数器的<code>key</code>后缀加上当天的日期。这样来一个请求，<code>incrby</code>一次，最终就可以统计出所有的<code>PV</code>数据。</p><p>但是<code>UV</code>不一样，它要去重，同一个用户一天之内的多次访问请求只能计数一次。这就要求每一个网页请求都需要带上用户的<code>ID</code>，无论是登陆用户还是未登陆用户都需要一个唯一<code>ID</code>来标识。</p><p>你也许已经想到了一个简单的方案，那就是为每一个页面一个独立的<code>set</code>集合来存储所有当天访问过此页面的用户<code>ID</code>。当一个请求过来时，我们使用<code>sadd</code>将用户<code>ID</code>塞进去就可以了。通过<code>scard</code>可以取出这个集合的大小，这个数字就是这个页面的<code>UV</code>数据。没错，这是一个非常简单的方案。</p><p>但如果页面访问量非常大，比如一个爆款页面几千万的<code>UV</code>，你需要一个很大的<code>set</code>集合来统计，这就非常浪费空间。如果这样的页面很多，那所需要的存储空间是惊人的。为这样一个去重功能就耗费这样多的存储空间，值得么？</p><p>由此可以<u>用<code>redis</code>提供的<code>HyperLogLog</code>数据结构来<strong>解决这种统计问题</strong>的</u>。</p><blockquote><p><code>HyperLogLog</code>提供不精确的去重计数方案，虽然不精确但是也不是非常不精确，标准误差是<code>0.81%</code>，这样的精确度已经可以满足上面的<code>UV</code>统计需求了。</p></blockquote><h4 id="HyperLogLog数据结构基础应用"><a href="#HyperLogLog数据结构基础应用" class="headerlink" title="HyperLogLog数据结构基础应用"></a><code>HyperLogLog</code>数据结构基础应用</h4><p><code>redis</code>为操作<code>HyperLogLog</code>数据结构提供了三条命令，</p><ul><li><code>pfadd</code>  添加计数</li><li><code>pfcount</code>  获取计数</li><li><p><code>pfmerge</code> 合并两个数据的数据</p></li><li><p><code>pfadd</code> 添加数据</p></li></ul><blockquote><p>命令：<code>PFADD key element [element ...]</code></p></blockquote><blockquote><ul><li>功能：将除了第一个参数以外的参数存储到以第一个参数为变量名的<code>HyperLogLog</code>结构中。</li></ul></blockquote><blockquote><ul><li>如果一个<code>HyperLogLog</code>的估计的近似基数在执行命令过程中发了变化，<code>PFADD</code>返回1，否则返回0，如果指定的key不存在，这个命令会自动创建一个空的<code>HyperLogLog</code>结构（指定长度和编码的字符串）。</li><li>如果在调用该命令时仅提供变量名而不指定元素也是可以的，如果这个变量名存在，则不会有任何操作，如果不存在，则会创建一个数据结构。</li><li>返回值：如果<code>HyperLogLog</code>的内部被修改了,那么返回 1,否则返回 0 。</li></ul></blockquote><ul><li><code>pfcount</code></li></ul><blockquote><p>命令：<code>PFCOUNT key [key ...]</code></p></blockquote><blockquote><ul><li>功能：当参数为一个<code>key</code>时,返回存储在<code>HyperLogLog</code>结构体的该变量的近似基数，如果该变量不存在,则返回0。</li></ul></blockquote><blockquote><ul><li>当参数为多个<code>key</code>时，返回这些<code>HyperLogLog</code>并集的近似基数，这个值是将所给定的所有<code>key</code>的<code>HyperLoglog</code>结构合并到一个临时的<code>HyperLogLog</code>结构中计算而得到的;</li><li><u><strong><code>HyperLogLog</code>可以使用固定且很少的内存（每个<code>HyperLogLog</code>结构需要12K字节再加上key本身的几个字节）来存储集合的唯一元素。返回的可见集合基数并不是精确值， 而是一个带有 0.81% 标准错误（<code>standard error</code>）的近似值。</strong></u></li><li>返回值：<code>PFADD</code>添加的唯一元素的近似数量;</li></ul></blockquote><p><code>pfadd</code>和<code>pfcount</code>用法和<code>set</code>集合的<code>sadd</code>和<code>scard</code>是一样的，添加数据，获取计数/长度;</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> pfadd 添加计算，若修改了HyperLogLog结构则返回1 ，否则返回0</span></span><br><span class="line">127.0.0.1:6379&gt; pfadd page user1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfadd page user1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; pfcount page</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfadd page user2</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount page</span><br><span class="line">(integer) 2</span><br><span class="line"><span class="meta">#</span><span class="bash"> pfadd 可以一次添加多个计数</span></span><br><span class="line">127.0.0.1:6379&gt; pfadd page user3 user4 user5</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount page</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><ul><li><code>pfmerge</code></li></ul><blockquote><p>命令：<code>PFMERGE destkey sourcekey [sourcekey ...]</code></p></blockquote><blockquote><ul><li>功能：将多个<code>HyperLogLog</code>合并（<code>merge</code>）为一个<code>HyperLogLog</code>, 合并后的<code>HyperLogLog</code>的基数接近于所有输入<code>HyperLogLog</code>的可见集合（<code>observed set</code>）的并集;</li></ul></blockquote><blockquote><ul><li><u>合并得出的<code>HyperLogLog</code>会被储存在目标变量（第一个参数）里面， 如果该键并不存在， 那么命令在执行之前， 会先为该键创建一个空的;</u></li><li>返回值：这个命令只会返回 OK</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; pfadd home user1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount home</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfadd about user1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount about</span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta">#</span><span class="bash"> pfmerge 将home和about两个page的计算合并为total, 注意合并时会将home和about中相同的部分在进行Pfadd加入到新`total` HyperLogLog结构中时， 因其近似基数部分相同所以会被忽略而不会重复计数；</span></span><br><span class="line">127.0.0.1:6379&gt; pfmerge total home about</span><br><span class="line">OK</span><br><span class="line"><span class="meta">#</span><span class="bash"> 合并生成 的total 并不是2 而是1， 因为home和about的计数值都是user1</span></span><br><span class="line">127.0.0.1:6379&gt; pfcount total</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfadd home user2</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount home</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; pfmerge total home about</span><br><span class="line">OK</span><br><span class="line"><span class="meta">#</span><span class="bash"> 再次合并后就变成了2了， 因为不重复访问用户只有 user1, user2</span></span><br><span class="line">127.0.0.1:6379&gt; pfcount total</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; pfcount about</span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 注意pfmerge 是把<span class="built_in">source</span>列表去重后合并到destkey， 如果destkey已经存在，和覆盖其之前值</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 同时合并仅对destkey值产生变更，其他不变</span></span><br><span class="line">127.0.0.1:6379&gt; pfmerge about home</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; pfcount about</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><h4 id="HyperLogLog-实现原理"><a href="#HyperLogLog-实现原理" class="headerlink" title="HyperLogLog 实现原理"></a><code>HyperLogLog</code> 实现原理</h4><p>上述实现过程中可以看到<code>HyperLogLog</code> 在统计计数时可以很好的处理重复值问题， 那它是如何做到的呢？ 这就需要进一步了解<code>HyperLogLog</code>的内部实现原理了，</p><p><code>redis</code>内部<code>HyperLogLog</code>中会先给其分配一定数量的桶， 这些桶就是用来存储创建的<code>key</code>值的， 即<code>pfadd key elmement</code>中的<code>key</code>, 然后通过<code>hash</code>将<code>element</code>存储下来， 这样相同的<code>element</code>的<u><strong>近似基数</strong></u>是一样的，所以相同的<code>element</code>插入不在往桶中添加了，故在<code>pfcount</code>基数时 则只会算一次了，</p><p>上说的<code>pfcount</code>计算的是近似估值，误差在<code>0.81%</code>标准错误, 这是因为<code>HyperLogLog</code>在统计时计算的就是估值而不是精确值，因为在<code>pfadd</code>时是通过<code>element</code>的近似基数进行更新<code>HyperLogLog</code>结构的， 案例分析如下，</p><blockquote><p>`pfadd nums 随机数1， 随机数2， 随机数3 … 随机数N</p></blockquote><figure class="highlight"><font style="color:#817c7c;font-size:90%">高位 &lt;—————– 低位</font><br><br>随机数1   1 0 0 1 0 1 0 1 1 <font style="color:#d14;border:1px solid #d6d6d6; border-radius:0.25em;">0 0 0 0</font><br>随机数2   1 0 0 1 0 1 0 1 0 1 <font style="color:#d14;border:1px solid #d6d6d6; border-radius:0.25em;">0 0 0</font><br>随机数3   1 <font style="color:#d14;border:1px solid #d6d6d6; border-radius:0.25em;">0 0 0 0 0 0 0 0 0 0 0 0</font><br>随机数4   1 0 0 1 0 1 0 1 1 1 1 <font style="color:#d14;border:1px solid #d6d6d6; border-radius:0.25em;">0 0</font><br>随机数5   1 0 0 1 0 1 <font style="color:#d14;border:1px solid #d6d6d6; border-radius:0.25em;">0 0 0 0 0 0 0</font><br>……<br>随机数N   1 0 0 1 <font style="color:#d14;border:1px solid #d6d6d6; border-radius:0.25em;">0 0 0 0 0 0 0 0 0</font><br></figure><p>如上， 给定一系列的随机整数，通过记录下低位连续零位的最大长度<code>k</code>，通过这个<code>k</code>值可以估算出随机数的数量，实验发现<code>K</code>和<code>N</code>的对数之间存在显著的线性相关性, 通过这种线性近似计算可以得到<code>pfcount</code> 指定<code>key</code>的近似估值， 详细的原理这里不在进一步阐述；</p><blockquote><p> 可进一步参看<a href="https://www.slideshare.net/KaiZhang130/countdistinct-problem-88329470" target="_blank" rel="noopener">HyperLogLog 复杂的公式推导</a></p></blockquote><blockquote><p><code>redis</code>的<code>HyperLogLog</code>实现中用到的是<code>16384</code>个桶，也就是<code>2^14</code>，每个桶的<code>maxbits</code>需要<code>6 bits</code>来存储，最大可以表示<code>maxbits=63</code>，于是总共占用内存就是<code>2^14 * 6 / 8 = 12k</code>字节。</p></blockquote><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul><li>从处理海量数据count distict问题场景入手，引入<code>redis</code>的<code>HyperLogLog</code>数据结构解决方案，总结了使用方法并进行了实例分析说明；</li><li>对<code>HyperLogLog</code> 如何进行<code>count distict</code>计数的原理进行了简要探讨和实例分析说明，并给出了进一步参看建议;</li><li><code>HyperLogLog</code>结构主要是为了<code>count-distinct</code>问题，尤其是处理海量数据时，速度快，占用内存小，但是统计值是有误差的，并且只能递增，不能递减；</li><li><code>redis</code>对<code>HyperLogLog</code>的存储进行了优化，在计数比较小时，它的存储空间采用<code>稀疏矩阵存储</code>，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成<code>稠密矩阵</code>，才会占用<code>12k</code>的空间;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;HyperLoglog&lt;/code&gt;是&lt;code&gt;redis&lt;/code&gt;新支持的两种类型中的另外一种(上一种是位图类型&lt;code&gt;Bitmaps&lt;/code&gt;)。主要适用场景是海量数据的计算。特点是速度快, 占用空间小。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题04 数据结构之redis位图系列问题</title>
    <link href="http://researchlab.github.io/2018/01/19/redis-04-bitmap/"/>
    <id>http://researchlab.github.io/2018/01/19/redis-04-bitmap/</id>
    <published>2018-01-19T11:17:30.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p><code>redis</code>位图数据结构<code>bitmap</code>将很多小的整数储存到一个长度较大的位图中， 又或者将一个非常庞大的键分割为多个较小的键来进行储存，从而非常高效地使用内存，使得<code>redis</code>能够应用在诸多场景中, 如用户签到、统计活跃用户、用户在线状态等</p><blockquote><p>此外, <code>bitfield</code>能够以指定的方式对计算溢出进行控制的能力，使得它特别适合应用于实时分析领域；<br><a id="more"></a></p></blockquote><p>用户签到场景中, 签了记录<code>1</code>，没签<code>0</code>，如果使用普通的<code>key/value</code>结构，每个用户一年要记录<code>365</code>个，当用户上亿的时候，需要的存储空间是惊人的。采用<code>redis位图数据结构bitmap</code>，这样每天的签到记录只占据一个位，<code>365</code>天就是<code>365</code>个位，8个bit一个byte, 折算一下<code>46</code>个字节就可以完全容纳下，这就大大节约了存储空间。</p><p>当我们要统计月活的时候，因为需要去重，需要使用<code>set</code>来记录所有活跃用户的<code>id</code>，这非常浪费内存。这时就可以考虑使用位图来标记用户的活跃状态。每个用户会都在这个位图的一个确定位置上，<code>0</code>表示不活跃，<code>1</code>表示活跃。然后到月底遍历一次位图就可以得到月度活跃用户数。不过这个方法也是有条件的，那就是<code>userid</code>是整数连续的，并且活跃占比较高，否则可能得不偿失。</p><h4 id="位图操作"><a href="#位图操作" class="headerlink" title="位图操作"></a>位图操作</h4><p><code>redis</code>位图是通过一个<code>bit</code>位来表示某个元素对应的值或者状态, 其中的key就是对应元素本身，当然<code>redis</code>位数组是自动扩展，如果设置了某个偏移位置超出了现有的内容范围，就会自动将位数组进行零扩充。</p><p>位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是<code>byte</code>数组。可以使用普通的<code>get/set</code>直接获取和设置整个位图的内容，从<code>redis2.2.0</code>版本开始新增了<code>setbit</code>,<code>getbit</code>,<code>bitcount</code>等几个<code>bitmap</code>相关命令， 也可以使用位图操作<code>getbit/setbit</code>等将<code>byte</code>数组看成<code>「位数组」</code>来处理。</p><p>8个bit组成一个Byte，可以通过<code>setbit/getbit</code>来操作单个位但是比较麻烦，但这也正是bitmap本身会极大的节省储存空间， 当然也可以通过<code>bitfield</code>命令来操作多个位。</p><p>以设置一个字符<code>h</code>为示例<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">字符h对应的8位bit是: 0b1101000  (依次从高位到低位)</span><br></pre></td></tr></table></figure></p><p>从上述可知 只需要设置位图的第1、2，4位置为1 ，即完成设置字符串h的操作，<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; setbit s 1 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit s 2 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit s 4 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; get s</span><br><span class="line">"h"</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p><p>上述设置是通过<code>setbit</code>分3次设置，然后通过<code>get</code>操作一次取出8bit 得字符<code>h</code>, 也即<code>零存整取</code>的意思, 同样可以通过<code>set s h</code>配合<code>getbit 1</code> 来做到<code>整存零取</code>，或者<code>setbit/getbit</code>实现按位存入读取操作;</p><blockquote><p>如果对应位的字节是不可打印字符，redis-cli 会显示该字符的 16 进制形式。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; setbit x 0 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; setbit x 1 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; get x</span><br><span class="line">"\xc0"</span><br></pre></td></tr></table></figure><h4 id="bitcount-bitpos-应用"><a href="#bitcount-bitpos-应用" class="headerlink" title="bitcount/bitpos 应用"></a>bitcount/bitpos 应用</h4><p><code>redis</code>提供了位图统计指令<code>bitcount</code>和位图查找指令<code>bitpos</code>，<code>bitcount</code>用来统计指定位置范围内<code>1</code>的个数，<code>bitpos</code>用来查找指定范围内出现的第一个<code>0</code>或<code>1</code>。</p><p>比如我们可以通过<code>bitcount</code>统计用户一共签到了多少天，通过<code>bitpos</code>指令查找用户从哪一天开始第一次签到。如果指定了范围参数<code>[start, end]</code>，就可以统计在某个时间范围内用户签到了多少天，用户自某天以后的哪天开始签到。</p><blockquote><p>但<code>start</code>和<code>end</code>参数是<code>字节索引</code>，也就是说指定的位范围必须是<code>8</code>的倍数，而不能任意指定。正因此无法直接计算某个月内用户签到了多少天，而必须要将这个月所覆盖的字节内容全部取出来 (<code>getrange</code>可以取出字符串的子串) 然后在内存里进行统计，这个非常繁琐。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set s hello</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 统计所有`1`的个数</span></span><br><span class="line">127.0.0.1:6379&gt; bitcount s</span><br><span class="line">(integer) 21</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 统计第一个字符中1个个数</span></span><br><span class="line">127.0.0.1:6379&gt; bitcount s 0 0</span><br><span class="line">(integer) 3</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 统计前两个字符中1的个数</span></span><br><span class="line">127.0.0.1:6379&gt; bitcount s 0 1</span><br><span class="line">(integer) 7</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 第一个0 位置</span></span><br><span class="line">127.0.0.1:6379&gt; bitpos s 0</span><br><span class="line">(integer) 0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">第一个1 位置</span></span><br><span class="line">127.0.0.1:6379&gt; bitpos s 1</span><br><span class="line">(integer) 1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">从第二个字符开始的第一个1位置</span></span><br><span class="line">127.0.0.1:6379&gt; bitpos s 1 1 1</span><br><span class="line">(integer) 9</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">从第三个字符开始的第一个1位置</span></span><br><span class="line">127.0.0.1:6379&gt; bitpos s 1 2 2</span><br><span class="line">(integer) 17</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><h4 id="bitfield应用"><a href="#bitfield应用" class="headerlink" title="bitfield应用"></a>bitfield应用</h4><p><code>redis3.2</code>版本以后新增了一条<code>bitfield</code>命令，借助<code>bitfield</code>命令可以一次进行多个位的操作。</p><p><code>bitfield</code>有三个子指令，分别是<code>get/set/incrby</code>，它们都可以对指定位片段进行读写，但是最多只能处理<code>64</code>个连续的位，如果超过<code>64</code>位，就得使用多个子指令，当然<code>bitfield</code>可以一次执行多个子指令。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set s hello</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; bitfield s get u4 0 # 从第一个位开始取 4 个位，结果是无符号数 (u)</span><br><span class="line">1) (integer) 6</span><br><span class="line">127.0.0.1:6379&gt; bitfield s get u3 2 # 从第三个位开始取 3 个位，结果是无符号数 (u)</span><br><span class="line">1) (integer) 5</span><br><span class="line">127.0.0.1:6379&gt; bitfield s get i4 0 # 从第一个位开始取 4 个位，结果是无符号数 (i)</span><br><span class="line">1) (integer) 6</span><br><span class="line">127.0.0.1:6379&gt; bitfield s get i3 2 # 从第三个位开始取 3 个位，结果是无符号数 (i)</span><br><span class="line">1) (integer) -3</span><br><span class="line"><span class="meta">#</span><span class="bash"> 同时执行多条命令</span></span><br><span class="line">127.0.0.1:6379&gt; bitfield s get u4 0 get u3 2 get i4 0 get i3 2</span><br><span class="line">1) (integer) 6</span><br><span class="line">2) (integer) 5</span><br><span class="line">3) (integer) 6</span><br><span class="line">4) (integer) -3</span><br><span class="line"><span class="meta">#</span><span class="bash">将将第二个字符e改成a，a的 ASCII 码是 97</span></span><br><span class="line">127.0.0.1:6379&gt; bitfield s set u8 8 97</span><br><span class="line">1) (integer) 101</span><br><span class="line">127.0.0.1:6379&gt; get s</span><br><span class="line">"hallo"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 注意当设置位数不是8的整数倍，如下是7位时，会导致位数不对无法有效显示字符，redis直接显示出16进制代替</span></span><br><span class="line">127.0.0.1:6379&gt; bitfield s set u8 7 96</span><br><span class="line">1) (integer) 48</span><br><span class="line">127.0.0.1:6379&gt; get s</span><br><span class="line">"h\xc1llo"</span><br></pre></td></tr></table></figure></p><blockquote><p>所谓有符号数是指获取的位数组中第一个位是符号位，剩下的才是值。如果第一位是 1，那就是负数;</p></blockquote><blockquote><p>无符号数表示非负数，没有符号位，获取的位数组全部都是值;</p></blockquote><blockquote><p>有符号数最多可以获取 64 位，无符号数只能获取 63 位 (因为 Redis 协议中的 integer 是有符号数，最大 64 位，不能传递 64 位无符号值)。如果超出限制， redis会报错;</p></blockquote><p><code>bitfield</code>还有一个命令<code>incrby</code>，它用来对指定范围的位进行自增操作；</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set s hello</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; bitfield s incrby u4 2 1</span><br><span class="line">1) (integer) 11</span><br></pre></td></tr></table></figure><blockquote><p>既然提到自增，就有可能出现溢出。如果增加了正数，会出现上溢，如果增加的是负数，就会出现下溢出;</p></blockquote><blockquote><p><code>Redis</code>默认的处理是折返。如果出现了溢出，就将溢出的符号位丢掉。如果是 8 位无符号数 255，加 1 后就会溢出，会全部变零。如果是 8 位有符号数 127，加 1 后就会溢出变成 -128。</p></blockquote><h4 id="bitfield-自增溢出策略overflow"><a href="#bitfield-自增溢出策略overflow" class="headerlink" title="bitfield 自增溢出策略overflow"></a>bitfield 自增溢出策略overflow</h4><p><code>bitfield</code>指令提供了溢出策略子指令<code>overflow</code>，用户可以选择溢出行为，默认是折返<code>(wrap)</code>，还可以选择失败<code>(fail)</code>报错不执行，以及饱和截断<code>(sat)</code>，超过了范围就停留在最大最小值。<code>overflow</code>指令只影响接下来的第一条指令，这条指令执行完后溢出策略会变成默认值折返<code>(wrap)</code></p><p><strong>饱和截断策略 SAT</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set s 0111 0101</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; bitfield s overflow sat incrby u4 1 1</span><br><span class="line">1) (integer) 15</span><br><span class="line">127.0.0.1:6379&gt; bitfield s overflow sat incrby u4 1 1 # 保持最大值</span><br><span class="line">1) (integer) 15</span><br></pre></td></tr></table></figure><p>分析<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">字符'u'的ACSII二进制表示为 0111 0101</span><br><span class="line">字符'u' 8bit 在位图数组中的位置如下</span><br><span class="line">bitmap下标  0 1 2 3 4 5 6 7</span><br><span class="line">'u'8bit分布 0 1 1 1 0 1 0 1</span><br><span class="line"></span><br><span class="line">指令，bitfield s overflow sat incrby u4 1 1</span><br><span class="line">表示从 第一位置依次取四个位置值出来 加上一个1</span><br><span class="line">从第一位置依次取出四个位置值 为 bitmap下标1到4直接的值 即 1110 在加1 就是1111</span><br></pre></td></tr></table></figure></p><p><strong>失败不执行策略 FAIL</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set s what</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; bitfield s overflow fail incrby u4 1 1</span><br><span class="line">1) (integer) 15</span><br><span class="line">127.0.0.1:6379&gt; bitfield s overflow fail incrby u4 1 1</span><br><span class="line">1) (nil)</span><br><span class="line">127.0.0.1:6379&gt; bitfield s overflow fail incrby u4 1 1 # 失败不在执行</span><br><span class="line">1) (nil)</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p>分析同上</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><hr><ul><li><p>给出了<code>redis</code>位图数据结构<code>bitmap</code>的基本概念，操作及应用场景;</p></li><li><p>以签到场景为例 引入<code>bitcount/bitpos</code>在实际案例中的应用分析;</p></li><li><p>以依次操作多个位，引入<code>bitfield</code>指令，并对<code>bitfield</code>三个子指令<code>get/set/incrby</code>进行了实例分析说明；</p></li><li><p>进一步对<code>bitfield</code>的<code>incrby</code>操作溢出情况，从<code>redis</code>给出的三种溢出策略折返<code>(wrap)</code>，选择失败<code>(fail)</code>报错不执行，饱和截断<code>(sat)</code>进行了实例使用说明;</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;redis&lt;/code&gt;位图数据结构&lt;code&gt;bitmap&lt;/code&gt;将很多小的整数储存到一个长度较大的位图中， 又或者将一个非常庞大的键分割为多个较小的键来进行储存，从而非常高效地使用内存，使得&lt;code&gt;redis&lt;/code&gt;能够应用在诸多场景中, 如用户签到、统计活跃用户、用户在线状态等&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;此外, &lt;code&gt;bitfield&lt;/code&gt;能够以指定的方式对计算溢出进行控制的能力，使得它特别适合应用于实时分析领域；&lt;br&gt;&lt;/p&gt;&lt;/blockquote&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题03 消息队列系列问题</title>
    <link href="http://researchlab.github.io/2018/01/18/redis-03-delay-queue/"/>
    <id>http://researchlab.github.io/2018/01/18/redis-03-delay-queue/</id>
    <published>2018-01-18T10:20:31.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p>很多业务场景中多会用到消息队列来传递消息数据问题， 常用的消息队列如<code>NSQ</code>,<code>NAS</code>, <code>Rabbitmq</code>和<code>Kafka</code>等重量级消息队列中间件，功能很强大 使用起来自然也复杂，其实在大部分场景只是需要一个消息队列来传递数据，数据量，数据之间的顺序等也没有特殊的要求， 这样的场景使用<code>redis</code>非常轻松就可以搞定，而且在使用和维护上相对而言要简单方便些,当然<code>redis</code>的消息队列不是专业的消息队列，它没有非常多的高级特性，没有<code>ack</code>保证，如果对消息的可靠性有着极致的追求，那么它就不适合使用；<br><a id="more"></a></p><p>新秀<code>NQS</code>集群搭建相对简单，文档也很简介易懂，但其维护性和代码嵌入性上来讲要比用<code>redis消息队列</code>复杂的多， 此外使用过<code>Rabbitmq</code>的同学知道它使用起来有多复杂，发消息之前要创建<code>Exchange</code>，再创建<code>Queue</code>，还要将 <code>Queue</code>和<code>Exchange</code>通过某种规则绑定起来，发消息的时候要指定<code>routing-key</code>，还要控制头部信息。消费者在消费消息之前也要进行上面一系列的繁琐过程。</p><h4 id="list结构模拟队列"><a href="#list结构模拟队列" class="headerlink" title="list结构模拟队列"></a>list结构模拟队列</h4><p><code>redis</code>中可以用<code>list</code>(列表）结构来模拟队列和栈，而且非常简单，也常用来作为异步消息队列使用，使用<code>rpush/lpush</code>操作入队列，使用<code>lpop/rpop</code>来出队列。</p><p>客户端是通过队列的<code>pop</code>操作来获取消息，然后进行处理。处理完了再接着获取消息，再进行处理。显然客户端不停的<code>pop</code>操作，当队列空后，客户端就会陷入<code>pop</code>的死循环，此时空轮询不但拉高了客户端的<code>CPU</code>占用率,<code>redis</code>的 <code>QPS</code>也会被拉高，如果这样空轮询的客户端有几十来个，<code>redis</code>的慢查询可能会显著增多。</p><p>上述问题通常可以通过<code>sleep</code>命令来解决这个问题，让线程休眠一下，如<code>sleep (1s)</code>，但是休眠会导致消息的延迟增大。如果只有1个消费者，那么这个延迟就是1s。如果有多个消费者，这个延迟会有所下降，因为每个消费者的休眠时间是岔开来的。</p><p>有没有什么办法能显著降低延迟呢？</p><p>当然可以，借助redis提供了一组<code>blpop/brpop</code>阻塞读命令就可以，阻塞读在队列没有数据的时候，会立即进入休眠状态，一旦数据到来，则立刻醒过来。消息的延迟几乎为零。用<code>blpop/brpop</code>替代前面的<code>lpop/rpop</code>，就完美解决了上面的问题。</p><p>但是在实际使用过程中,<code>blpop/brpop</code> 可能会产生<code>假死</code>现象，就是当没有数据的时候通过<code>blpop/brpop</code>操作进入阻塞休眠状态，当再次有数据进来后，<code>blpop/brpop</code>操作并没有被唤醒继续执行<code>pop</code>, 这是为什么呢？</p><p>什么问题？ —— 空闲连接的问题。</p><p>如果线程一直阻塞在哪里，<code>Redis</code>的客户端连接就成了闲置连接，闲置过久，服务器一般会主动断开连接，减少闲置资源占用。这个时候blpop/brpop会抛出异常来。所以编写客户端消费者的时候要小心，注意捕获异常，还要重试。</p><p><strong>应用场景一 延时队列</strong></p><p>当客户端在处理请求时加锁没加成功怎么办。一般有3种策略来处理加锁失败：</p><ul><li><p>直接抛出异常，通知用户稍后重试；</p><ul><li>这种方式比较适合由用户直接发起的请求，用户看到错误对话框后，会先阅读对话框的内容，再点击重试，这样就可以起到人工延时的效果。如果考虑到用户体验，可以由前端的代码替代用户自己来进行延时重试控制。它本质上是对当前请求的放弃，由用户决定是否重新发起新的请求。</li></ul></li><li><p><code>sleep</code>一会再重试；</p><ul><li><code>sleep</code> 会阻塞当前的消息处理线程，会导致队列的后续消息处理出现延迟。如果碰撞的比较频繁或者队列里消息比较多，</li><li><code>sleep</code> 可能并不合适。如果因为个别死锁的 key 导致加锁不成功，线程会彻底堵死，导致后续消息永远得不到及时处理。</li></ul></li></ul><ul><li><u><strong>将请求转移至延时队列，过一会再试；</strong></u></li></ul><p>这种方式比较适合异步消息处理，将当前冲突的请求扔到另一个队列延后处理以避开冲突。</p><p><code>延时队列</code>可以通过<code>redis</code>的<code>zset(有序列表)</code>来实现。我们将消息序列化成一个字符串作为<code>zset</code>的<code>value</code>，这个消息的到期处理时间作为<code>score</code>，然后用多个线程轮询<code>zset</code>获取到期的任务进行处理，多个线程是为了保障可用性，万一挂了一个线程还有其它线程可以继续处理。因为有多个线程，所以需要考虑并发争抢任务，确保任务不能被多次执行。在处理上可以将<code>zrangebyscore</code>和<code>zrem</code>一同挪到服务器端进行原子化操作;</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><hr><ul><li>阐述了<code>redis</code>利用<code>list</code>结构模拟消息队列的使用原理，场景;</li><li>进一步分析了通过<code>list</code>结构模拟异步消息队列出现队列延迟的问题，引入<code>blpop/brpop</code>阻塞读命令操作；</li><li>进一步在<code>blpop/brpop</code>阻塞读命令休眠过久时无法再次唤醒<code>pop</code>操作，是因为当前连接休眠过久被会<code>redis</code>认为是<code>空闲连接</code>而强行断开连接， 导致后继的<code>blpop/brpop</code>在数据再次到达后无法再次唤醒<code>pop</code>操作， 此情况需要在程序实现时注意捕获<code>blpop/brpop</code>阻塞读异常并进行重试reload操作;</li><li>进一步分析了分布式锁加锁失败后的使用方法， 进而引入分析<code>延时队列</code>策略解决分布式锁加锁失败重试问题；</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;很多业务场景中多会用到消息队列来传递消息数据问题， 常用的消息队列如&lt;code&gt;NSQ&lt;/code&gt;,&lt;code&gt;NAS&lt;/code&gt;, &lt;code&gt;Rabbitmq&lt;/code&gt;和&lt;code&gt;Kafka&lt;/code&gt;等重量级消息队列中间件，功能很强大 使用起来自然也复杂，其实在大部分场景只是需要一个消息队列来传递数据，数据量，数据之间的顺序等也没有特殊的要求， 这样的场景使用&lt;code&gt;redis&lt;/code&gt;非常轻松就可以搞定，而且在使用和维护上相对而言要简单方便些,当然&lt;code&gt;redis&lt;/code&gt;的消息队列不是专业的消息队列，它没有非常多的高级特性，没有&lt;code&gt;ack&lt;/code&gt;保证，如果对消息的可靠性有着极致的追求，那么它就不适合使用；&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis专题02 分布式锁</title>
    <link href="http://researchlab.github.io/2018/01/18/redis-02-distributed-lock/"/>
    <id>http://researchlab.github.io/2018/01/18/redis-02-distributed-lock/</id>
    <published>2018-01-18T10:16:28.000Z</published>
    <updated>2018-10-26T12:04:15.898Z</updated>
    
    <content type="html"><![CDATA[<p>分布式应用进行逻辑处理时经常会遇到并发问题。<br><a id="more"></a></p><p>比如一个操作要修改用户的状态，修改状态需要先读出用户的状态，在内存里进行修改，改完了再存回去。如果这样的操作同时进行了，就会出现并发问题，因为读取和保存状态这两个操作不是原子的。（Wiki解释：所谓原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch 线程切换。）</p><p>这个时候就可以使用分布式锁来限制程序的并发执行。Redis分布式锁使用非常广泛。</p><h4 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h4><p>分布式锁本质上要实现的目标就是在<code>Redis</code>里面占一个”茅坑”，当别的进程也要来占时，发现已经有人蹲在那里了，就只好放弃或者稍后再试。</p><p>占坑一般是使用<code>setnx(set if not exists)</code>指令，只允许被一个客户端占坑。先来先占, 用完后再调用<code>del</code>指令释放茅坑。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; setnx lock:codehole true</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; get lock:codehole</span><br><span class="line">"true"</span><br><span class="line">... do something critical ...</span><br><span class="line">127.0.0.1:6379&gt; del lock:codehole</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p><p>但是有个问题，如果逻辑执行到中间出现异常了，可能会导致<code>del</code>指令没有被调用，这样就会陷入死锁，锁永远得不到释放。可以在拿到锁之后，再给锁加上一个过期时间，比如<code>5s</code>，这样即使中间出现异常也可以保证<code>5秒</code>之后锁会自动释放。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; setnx lock:codehole true</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; expire lock:codehole 5</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p><p>但是以上逻辑还有问题。如果在<code>setnx</code>和<code>expire</code>之间服务器进程突然挂掉了，可能是因为机器掉电或者是被人为杀掉的，就会导致<code>expire</code>得不到执行，也会造成死锁。</p><p>这种问题的根源就在于<code>setnx</code>和<code>expire</code>是两条指令而不是原子指令。如果这两条指令可以一起执行就不会出现问题。也许你会想到用<code>Redis</code>事务来解决。但是这里不行，因为<code>expire</code>是依赖于<code>setnx</code>的执行结果的，如果<code>setnx</code>的执行结果的，如果<code>setnx</code>没抢到锁，<code>expire</code>是不应该执行的。<code>redis事务</code>里没有<code>if-else</code>分支逻辑，<u><strong>事务的特点是一口气执行，要么全部执行要么一个都不执行。</strong></u></p><p>为了解决这个疑难，Redis2.8版本中作者加入了<code>set</code>指令的扩展参数，使得<code>setnx</code>和<code>expire</code>组合在一起的原子指令一起执行，它就是redis分布式锁的原理;</p><p><code>set</code>完整命令<br><strong>SET key value [EX seconds] [PX milliseconds] [NX|XX]</strong></p><ul><li><code>EX</code> second ：设置键的过期时间为 second 秒。 SET key value EX second 效果等同于 SETEX key second value 。</li><li><code>PX</code> millisecond ：设置键的过期时间为 millisecond 毫秒。 SET key value PX millisecond 效果等同于 PSETEX key millisecond value 。</li><li><code>NX</code> ：只在键不存在时，才对键进行设置操作。 SET key value NX 效果等同于 SETNX key value 。</li><li><code>XX</code> ：只在键已经存在时，才对键进行设置操作。</li></ul><p>从客户端执行命令： <code>SET resource-name anystring NX EX max-lock-time</code><br>如果服务器返回 OK ，那么这个客户端获得锁。<br>如果服务器返回 NIL ，那么客户端获取锁失败，可以在稍后再重试。<br>设置的过期时间到达之后，锁将自动释放。</p><p>可以通过以下修改，让这个锁实现更健壮：</p><p>不使用固定的字符串作为键的值，而是设置一个不可猜测（non-guessable）的长随机字符串，作为口令串（token）。<br>不使用 DEL 命令来释放锁，而是发送一个 Lua 脚本，这个脚本只在客户端传入的值和键的口令串相匹配时，才对键进行删除。<br>这两个改动可以防止持有过期锁的客户端误删现有锁的情况出现。</p><p>以下是一个简单的解锁脚本示例：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">if redis.call("get",KEYS[1]) == ARGV[1]</span><br><span class="line">then</span><br><span class="line">    return redis.call("del",KEYS[1])</span><br><span class="line">else</span><br><span class="line">    return 0</span><br><span class="line">end</span><br></pre></td></tr></table></figure></p><blockquote><p>这个脚本可以通过 EVAL …script… 1 resource-name token-value 命令来调用。</p></blockquote><blockquote><p>Redis的分布式锁不能解决超时问题，如果在加锁和释放锁之间的逻辑执行的太长，以至于超出了锁的超时限制，就会出现问题。因为这时候第一个线程持有的锁过期了，临界区的逻辑还没有执行完，这个时候第二个线程就提前重新持有了这把锁，导致临界区代码不能得到严格的串行执行。为了避免这个问题，Redis 分布式锁不要用于较长时间的任务。如果真的偶尔出现了，数据出现的小波错乱可能需要人工介入解决。</p></blockquote><p>上述通过<code>set</code>配合<code>lua</code>脚本实现的redis分布式锁，在集群情况下会存在如下问题，<br>比如在<code>Sentinel</code>集群中，主节点挂掉时，从节点会取而代之，客户端上却并没有明显感知。原先第一个客户端在主节点中申请成功了一把锁，但是这把锁还没有来得及同步到从节点，主节点突然挂掉了。然后从节点变成了主节点，这个新的节点内部没有这个锁，所以当另一个客户端过来请求加锁时，立即就批准了。这样就会导致系统中同样一把锁被两个客户端同时持有，不安全性由此产生。不过这种不安全也仅仅是在主从发生 failover 的情况下才会产生，而且持续时间极短，业务系统多数情况下可以容忍。</p><p>为了处理在集群模式下<code>redis</code>分布式锁存在的上述问题，可以考虑引入<code>redlock</code>分布式锁机制，当然为了使用<code>Redlock</code>，需要提供多个<code>Redis</code>实例，这些实例之前相互独立没有主从关系。同很多分布式算法一样，<code>redlock</code>也使用<code>「大多数机制」</code>。加锁时，它会向过半节点发送<code>set(key, value, nx=True, ex=xxx)</code>指令，只要过半节点 <code>set</code>成功，那就认为加锁成功。释放锁时，需要向所有节点发送<code>del</code>指令。不过<code>Redlock</code>算法还需要考虑出错重试、时钟漂移等很多细节问题，同时因为<code>Redlock</code>需要向多个节点进行读写，意味着相比单实例<code>Redis</code>性能会下降一些。</p><p>如果很在乎高可用性，希望挂了一台<code>redis</code>完全不受影响，那就应该考虑<code>redlock</code>, 不过代价也是有的，需要更多的 redis 实例，性能也会有折扣等；</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><hr><ul><li>阐述了<code>redis分布式锁</code>的实现原理;</li><li>进一步分析简单<code>redis分布式锁</code>可能存的超时操作，误删除操作等无法合理处理的问题，建议引入<code>lua</code>脚本配合执行，<code>lua</code>脚本作为<code>redis</code>的内置脚本可以优雅的协助处理很多<code>redis事务</code>无法处理的场景， 同时建议<code>redis分布式锁</code>不要用于较长时间的任务;</li><li>分析了在集群模式下<code>set</code>命令配合<code>lua</code>实现的<code>redis分布式锁</code>会引发数据不一致性问题，进一步引入分析了<code>redlock</code>锁机制，对其实现原理及可能带来的影响进行了简单分析总结;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;分布式应用进行逻辑处理时经常会遇到并发问题。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="redis专题" scheme="http://researchlab.github.io/categories/redis%E4%B8%93%E9%A2%98/"/>
    
    
      <category term="redis" scheme="http://researchlab.github.io/tags/redis/"/>
    
  </entry>
  
</feed>
